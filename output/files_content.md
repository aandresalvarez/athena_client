# üìÇ Project File Contents

- üìÅ **athena_client**
  - [`CONCEPT_EXPLORATION_GUIDE.md`](#athena_client-concept_exploration_guidemd)
  - [`CONTRIBUTING.md`](#athena_client-contributingmd)
  - [`README.md`](#athena_client-readmemd)
  - [`extract.py`](#athena_client-extractpy)
  - [`pyproject.toml`](#athena_client-pyprojecttoml)
  - [`test_enhanced_search.py`](#athena_client-test_enhanced_searchpy)
  - [`test_limits.py`](#athena_client-test_limitspy)
  - [`test_url.py`](#athena_client-test_urlpy)
    - üìÅ **workflows**
      - [`ci.yml`](#athena_client-github-workflows-ciyml)
      - [`publish.yml`](#athena_client-github-workflows-publishyml)
  - üìÅ **.pytest_cache**
    - [`README.md`](#athena_client-pytest_cache-readmemd)
  - üìÅ **athena_client**
    - [`__init__.py`](#athena_client-athena_client-__init__py)
    - [`async_client.py`](#athena_client-athena_client-async_clientpy)
    - [`auth.py`](#athena_client-athena_client-authpy)
    - [`cli.py`](#athena_client-athena_client-clipy)
    - [`client.py`](#athena_client-athena_client-clientpy)
    - [`concept_explorer.py`](#athena_client-athena_client-concept_explorerpy)
    - [`concept_set.py`](#athena_client-athena_client-concept_setpy)
    - [`exceptions.py`](#athena_client-athena_client-exceptionspy)
    - [`http.py`](#athena_client-athena_client-httppy)
    - [`query.py`](#athena_client-athena_client-querypy)
    - [`search_result.py`](#athena_client-athena_client-search_resultpy)
    - [`settings.py`](#athena_client-athena_client-settingspy)
  - üìÅ **athena_client.egg-info**
    - [`SOURCES.txt`](#athena_client-athena_clientegg-info-sourcestxt)
    - [`dependency_links.txt`](#athena_client-athena_clientegg-info-dependency_linkstxt)
    - [`entry_points.txt`](#athena_client-athena_clientegg-info-entry_pointstxt)
    - [`requires.txt`](#athena_client-athena_clientegg-info-requirestxt)
    - [`top_level.txt`](#athena_client-athena_clientegg-info-top_leveltxt)
    - üìÅ **db**
      - [`__init__.py`](#athena_client-athena_client-db-__init__py)
      - [`base.py`](#athena_client-athena_client-db-basepy)
      - [`sqlalchemy_connector.py`](#athena_client-athena_client-db-sqlalchemy_connectorpy)
    - üìÅ **models**
      - [`__init__.py`](#athena_client-athena_client-models-__init__py)
    - üìÅ **utils**
      - [`__init__.py`](#athena_client-athena_client-utils-__init__py)
      - [`progress.py`](#athena_client-athena_client-utils-progresspy)
      - üìÅ **athena_client**
        - [`__init__.py`](#athena_client-build-lib-athena_client-__init__py)
        - [`async_client.py`](#athena_client-build-lib-athena_client-async_clientpy)
        - [`auth.py`](#athena_client-build-lib-athena_client-authpy)
        - [`cli.py`](#athena_client-build-lib-athena_client-clipy)
        - [`client.py`](#athena_client-build-lib-athena_client-clientpy)
        - [`concept_explorer.py`](#athena_client-build-lib-athena_client-concept_explorerpy)
        - [`concept_set.py`](#athena_client-build-lib-athena_client-concept_setpy)
        - [`exceptions.py`](#athena_client-build-lib-athena_client-exceptionspy)
        - [`http.py`](#athena_client-build-lib-athena_client-httppy)
        - [`query.py`](#athena_client-build-lib-athena_client-querypy)
        - [`search_result.py`](#athena_client-build-lib-athena_client-search_resultpy)
        - [`settings.py`](#athena_client-build-lib-athena_client-settingspy)
        - üìÅ **db**
          - [`__init__.py`](#athena_client-build-lib-athena_client-db-__init__py)
          - [`base.py`](#athena_client-build-lib-athena_client-db-basepy)
          - [`sqlalchemy_connector.py`](#athena_client-build-lib-athena_client-db-sqlalchemy_connectorpy)
        - üìÅ **models**
          - [`__init__.py`](#athena_client-build-lib-athena_client-models-__init__py)
        - üìÅ **utils**
          - [`__init__.py`](#athena_client-build-lib-athena_client-utils-__init__py)
          - [`progress.py`](#athena_client-build-lib-athena_client-utils-progresspy)
  - üìÅ **examples**
    - [`advanced_retry_demo.py`](#athena_client-examples-advanced_retry_demopy)
    - [`bigquery_concept_set_demo.py`](#athena_client-examples-bigquery_concept_set_demopy)
    - [`concept_exploration_demo.py`](#athena_client-examples-concept_exploration_demopy)
    - [`concept_set_demo.py`](#athena_client-examples-concept_set_demopy)
    - [`demo.py`](#athena_client-examples-demopy)
    - [`error_handling_demo.py`](#athena_client-examples-error_handling_demopy)
    - [`graph_demo.py`](#athena_client-examples-graph_demopy)
    - [`large_query_demo.py`](#athena_client-examples-large_query_demopy)
    - [`retry_throttling_demo.py`](#athena_client-examples-retry_throttling_demopy)
    - [`simple_usage_demo.py`](#athena_client-examples-simple_usage_demopy)
  - üìÅ **tests**
    - [`__init__.py`](#athena_client-tests-__init__py)
    - [`conftest.py`](#athena_client-tests-conftestpy)
    - [`test_async_client.py`](#athena_client-tests-test_async_clientpy)
    - [`test_auth.py`](#athena_client-tests-test_authpy)
    - [`test_cli.py`](#athena_client-tests-test_clipy)
    - [`test_client.py`](#athena_client-tests-test_clientpy)
    - [`test_concept_explorer.py`](#athena_client-tests-test_concept_explorerpy)
    - [`test_concept_set.py`](#athena_client-tests-test_concept_setpy)
    - [`test_exceptions.py`](#athena_client-tests-test_exceptionspy)
    - [`test_http.py`](#athena_client-tests-test_httppy)
    - [`test_models.py`](#athena_client-tests-test_modelspy)
    - [`test_query.py`](#athena_client-tests-test_querypy)
    - [`test_search_result.py`](#athena_client-tests-test_search_resultpy)
    - [`test_utils.py`](#athena_client-tests-test_utilspy)
    - üìÅ **benchmarks**
      - [`test_orjson.py`](#athena_client-tests-benchmarks-test_orjsonpy)
    - üìÅ **db**
      - [`__init__.py`](#athena_client-tests-db-__init__py)
      - [`test_sqlalchemy_connector.py`](#athena_client-tests-db-test_sqlalchemy_connectorpy)
    - üìÅ **property**
      - [`test_query_builder.py`](#athena_client-tests-property-test_query_builderpy)

---

# Target Folder: athena_client

## Folder: athena_client

> ‚ÑπÔ∏è *Note: Contains a virtual environment folder (e.g., `venv`, `.venv`). Contents are excluded.*

### File: `athena_client/CONCEPT_EXPLORATION_GUIDE.md`
<a name="athena_client-concept_exploration_guidemd"></a>
```markdown
 
```

### File: `athena_client/CONTRIBUTING.md`
<a name="athena_client-contributingmd"></a>
```markdown
# Contributing to Athena Client

Thank you for considering a contribution!

### Quick Start

```bash
pip install hatch
make install
make quality   # format + lint + mypy + bandit
make test      # unit, async & property tests
```

### Security Checks

We run **Bandit** on every pull request. Execute locally with:

```bash
make bandit
```

The CI build fails on any high-severity finding.

```

### File: `athena_client/README.md`
<a name="athena_client-readmemd"></a>
```markdown
# athena-client
[![SBOM](https://img.shields.io/badge/SBOM-available-blue)](sbom.json)

A production-ready Python SDK for the OHDSI Athena Concepts API.

## Installation

```bash
pip install athena-client
```

To enable database integration features for concept set generation, install the necessary extras:

**For PostgreSQL:**
```bash
pip install "athena-client[postgres]"
```

**For Google BigQuery:**
```bash
pip install "athena-client[bigquery]"
```

Other optional dependencies:
```bash
pip install athena-client[cli]      # Command-line interface
pip install athena-client[async]    # Async client
pip install athena-client[pandas]   # DataFrame output support
pip install athena-client[yaml]     # YAML output format
pip install athena-client[crypto]   # HMAC authentication
pip install athena-client[all]      # All optional dependencies
```

## Quick Start

```python
from athena_client import Athena

# Create a client with default settings (public Athena server)
athena = Athena()

# Search for concepts
results = athena.search("aspirin")

# Various output formats
concepts = results.all()         # List of Pydantic models
top_three = results.top(3)       # First three results
as_dict = results.to_list()      # List of dictionaries
as_json = results.to_json()      # JSON string
as_df = results.to_df()          # pandas DataFrame

# Get details for a specific concept
details = athena.details(concept_id=1127433)

# Get relationships
rels = athena.relationships(concept_id=1127433)

# Get graph
graph = athena.graph(concept_id=1127433, depth=5)

# Get comprehensive summary
summary = athena.summary(concept_id=1127433)
```

---

## Generating Validated Concept Sets

This feature bridges the gap between the public Athena API and your local OMOP database, allowing you to generate complete, analysis-ready concept sets that are validated against your specific vocabulary version.

### How It Works
1.  **Discover**: Uses the Athena API's powerful search to find candidate standard concepts for your query.
2.  **Validate**: Checks if those concepts exist and are marked as 'Standard' **in your local database**. This is crucial for aligning with your institution's vocabulary version.
3.  **Expand**: Queries your local `concept_ancestor` table to instantly find all descendant concepts, ensuring your set is complete.
4.  **Recover**: If the best concept from the API isn't in your local DB, it intelligently finds an alternative path using other candidates or local non-standard mappings.

### Usage Example
```python
import asyncio
from athena_client import Athena

# Your OMOP database connection string
# (You'll get this from your database administrator)
DB_CONNECTION_STRING = "postgresql://user:pass@localhost/omop_cdm"

async def main():
    athena = Athena()

    # Generate a concept set for "Type 2 Diabetes"
    concept_set = await athena.generate_concept_set(
        query="Type 2 Diabetes",
        db_connection_string=DB_CONNECTION_STRING
    )

    if concept_set["metadata"]["status"] == "SUCCESS":
        print(f"Success! Found {len(concept_set['concept_ids'])} concepts.")
        print(f"Strategy used: {concept_set['metadata']['strategy_used']}")
        for warning in concept_set['metadata'].get('warnings', []):
            print(f"Warning: {warning}")
    else:
        print(f"Failed: {concept_set['metadata']['reason']}")

asyncio.run(main())
```
The returned dictionary includes the `concept_ids` and `metadata` explaining how the set was generated and any warnings to consider.

### CLI Usage for Concept Sets
You can also generate concept sets directly from the command line.

```bash
# Set an environment variable with your connection string (optional, but convenient)
export OMOP_DB_CONNECTION="postgresql://user:pass@localhost/omop"

# Generate the concept set and output as JSON
athena generate-set "Type 2 Diabetes" --output json
```

---
***(New Section Ends Here)***

## Concept Exploration - Finding Standard Concepts

The athena-client provides advanced concept exploration capabilities to help you find standard concepts that might not appear directly in search results. This is particularly useful when working with medical terminology where standard concepts may be referenced through synonyms, relationships, or cross-references.

### Why Concept Exploration?

Medical terminology systems often have complex hierarchies where:
- **Standard concepts** are the preferred, canonical representations
- **Non-standard concepts** may be more commonly used terms
- **Synonyms** provide alternative names for the same concept
- **Relationships** connect related concepts across vocabularies
- **Cross-references** map concepts between different coding systems

The concept exploration functionality helps bridge the gap between user queries and standard medical concepts.

### Basic Concept Exploration

```python
import asyncio
from athena_client import Athena, create_concept_explorer
from athena_client.async_client import AthenaAsyncClient

# Create async client and explorer (recommended for best performance)
client = AthenaAsyncClient()
explorer = create_concept_explorer(client)

async def explore_concepts():
    # Find standard concepts through exploration
    results = await explorer.find_standard_concepts(
        query="headache",
        max_exploration_depth=2,
        initial_seed_limit=10,  # Control exploration scope
        include_synonyms=True,
        include_relationships=True,
        vocabulary_priority=['SNOMED', 'RxNorm', 'ICD10']
    )

    print(f"Direct matches: {len(results['direct_matches'])}")
    print(f"Synonym matches: {len(results['synonym_matches'])}")
    print(f"Relationship matches: {len(results['relationship_matches'])}")
    print(f"Cross-references: {len(results['cross_references'])}")

# Run the async function
asyncio.run(explore_concepts())
```

### Mapping to Standard Concepts with Confidence Scores

```python
async def map_concepts():
    # Map a query to standard concepts with confidence scoring
    mappings = await explorer.map_to_standard_concepts(
        query="migraine",
        target_vocabularies=['SNOMED', 'RxNorm'],
        confidence_threshold=0.5
    )

    for mapping in mappings:
        concept = mapping['concept']
        confidence = mapping['confidence']
        path = mapping['exploration_path']
        
        print(f"Concept: {concept.name}")
        print(f"Vocabulary: {concept.vocabulary}")
        print(f"Confidence: {confidence:.2f}")
        print(f"Discovery path: {path}")
        print()

asyncio.run(map_concepts())
```

### Alternative Query Suggestions

When standard concepts aren't found directly, get alternative query suggestions:

```python
# Get alternative query suggestions
suggestions = explorer.suggest_alternative_queries(
    query="heart attack", 
    max_suggestions=8
)

print("Alternative suggestions:")
for suggestion in suggestions:
    print(f"  - {suggestion}")

# Test a suggestion
test_results = athena.search(suggestions[0], size=5)
standard_concepts = [c for c in test_results.all() if c.standardConcept == "Standard"]
print(f"Found {len(standard_concepts)} standard concepts")
```

### Concept Hierarchy Exploration

Explore the hierarchical relationships of concepts:

```python
# Get concept hierarchy
hierarchy = explorer.get_concept_hierarchy(
    concept_id=12345, 
    max_depth=3
)

print(f"Root concept: {hierarchy['root_concept'].name}")
print(f"Parent relationships: {len(hierarchy['parents'])}")
print(f"Child relationships: {len(hierarchy['children'])}")
print(f"Sibling relationships: {len(hierarchy['siblings'])}")

# Show parent concepts
for parent in hierarchy['parents'][:3]:
    print(f"  Parent: {parent.targetConceptName} ({parent.relationshipName})")
```

### Comprehensive Workflow Example

Here's a complete workflow for finding standard concepts:

```python
import asyncio
from athena_client.async_client import AthenaAsyncClient
from athena_client import create_concept_explorer

async def find_standard_concepts_workflow(query):
    """Comprehensive workflow for finding standard concepts."""
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # Step 1: Try direct search first
    direct_results = client.search_concepts(query, page_size=10)
    direct_standard = [c for c in direct_results['content'] if c.standardConcept == "Standard"]
    
    if direct_standard:
        print(f"‚úÖ Found {len(direct_standard)} standard concepts directly")
        return direct_standard
    
    # Step 2: Use concept exploration
    print("üîç Exploring for standard concepts...")
    exploration_results = await explorer.find_standard_concepts(
        query=query,
        max_exploration_depth=3,
        initial_seed_limit=10,
        include_synonyms=True,
        include_relationships=True
    )
    
    # Step 3: Get high-confidence mappings
    mappings = await explorer.map_to_standard_concepts(
        query=query,
        confidence_threshold=0.4
    )
    
    if mappings:
        print(f"‚úÖ Found {len(mappings)} high-confidence mappings")
        return [m['concept'] for m in mappings]
    
    # Step 4: Try alternative queries
    print("üí° Trying alternative queries...")
    suggestions = explorer.suggest_alternative_queries(query, max_suggestions=5)
    
    for suggestion in suggestions:
        test_results = client.search_concepts(suggestion, page_size=5)
        standard_found = [c for c in test_results['content'] if c.standardConcept == "Standard"]
        if standard_found:
            print(f"‚úÖ Found standard concepts with suggestion: '{suggestion}'")
            return standard_found
    
    print("‚ùå No standard concepts found")
    return []

# Use the workflow
async def main():
    standard_concepts = await find_standard_concepts_workflow("myocardial infarction")
    print(f"Found {len(standard_concepts)} standard concepts")

asyncio.run(main())
```

### Advanced Configuration

Configure exploration behavior for your specific needs:

```python
import asyncio
from athena_client.async_client import AthenaAsyncClient
from athena_client import create_concept_explorer

async def advanced_exploration():
    # Create async client and explorer
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)

    # Comprehensive exploration with all features
    results = await explorer.find_standard_concepts(
        query="diabetes",
        max_exploration_depth=3,        # How deep to explore relationships
        initial_seed_limit=15,          # Number of seed concepts to explore
        include_synonyms=True,          # Explore synonyms
        include_relationships=True,     # Explore relationships
        vocabulary_priority=[           # Preferred vocabularies
            'SNOMED', 
            'RxNorm', 
            'ICD10', 
            'LOINC'
        ]
    )

    # High-confidence mapping with specific vocabularies
    mappings = await explorer.map_to_standard_concepts(
        query="hypertension",
        target_vocabularies=['SNOMED', 'ICD10'],  # Only these vocabularies
        confidence_threshold=0.7                  # High confidence threshold
    )
asyncio.run(advanced_exploration())
```

### Use Cases

#### 1. Clinical Decision Support
```python
import asyncio
from athena_client.async_client import AthenaAsyncClient
from athena_client import create_concept_explorer

async def clinical_decision_support():
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # Find standard concepts for clinical conditions
    conditions = ["chest pain", "shortness of breath", "fever"]
    standard_concepts = {}

    for condition in conditions:
        mappings = await explorer.map_to_standard_concepts(
            condition, 
            target_vocabularies=['SNOMED'],
            confidence_threshold=0.6
        )
        if mappings:
            standard_concepts[condition] = mappings[0]['concept']
    
    return standard_concepts

asyncio.run(clinical_decision_support())
```

#### 2. Medication Mapping
```python
async def medication_mapping():
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # Map medication names to standard drug concepts
    medications = ["aspirin", "ibuprofen", "acetaminophen"]
    drug_concepts = {}

    for med in medications:
        mappings = await explorer.map_to_standard_concepts(
            med,
            target_vocabularies=['RxNorm'],
            confidence_threshold=0.5
        )
        if mappings:
            drug_concepts[med] = mappings[0]['concept']
    
    return drug_concepts

asyncio.run(medication_mapping())
```

#### 3. Cross-Vocabulary Mapping
```python
async def cross_vocabulary_mapping():
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # Map between different coding systems
    icd10_results = client.search_concepts("diabetes", vocabulary="ICD10")
    if icd10_results['content']:
        icd10_concept = icd10_results['content'][0]
        snomed_mappings = await explorer.map_to_standard_concepts(
            icd10_concept.name,
            target_vocabularies=['SNOMED'],
            confidence_threshold=0.7
        )
        return snomed_mappings
    
    return []

asyncio.run(cross_vocabulary_mapping())
```

### Best Practices

1. **Start with direct search** - It's faster and often sufficient
2. **Use appropriate confidence thresholds** - 0.5-0.7 for most use cases
3. **Specify target vocabularies** - Focus on relevant coding systems
4. **Explore relationships** - Useful for finding broader/narrower concepts
5. **Use synonyms** - Helps with alternative terminology
6. **Monitor and adjust timeout settings** - Especially for complex or large queries

### Performance Considerations

- **Exploration depth** affects performance - use 1-3 for most cases
- **Vocabulary filtering** reduces API calls and improves relevance
- **Confidence thresholds** help focus on high-quality matches
- **Caching** can be implemented for frequently used mappings

### Error Handling

The concept exploration functionality includes robust error handling:

```python
import asyncio
from athena_client.async_client import AthenaAsyncClient
from athena_client import create_concept_explorer

async def robust_exploration():
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    try:
        mappings = await explorer.map_to_standard_concepts("diabetes")
        print(f"Found {len(mappings)} mappings")
    except Exception as e:
        print(f"Exploration failed: {e}")
        # Fall back to direct search
        results = client.search_concepts("diabetes")
        print(f"Direct search found {len(results['content'])} concepts")

asyncio.run(robust_exploration())
```

This concept exploration functionality helps ensure you can find the standard medical concepts you need, even when they don't appear directly in search results.

## Error Handling

The athena-client provides **automatic error handling and recovery** out of the box. You don't need to implement try-catch blocks - the client handles errors gracefully and provides clear, actionable messages:

```python
from athena_client import Athena

athena = Athena()

# Automatic error handling - no try-catch needed!
results = athena.search("aspirin")
print(f"Found {len(results.all())} concepts")

# If there are network issues, the client automatically retries
# If there are API errors, you get clear, actionable messages
details = athena.details(concept_id=1127433)
print(f"Concept: {details.name}")
```

### What Happens Automatically

‚úÖ **Network errors** are automatically retried (up to 3 attempts)  
‚úÖ **API errors** provide clear, actionable messages  
‚úÖ **Timeout issues** are handled with exponential backoff  
‚úÖ **Invalid parameters** are caught with helpful suggestions  
‚úÖ **Missing resources** are reported with context  

### Advanced Error Handling (Optional)

If you want more control, you can still use try-catch blocks:

```python
from athena_client import Athena
from athena_client.exceptions import NetworkError, APIError, ClientError

athena = Athena()

try:
    results = athena.search("aspirin")
    print(f"Found {len(results.all())} concepts")
except NetworkError as e:
    print(f"Network issue: {e}")
    # Error includes troubleshooting suggestions
except APIError as e:
    print(f"API issue: {e}")
    # Specific API error messages with context
except ClientError as e:
    print(f"Client error: {e}")
    # HTTP 4xx errors with status codes
except Exception as e:
    print(f"Unexpected error: {e}")
```

### Disabling Auto-Retry

If you prefer to handle retries yourself, you can disable automatic retry:

```python
# Disable automatic retry for this call
results = athena.search("aspirin", auto_retry=False)

# Or disable for all calls
athena = Athena(max_retries=0)
```

### Advanced Retry Configuration

Developers have fine-grained control over retry behavior:

```python
# Configure retry settings at client level
athena = Athena(
    max_retries=5,                    # Maximum retry attempts
    retry_delay=2.0,                  # Fixed delay between retries (seconds)
    enable_throttling=True,           # Enable request throttling
    throttle_delay_range=(0.1, 0.5),  # Throttling delay range (min, max)
    timeout=30                        # Request timeout
)

# Override retry settings for specific calls
results = athena.search(
    "aspirin",
    max_retries=3,      # Override max retries for this call
    retry_delay=1.0     # Override retry delay for this call
)
```

### Detailed Retry Error Reporting

When retries fail, you get comprehensive error information:

```python
try:
    results = athena.search("aspirin")
except RetryFailedError as e:
    print(f"Retry failed after {e.max_attempts} attempts")
    print(f"Last error: {e.last_error}")
    print(f"Retry history: {e.retry_history}")
    # Error includes detailed retry information and troubleshooting
```

### Retry Configuration Options

| Option | Description | Default | Example |
|--------|-------------|---------|---------|
| `max_retries` | Maximum retry attempts for network errors | 3 | `max_retries=5` |
| `retry_delay` | Fixed delay between retries (overrides exponential backoff) | None | `retry_delay=2.0` |
| `enable_throttling` | Enable request throttling to prevent overwhelming server | True | `enable_throttling=False` |
| `throttle_delay_range` | Range of delays for throttling (min, max) in seconds | (0.1, 0.3) | `throttle_delay_range=(0.2, 0.5)` |
| `timeout` | Request timeout in seconds | 15 | `timeout=30` |

### Error Types

- **NetworkError**: DNS, connection, socket issues
- **TimeoutError**: Request timeout issues  
- **ClientError**: 4xx HTTP status codes
- **ServerError**: 5xx HTTP status codes
- **AuthenticationError**: 401/403 authentication issues
- **RateLimitError**: 429 rate limiting issues
- **ValidationError**: Data validation failures
- **APIError**: API-specific error responses

### Error Message Features

‚úÖ **Clear explanations** of what went wrong  
‚úÖ **Context** about where the error occurred  
‚úÖ **Specific troubleshooting suggestions**  
‚úÖ **Error codes** for programmatic handling  
‚úÖ **User-friendly language** (not technical jargon)  
‚úÖ **Automatic retry** for recoverable errors

## Enhanced Large Query Handling

The athena-client provides intelligent handling for large queries with enhanced timeouts, progress tracking, and user-friendly error messages.

### Intelligent Timeout Management

Different operations use optimized timeouts based on query complexity:

```python
from athena_client import Athena

# Default timeouts are automatically adjusted based on query size
athena = Athena()

# Small queries: 30s timeout
results = athena.search("aspirin 325mg tablet")

# Large queries: 45s+ timeout (auto-adjusted)
results = athena.search("pain")  # Estimated 5000+ results

# Complex graphs: 60s+ timeout
graph = athena.graph(concept_id, depth=3, zoom_level=3)
```

### Progress Tracking for Long Operations

Large queries automatically show progress bars with ETA:

```python
# Progress tracking is enabled by default for large queries
results = athena.search("diabetes", size=100)
# Shows: Searching for 'diabetes': [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0% (100/100) 2.3s

# Disable progress tracking if needed
results = athena.search("diabetes", show_progress=False)
```

### User-Friendly Warnings

The client warns about potentially large queries:

```python
results = athena.search("pain")
# Output:
# ‚ö†Ô∏è  Large query detected: 'pain' (estimated 5,000+ results)
# üí° Suggestions:
#    ‚Ä¢ Add more specific terms to narrow results
#    ‚Ä¢ Use domain or vocabulary filters
#    ‚Ä¢ Consider using smaller page sizes
#    ‚Ä¢ This query may take several minutes to complete
```

### Smart Pagination

Enhanced pagination with automatic validation and optimization:

```python
# Automatic page size validation
try:
    results = athena.search("aspirin", size=2000)  # Too large
except ValueError as e:
    print(e)  # "Page size 2000 exceeds maximum allowed size of 1000"

# Smart defaults based on query size
results = athena.search("pain")  # Uses smaller page size for large queries
```

### Enhanced Error Messages for Large Queries

Specific error messages for timeout and complexity issues:

```python
try:
    results = athena.search("very broad search term")
except APIError as e:
    print(e)
    # Output:
    # Search timeout: The query 'very broad search term' is taking too long to process.
    # Try:
    # ‚Ä¢ Using more specific search terms
    # ‚Ä¢ Adding domain or vocabulary filters
    # ‚Ä¢ Reducing the page size
    # ‚Ä¢ Breaking the query into smaller parts
```

### Configuration for Large Queries

Fine-tune large query behavior:

```python
from athena_client.settings import get_settings

settings = get_settings()

# Timeout configuration
settings.ATHENA_SEARCH_TIMEOUT_SECONDS = 60      # Search operations
settings.ATHENA_GRAPH_TIMEOUT_SECONDS = 90       # Graph operations
settings.ATHENA_RELATIONSHIPS_TIMEOUT_SECONDS = 60  # Relationship queries

# Pagination configuration
settings.ATHENA_DEFAULT_PAGE_SIZE = 50           # Default page size
settings.ATHENA_MAX_PAGE_SIZE = 1000             # Maximum page size
settings.ATHENA_LARGE_QUERY_THRESHOLD = 100      # Threshold for "large" queries

# Progress configuration
settings.ATHENA_SHOW_PROGRESS = True             # Enable progress tracking
settings.ATHENA_PROGRESS_UPDATE_INTERVAL = 2.0   # Update interval (seconds)
```

### Large Query Best Practices

```python
# 1. Use specific search terms
results = athena.search("acute myocardial infarction")  # Better than "heart attack"

# 2. Add filters to narrow results
results = athena.search("diabetes", domain="Condition", vocabulary="SNOMED")

# 3. Use smaller page sizes for large queries
results = athena.search("pain", size=20)  # Instead of 100

# 4. Enable progress tracking for visibility
results = athena.search("cancer", show_progress=True)

# 5. Monitor and adjust timeout settings
athena = Athena(timeout=60)  # Increase timeout for complex operations
```

### Large Query Features

‚úÖ **Automatic timeout adjustment** based on query complexity  
‚úÖ **Progress tracking** with ETA for long operations  
‚úÖ **User-friendly warnings** for potentially large queries  
‚úÖ **Smart pagination** with automatic validation  
‚úÖ **Enhanced error messages** with specific suggestions
‚úÖ **Memory-efficient processing** for large result sets
‚úÖ **Configurable thresholds** for different query types

---

## Google BigQuery & OMOP Integration (Python 3.9 Only)

> **BigQuery support requires Python 3.9 due to upstream dependency constraints.**
> 
> - `pybigquery` (required for BigQuery) is only compatible with `sqlalchemy<1.5.0`.
> - The SDK will not work with BigQuery on Python 3.10+ or SQLAlchemy 2.x.

### Installation for BigQuery/OMOP

1. **Create a Python 3.9 virtual environment** (recommended):
   ```bash
   python3.9 -m venv .venv
   source .venv/bin/activate
   pip install --upgrade pip setuptools
   ```
2. **Install the SDK with BigQuery extras:**
   ```bash
   pip install "athena-client[bigquery]"
   ```
   This will install compatible versions of `pybigquery` and `sqlalchemy`.

3. **Authenticate with Google Cloud:**
   ```bash
   gcloud auth application-default login
   ```
   (Requires the [Google Cloud SDK](https://cloud.google.com/sdk/docs/install))

4. **Set your environment variables:**
   ```bash
   export GCP_PROJECT_ID=your-gcp-project-id
   export BIGQUERY_DATASET=your_omop_dataset
   ```

5. **Run the example script:**
   ```bash
   python examples/bigquery_concept_set_demo.py
   ```
   The script will check your Python version and dependencies at runtime, and provide clear error messages if anything is missing.

### Example: Generating a Concept Set with BigQuery
See [`examples/bigquery_concept_set_demo.py`](examples/bigquery_concept_set_demo.py) for a full, robust example including:
- Dependency and Python version checks
- Google Cloud authentication guidance
- Usage of the Athena client with a BigQuery OMOP CDM

---

## Troubleshooting

- **Editable install fails with TOML or dependency errors?**
  - Ensure your `pyproject.toml` is valid and you are using Python 3.9.
  - Run `pip install --upgrade pip setuptools` before installing.
- **psycopg2-binary build errors (pg_config not found)?**
  - On macOS, run `brew install postgresql` to provide `pg_config`.
- **BigQuery install fails due to SQLAlchemy version conflict?**
  - Only `sqlalchemy>=1.4.0,<1.5.0` is supported for BigQuery. The SDK will install the correct version if you use the `[bigquery]` extra.
- **Python version errors?**
  - BigQuery support is only tested and supported on Python 3.9. Use `pyenv` or a `.python-version` file to enforce this if needed.

---

```

### File: `athena_client/pyproject.toml`
<a name="athena_client-pyprojecttoml"></a>
```toml

[build-system]
requires = ["setuptools>=42", "wheel", "hatchling", "hatch"]
build-backend = "setuptools.build_meta"

[project]
name = "athena-client"
version = "1.0.9"
description = "Production-ready Python SDK for the OHDSI Athena Concepts API"
readme = "README.md"
requires-python = ">=3.9,<3.10"
license = "MIT"
authors = [
    {name = "Athena-Client Core Engineering Team"}
]

dependencies = [
    "orjson>=3.9.0",
    "pydantic>=2.0.0",
    "pydantic-settings",
    "httpx>=0.18.0",
    "backoff>=2.0.0",
    "sqlalchemy>=1.4.0,<1.5.0",
    "pandas>=1.3.0",
    "click>=8.0.0",
    "rich>=10.0.0",
    "pyyaml>=6.0",
    "cryptography>=36.0.0",
    "psycopg2-binary>=2.9.0"
]

[tool.setuptools]
packages = { find = { include = ["athena_client*"], exclude = ["output*"] } }

[project.optional-dependencies]
async = ["httpx>=0.18.0", "backoff>=2.0.0"]
pandas = ["pandas>=1.3.0"]
cli = ["click>=8.0.0", "rich>=10.0.0"]
yaml = ["pyyaml>=6.0"]
crypto = ["cryptography>=36.0.0"]
postgres = ["sqlalchemy>=1.4.0,<1.5.0", "psycopg2-binary>=2.9.0"]
bigquery = ["sqlalchemy>=1.4.0,<1.5.0", "sqlalchemy-bigquery"]
db = [
    "athena-client[postgres]",
    "athena-client[bigquery]"
]
dev = [
  "ruff>=0.4.0",
  "cyclonedx-bom>=3.15.0",
  "mypy>=1.10",
  "pip-audit>=2.6",
  "pytest>=8.2",
  "pytest-cov>=5.0",
  "pytest-asyncio[mode-auto]>=0.23",
  "hypothesis>=6.103",
  "vcrpy>=6.0",
  "rich>=13.7",
  "build>=1.2",
  "twine>=5.1",
  "pytest-benchmark>=4.0",
  "bandit>=1.7.5",
  "cyclonedx-python-lib>=5.2.0",
  "types-requests",
  "types-PyYAML",
  "pandas-stubs",
  "sqlalchemy-stubs",
  "hatch",
  "hatchling"
]


[tool.hatch.envs.default]
features = ["dev"]
dependencies = [
  "pytest-cov"
]

[project.scripts]
athena = "athena_client.cli:main"
athena-client = "athena_client.cli:main"

[project.urls]
Homepage = "https://github.com/username/athena-client"
Documentation = "https://athena-client.readthedocs.io"
Issues = "https://github.com/username/athena-client/issues"

[tool.black]
line-length = 88
target-version = ["py39"]


[tool.ruff]
target-version = "py39"
line-length = 88
lint.select = ["E", "F", "B", "I"]

[tool.mypy]
python_version = "3.9"
warn_redundant_casts = true
warn_unused_ignores = true
disallow_any_generics = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
strict_optional = true

[tool.hatch.envs.default.scripts]
lint = "ruff check athena_client tests"
format = "ruff format athena_client tests"
type-check = "mypy athena_client"
test = "pytest {args}"
cov = "pytest --cov=athena_client --cov-report=term-missing {args}"
bandit-check = "bandit -c pyproject.toml -r athena_client -s B101,B404,B603"
cyclonedx = "cyclonedx-py environment --of json -o sbom.json"

quality = [
  "format",
  "lint",
  "type-check",
  "bandit-check",
]
```

### File: `athena_client/test_enhanced_search.py`
<a name="athena_client-test_enhanced_searchpy"></a>
```python
#!/usr/bin/env python3
"""
Test script to demonstrate enhanced search functionality with progress tracking.
"""

from athena_client import Athena

def test_enhanced_search():
    """Test enhanced search with progress tracking."""
    athena = Athena()
    
    print('Testing enhanced search with large query...')
    print('Searching for "pain" with progress tracking...')
    
    try:
        results = athena.search('pain', size=50, show_progress=True)
        print(f'\n‚úÖ Search completed! Found {len(results)} results')
        print(f'Total elements: {results.total_elements}')
        print(f'Current page: {results.current_page}')
        print(f'Page size: {results.page_size}')
        
        print('\nFirst 3 results:')
        for i, concept in enumerate(results.top(3), 1):
            print(f'  {i}. [{concept.id}] {concept.name} ({concept.vocabulary})')
            
    except Exception as e:
        print(f'‚ùå Search failed: {e}')

def test_graph_with_progress():
    """Test graph operation with progress tracking."""
    athena = Athena()
    
    print('\nTesting enhanced graph with progress tracking...')
    print('Getting graph for aspirin concept (ID: 1191)...')
    
    try:
        graph = athena.graph(1191, depth=2, zoom_level=2, show_progress=True)
        print(f'\n‚úÖ Graph completed!')
        print(f'Terms: {len(graph.terms)}')
        print(f'Links: {len(graph.links)}')
        
    except Exception as e:
        print(f'‚ùå Graph failed: {e}')

if __name__ == "__main__":
    test_enhanced_search()
    test_graph_with_progress() 
```

### File: `athena_client/test_limits.py`
<a name="athena_client-test_limitspy"></a>
```python
#!/usr/bin/env python3
"""
Simple test to verify concept exploration limits are working.
"""

import pytest
from athena_client.async_client import AthenaAsyncClient
from athena_client.concept_explorer import create_concept_explorer

@pytest.mark.asyncio
async def test_limits():
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    print('Testing concept exploration with limits...')
    results = await explorer.find_standard_concepts(
        query='migraine',
        max_exploration_depth=1,
        initial_seed_limit=2,
        max_total_concepts=10,
        max_api_calls=8,
        max_time_seconds=15
    )
    
    print(f'Results: {len(results["direct_matches"])} direct, {len(results["synonym_matches"])} synonyms')
    if 'exploration_stats' in results:
        stats = results['exploration_stats']
        print(f'Stats: {stats["api_calls_made"]} API calls, {stats["time_elapsed_seconds"]:.1f}s')
        print(f'Limits hit: {stats["limits_reached"]}')
    
    # Add assertions to make this a proper test
    assert isinstance(results, dict)
    assert 'direct_matches' in results
    assert 'synonym_matches' in results
    assert 'relationship_matches' in results
    assert 'cross_references' in results 
```

### File: `athena_client/test_url.py`
<a name="athena_client-test_urlpy"></a>
```python
#!/usr/bin/env python3
"""
Simple test to check URL building.
"""
from athena_client import Athena
from athena_client.settings import get_settings

# Check settings
settings = get_settings()
print(f"Base URL from settings: {settings.ATHENA_BASE_URL}")

# Create client
client = Athena()
print(f"Client HTTP base URL: {client.http.base_url}")

# Test URL building
test_url = client.http._build_url("/concepts")
print(f"Built URL for /concepts: {test_url}")

# Test with query parameters
test_url_with_params = client.http._build_url("/concepts?query=aspirin")
print(f"Built URL for /concepts?query=aspirin: {test_url_with_params}") 
```

## Folder: .pytest_cache

### File: `athena_client/.pytest_cache/README.md`
<a name="athena_client-pytest_cache-readmemd"></a>
```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```

## Folder: .pytest_cache/v

## Folder: .pytest_cache/v/cache

## Folder: athena_client

### File: `athena_client/athena_client/__init__.py`
<a name="athena_client-athena_client-__init__py"></a>
```python
"""
athena-client: Production-ready Python SDK for the OHDSI Athena Concepts API
"""

from .client import AthenaClient
from .concept_explorer import ConceptExplorer, create_concept_explorer
from .db.base import DatabaseConnector
from .db.sqlalchemy_connector import SQLAlchemyConnector
from .models import ConceptDetails, ConceptRelationsGraph, ConceptRelationship

Athena = AthenaClient

__version__ = "1.0.5"

__all__ = [
    "Athena",
    "AthenaClient",
    "ConceptDetails",
    "ConceptRelationsGraph",
    "ConceptRelationship",
    "ConceptExplorer",
    "create_concept_explorer",
    "SQLAlchemyConnector",
    "DatabaseConnector",
]

```

### File: `athena_client/athena_client/async_client.py`
<a name="athena_client-athena_client-async_clientpy"></a>
```python
"""
Async HTTP client for the Athena API.

This module provides an asynchronous HTTP client for interacting with the Athena API.
It uses httpx for HTTP requests and provides automatic retry logic, rate limiting,
and error handling.
"""

import json
import logging
from typing import Any, Dict, Optional, Union, cast

try:
    import httpx
except ImportError as err:
    raise AttributeError(
        "httpx is required for the async client. Install with 'pip install httpx'"
    ) from err

try:
    import backoff
except ImportError as err:
    raise ImportError(
        "backoff is required for the async client. Install with 'pip install backoff'"
    ) from err

from .auth import build_headers
from .concept_explorer import create_concept_explorer
from .concept_set import ConceptSetGenerator
from .db.base import DatabaseConnector
from .exceptions import AthenaError, ClientError, NetworkError, ServerError
from .models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
    ConceptSearchResponse,
)
from .search_result import SearchResult
from .settings import get_settings

logger = logging.getLogger(__name__)


class AsyncHttpClient:
    """
    Asynchronous HTTP client for making requests to the Athena API.

    Features:
    - Automatic retry with exponential backoff
    - Custom timeout handling
    - Authentication header generation
    - Error handling and mapping to typed exceptions
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        db_connector: Optional[DatabaseConnector] = None,
    ) -> None:
        """
        Initialize the async HTTP client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
        """
        settings = get_settings()

        # Use provided values or fall back to settings
        self.base_url = base_url or settings.ATHENA_BASE_URL

        # Set up token and HMAC if provided
        if token is not None:
            settings.ATHENA_TOKEN = token
        if client_id is not None:
            settings.ATHENA_CLIENT_ID = client_id
        if private_key is not None:
            settings.ATHENA_PRIVATE_KEY = private_key

        self.timeout = timeout or settings.ATHENA_TIMEOUT_SECONDS
        self.max_retries = max_retries or settings.ATHENA_MAX_RETRIES
        self.backoff_factor = backoff_factor or settings.ATHENA_BACKOFF_FACTOR

        # Create httpx client
        self.client = httpx.AsyncClient(timeout=self.timeout)

        # Set up default headers
        self._setup_default_headers()

    def _setup_default_headers(self) -> None:
        """Set up default headers for all requests."""
        # Set default headers similar to the working client
        default_headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "AthenaOHDSIAPIClient/1.0",
        }

        # Update client headers
        self.client.headers.update(default_headers)

        logger.debug("Default headers set: %s", default_headers)

    def _build_url(self, path: str) -> str:
        """
        Build full URL by joining base URL and path.

        Args:
            path: API endpoint path

        Returns:
            Full URL
        """
        # Handle paths that start with / to ensure they're appended correctly
        if path.startswith("/"):
            # Remove the leading / and join with base_url
            path = path[1:]

        # Ensure base_url doesn't end with / and path doesn't start with /
        if self.base_url.endswith("/"):
            base = self.base_url[:-1]
        else:
            base = self.base_url

        if path.startswith("/"):
            path = path[1:]

        full_url = f"{base}/{path}"

        logger.debug(
            f"Building URL: base_url='{self.base_url}', path='{path}' "
            f"-> full_url='{full_url}'"
        )
        return full_url

    async def _handle_response(self, response: httpx.Response) -> Dict[str, Any]:
        """
        Handle API response and raise appropriate exceptions.

        Args:
            response: HTTP response from httpx

        Returns:
            Parsed JSON response

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
        """
        try:
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            if 400 <= response.status_code < 500:
                raise ClientError(
                    f"Client error: {response.status_code} {response.reason_phrase}",
                    status_code=response.status_code,
                    response=response.text,
                ) from e
            elif response.status_code >= 500:
                raise ServerError(
                    f"Server error: {response.status_code} {response.reason_phrase}",
                    status_code=response.status_code,
                    response=response.text,
                ) from e
            else:
                raise
        except httpx.DecodingError as e:
            raise AthenaError(f"Invalid JSON response: {e}") from e

    @backoff.on_exception(
        backoff.expo,
        (httpx.TimeoutException, httpx.ConnectError),
        max_tries=3,
        factor=0.3,
    )
    async def request(
        self,
        method: str,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        data: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make an HTTP request to the Athena API.

        Args:
            method: HTTP method (GET, POST, etc.)
            path: API endpoint path
            params: Query parameters
            data: Request body data
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
        """
        url = self._build_url(path)
        body_bytes = b""

        # Convert data to JSON bytes if provided
        if data is not None:
            body_bytes = json.dumps(data).encode("utf-8")

        # Build authentication headers
        headers = build_headers(method, url, body_bytes)

        # Add Content-Type header if sending data
        if data is not None:
            headers["Content-Type"] = "application/json"

        # Generate a correlation ID for logging
        correlation_id = f"req-{id(self)}-{id(path)}"
        logger.debug(f"[{correlation_id}] {method} {url}")

        try:
            response = await self.client.request(
                method=method,
                url=url,
                params=params,
                content=body_bytes if data is not None else None,
                headers=headers,
                timeout=self.timeout,
            )

            logger.debug(
                f"[{correlation_id}] {response.status_code} {response.reason_phrase}"
            )

            if raw_response:
                return response

            return await self._handle_response(response)

        except (httpx.TimeoutException, httpx.ConnectError) as e:
            logger.warning(f"[{correlation_id}] Network error: {e}")
            raise NetworkError(f"Network error: {e}") from e

    async def get(
        self,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make a GET request to the Athena API.

        Args:
            path: API endpoint path
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return await self.request("GET", path, params=params, raw_response=raw_response)

    async def post(
        self,
        path: str,
        data: Any = None,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make a POST request to the Athena API.

        Args:
            path: API endpoint path
            data: Request body data
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return await self.request(
            "POST", path, data=data, params=params, raw_response=raw_response
        )


class AthenaAsyncClient:
    """
    Asynchronous client for the Athena API.

    This class provides asynchronous access to all Athena API endpoints
    with minimal abstraction, returning parsed Pydantic models.
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        db_connector: Optional[DatabaseConnector] = None,
    ) -> None:
        """
        Initialize the async Athena client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
            db_connector: Optional database connector for local OMOP validation
        """
        self.http = AsyncHttpClient(
            base_url=base_url,
            token=token,
            client_id=client_id,
            private_key=private_key,
            timeout=timeout,
            max_retries=max_retries,
            backoff_factor=backoff_factor,
        )
        self.db_connector = db_connector

    def set_database_connector(self, connector: DatabaseConnector) -> None:
        """Set the database connector for this client."""

        self.db_connector = connector

    async def search_concepts(
        self,
        query: str = "",
        exact: Optional[str] = None,
        fuzzy: bool = False,
        wildcard: Optional[str] = None,
        boosts: Optional[Dict[str, Any]] = None,
        debug: bool = False,
        page_size: int = 20,
        page: int = 0,
        domain: Optional[str] = None,
        vocabulary: Optional[str] = None,
        standard_concept: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Search for concepts in the Athena vocabulary.

        Args:
            query: The search query string
            exact: Exact match phrase
            fuzzy: Whether to enable fuzzy matching
            wildcard: Wildcard pattern
            boosts: Dictionary of field boosts
            debug: Enable debug mode
            page_size: Number of results per page
            page: Page number (0-indexed)
            domain: Filter by domain
            vocabulary: Filter by vocabulary
            standard_concept: Filter by standard concept status

        Returns:
            Raw API response data
        """
        # Convert page to start parameter that the API expects
        start = page * page_size

        params: Dict[str, Any] = {"pageSize": page_size, "start": start}

        # Add query if provided
        if query:
            params["query"] = query

        # Add filters if provided
        if exact:
            params["exact"] = exact
        if fuzzy:
            params["fuzzy"] = str(fuzzy).lower()
        if wildcard:
            params["wildcard"] = wildcard
        if domain:
            params["domain"] = domain
        if vocabulary:
            params["vocabulary"] = vocabulary
        if standard_concept:
            params["standardConcept"] = standard_concept

        # If boosts provided, use debug endpoint and include boosts in request
        if boosts or debug:
            response = await self.http.post(
                "/concepts",
                data={"boosts": boosts} if boosts else {},
                params=params,
            )
            return cast(Dict[str, Any], response)

        # Otherwise use standard GET endpoint
        response = await self.http.get("/concepts", params=params)
        return cast(Dict[str, Any], response)

    async def search(
        self,
        query: str = "",
        size: int = 20,
        page: int = 0,
        **kwargs: Any,
    ) -> SearchResult:
        """
        Search for concepts with a SearchResult wrapper.

        Args:
            query: The search query string
            size: Number of results per page
            page: Page number (0-indexed)
            **kwargs: Additional search parameters

        Returns:
            SearchResult object with convenient access methods
        """
        # Convert size to pageSize for the API
        search_kwargs: Dict[str, Any] = dict(kwargs)
        search_kwargs["page_size"] = size
        search_kwargs["page"] = page

        response_data = await self.search_concepts(query=query, **search_kwargs)
        response = ConceptSearchResponse.model_validate(response_data)
        return SearchResult(response, self)

    async def details(self, concept_id: int) -> ConceptDetails:
        """
        Get detailed information for a specific concept.

        This is an alias for get_concept_details for compatibility.

        Args:
            concept_id: The concept ID to get details for

        Returns:
            ConceptDetails object
        """
        return await self.get_concept_details(concept_id)

    async def relationships(
        self,
        concept_id: int,
        only_standard: bool = False,
        relationship_id: Optional[str] = None,
    ) -> ConceptRelationship:
        """
        Get relationships for a specific concept.

        This is an alias for get_concept_relationships for compatibility.

        Args:
            concept_id: The concept ID to get relationships for
            only_standard: Only include standard concepts
            relationship_id: Filter by relationship type

        Returns:
            ConceptRelationship object
        """
        return await self.get_concept_relationships(
            concept_id, relationship_id=relationship_id, only_standard=only_standard
        )

    async def get_concept_details(self, concept_id: int) -> ConceptDetails:
        """
        Get detailed information for a specific concept.

        Args:
            concept_id: The concept ID to get details for

        Returns:
            ConceptDetails object
        """
        response = await self.http.get(f"/concepts/{concept_id}")
        data = cast(Dict[str, Any], response)
        return ConceptDetails.model_validate(data)

    async def get_concept_relationships(
        self,
        concept_id: int,
        relationship_id: Optional[str] = None,
        only_standard: bool = False,
    ) -> ConceptRelationship:
        """
        Get relationships for a specific concept.

        Args:
            concept_id: The concept ID to get relationships for
            relationship_id: Filter by relationship type
            only_standard: Only include standard concepts

        Returns:
            ConceptRelationship object
        """
        params: Dict[str, Any] = {}

        if relationship_id:
            params["relationshipId"] = relationship_id
        if only_standard:
            params["standardConcepts"] = "true"

        response = await self.http.get(
            f"/concepts/{concept_id}/relationships", params=params
        )
        data = cast(Dict[str, Any], response)
        return ConceptRelationship.model_validate(data)

    async def get_concept_graph(
        self,
        concept_id: int,
        depth: int = 10,
        zoom_level: int = 4,
    ) -> ConceptRelationsGraph:
        """
        Get relationship graph for a specific concept.

        Args:
            concept_id: The concept ID to get graph for
            depth: Maximum depth of relationships to traverse
            zoom_level: Zoom level for the graph

        Returns:
            ConceptRelationsGraph object
        """
        params = {"depth": depth, "zoomLevel": zoom_level}
        response = await self.http.get(
            f"/concepts/{concept_id}/relations", params=params
        )
        data = cast(Dict[str, Any], response)
        return ConceptRelationsGraph.model_validate(data)

    async def generate_concept_set(self, query: str, **kwargs: Any) -> Dict[str, Any]:
        """Generate a validated concept set from a search query."""

        if not self.db_connector:
            raise RuntimeError("A database connector has not been configured.")

        explorer = create_concept_explorer(self)
        generator = ConceptSetGenerator(explorer=explorer, db=self.db_connector)

        return await generator.create_from_query(query, **kwargs)

```

### File: `athena_client/athena_client/auth.py`
<a name="athena_client-athena_client-authpy"></a>
```python
"""
Authentication module for the Athena client.

This module handles Bearer token and HMAC authentication for the Athena API.
"""

import logging
from base64 import b64encode
from datetime import datetime
from typing import Any, Dict

from .settings import get_settings

logger = logging.getLogger(__name__)


def build_headers(
    method: str,
    url: str,
    body: bytes,
    serialization_module: Any = None,
    hashes_module: Any = None,
) -> Dict[str, str]:
    """
    Build authentication headers for Athena API requests.

    If a token is supplied, adds Bearer authentication.
    If a private key is supplied, adds HMAC signature.

    Args:
        method: HTTP method (GET, POST, etc.)
        url: Full request URL
        body: Request body as bytes

    Returns:
        Dictionary of headers to add to the request
    """
    s = get_settings()

    # Start with empty headers - authentication is optional
    hdrs = {}

    # Add Bearer token if available
    if s.ATHENA_TOKEN:
        hdrs["X-Athena-Auth"] = f"Bearer {s.ATHENA_TOKEN}"
        hdrs["X-Athena-Client-Id"] = s.ATHENA_CLIENT_ID or "athena-client"
        logger.debug("Bearer token authentication headers added")
    else:
        logger.debug("No API token provided; proceeding without Authorization header")

    # Add HMAC signature if private key is available
    if s.ATHENA_PRIVATE_KEY:
        try:
            if serialization_module is None or hashes_module is None:
                from cryptography.hazmat.primitives import hashes, serialization

                serialization_module = serialization
                hashes_module = hashes
        except ImportError:
            logger.warning(
                "cryptography package is required for HMAC signing. "
                "Install with 'pip install \"athena-client[crypto]\"'"
            )
            return hdrs
        try:
            nonce = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
            to_sign = f"{method}\n{url}\n\n{nonce}\n{body.decode()}"
            key = serialization_module.load_pem_private_key(
                s.ATHENA_PRIVATE_KEY.encode(), password=None
            )
            signing_key: Any = key
            sig = signing_key.sign(to_sign.encode(), hashes_module.SHA256())
            hdrs.update(
                {"X-Athena-Nonce": nonce, "X-Athena-Hmac": b64encode(sig).decode()}
            )
            logger.debug("HMAC signature headers added")
        except Exception as e:
            logger.error(f"Error generating HMAC signature: {e}")

    return hdrs

```

### File: `athena_client/athena_client/cli.py`
<a name="athena_client-athena_client-clipy"></a>
```python
"""
Command-line interface for the Athena client.

This module provides a CLI for interacting with the Athena API.
"""

import asyncio
import json
import sys
from typing import Any, Optional

try:
    import click
except ImportError:
    click = None  # type: ignore
    print(
        "The 'click' package is required for the CLI. "
        "Install with 'pip install \"athena-client[cli]\"'"
    )
    sys.exit(1)

try:
    import rich
    from rich.console import Console
    from rich.syntax import Syntax
    from rich.table import Table
except ImportError:
    rich = None  # type: ignore
    Console = None  # type: ignore
    Syntax = None  # type: ignore
    Table = None  # type: ignore

from . import Athena, __version__


def _create_client(
    base_url: Optional[str],
    token: Optional[str],
    timeout: Optional[int],
    retries: Optional[int],
) -> Athena:
    """
    Create an Athena client with the given parameters.

    Args:
        base_url: Base URL for the Athena API
        token: Bearer token for authentication
        timeout: HTTP timeout in seconds
        retries: Maximum number of retry attempts

    Returns:
        Athena client
    """
    return Athena(
        base_url=base_url,
        token=token,
        timeout=timeout,
        max_retries=retries,
    )


def _format_output(data: object, output: str, console: Any = None) -> None:
    """
    Format and print data based on the requested output format.

    Args:
        data: Data to format and print
        output: Output format (json, yaml, table, pretty)
        console: Rich console for pretty printing
    """
    if output == "json":
        if isinstance(data, str):
            print(data)
        else:
            print(json.dumps(data, indent=2))
    elif output == "yaml":
        try:
            import yaml

            print(yaml.dump(data))
        except ImportError:
            print(
                "The 'pyyaml' package is required for YAML output. "
                "Install with 'pip install \"athena-client[yaml]\"'"
            )
            sys.exit(1)
    elif output == "table" and console is not None and rich is not None:
        if hasattr(data, "to_list"):
            # Handle SearchResult
            results = data.to_list()
            if not results:
                console.print("[yellow]No results found[/yellow]")
                return

            table = Table(title="Athena Concepts")

            # Add columns
            table.add_column("ID", style="cyan")
            table.add_column("Name", style="green")
            table.add_column("Code", style="magenta")
            table.add_column("Vocabulary", style="blue")
            table.add_column("Domain", style="yellow")
            table.add_column("Class", style="red")

            # Add rows
            for item in results:
                table.add_row(
                    str(item["id"]),
                    item["name"],
                    item["code"],
                    item["vocabulary"],
                    item["domain"],
                    item["className"],
                )

            console.print(table)
        else:
            # Just pretty-print JSON for other data types
            syntax = Syntax(
                json.dumps(data, indent=2, default=str),
                "json",
                theme="monokai",
                word_wrap=True,
            )
            console.print(syntax)
    elif output == "pretty" and console is not None and rich is not None:
        # Use rich's pretty printing
        console.print(data)
    else:
        # Fall back to regular JSON
        if isinstance(data, str):
            print(data)
        else:
            print(json.dumps(data, indent=2))


@click.group()
@click.version_option(__version__)
@click.option(
    "--base-url",
    envvar="ATHENA_BASE_URL",
    help="Base URL for the Athena API",
)
@click.option(
    "--token",
    envvar="ATHENA_TOKEN",
    help="Bearer token for authentication",
)
@click.option(
    "--timeout",
    type=int,
    envvar="ATHENA_TIMEOUT_SECONDS",
    help="HTTP timeout in seconds",
)
@click.option(
    "--retries",
    type=int,
    envvar="ATHENA_MAX_RETRIES",
    help="Maximum number of retry attempts",
)
@click.option(
    "--output",
    "-o",
    type=click.Choice(["json", "yaml", "table", "pretty"]),
    default="table",
    help="Output format",
)
@click.pass_context
def cli(
    ctx: Any,
    base_url: Optional[str],
    token: Optional[str],
    timeout: Optional[int],
    retries: Optional[int],
    output: str,
) -> None:
    """Athena Client CLI - Interact with the OHDSI Athena API."""
    ctx.ensure_object(dict)
    ctx.obj["base_url"] = base_url
    ctx.obj["token"] = token
    ctx.obj["timeout"] = timeout
    ctx.obj["retries"] = retries
    ctx.obj["output"] = output

    # Set up rich console if available
    if rich is not None:
        ctx.obj["console"] = Console()
    else:
        ctx.obj["console"] = None


@cli.command()
@click.argument("query")
@click.option("--fuzzy/--no-fuzzy", default=False, help="Enable fuzzy matching")
@click.option("--page-size", type=int, default=20, help="Number of results per page")
@click.option("--page", type=int, default=0, help="Page number (0-indexed)")
@click.option("--domain", help="Filter by domain")
@click.option("--vocabulary", help="Filter by vocabulary")
@click.pass_context
def search(
    ctx: Any,
    query: str,
    fuzzy: bool,
    page_size: int,
    page: int,
    domain: Optional[str],
    vocabulary: Optional[str],
) -> None:
    """Search for concepts in the Athena vocabulary."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    results = client.search(
        query,
        fuzzy=fuzzy,
        page_size=page_size,
        page=page,
        domain=domain,
        vocabulary=vocabulary,
    )

    # Get the appropriate output based on the format
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = results.to_json()
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(results.to_list())
    else:
        output_data = results

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command(name="generate-set")
@click.argument("query")
@click.option(
    "--db-connection",
    required=True,
    envvar="OMOP_DB_CONNECTION",
    help="SQLAlchemy connection string for the OMOP database.",
)
@click.option(
    "--strategy",
    type=click.Choice(["fallback", "strict"]),
    default="fallback",
    help="Generation strategy.",
)
@click.option(
    "--no-descendants",
    is_flag=True,
    help="Do not include descendant concepts in the set.",
)
@click.pass_context
def generate_set(
    ctx: Any,
    query: str,
    db_connection: str,
    strategy: str,
    no_descendants: bool,
) -> None:
    """Generate a validated concept set for a given query."""

    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    click.echo(f"Generating concept set for '{query}'...")

    try:
        concept_set = asyncio.run(
            client.generate_concept_set(
                query=query,
                db_connection_string=db_connection,
                strategy=strategy,
                include_descendants=not no_descendants,
            )
        )

        _format_output(concept_set, ctx.obj["output"], ctx.obj.get("console"))

        metadata = concept_set.get("metadata", {})
        if metadata.get("status") == "SUCCESS":
            click.secho(
                f"\nSuccess! Found {len(concept_set.get('concept_ids', []))} concepts.",
                fg="green",
                err=True,
            )
            click.secho(f"Strategy used: {metadata.get('strategy_used')}", err=True)
            for warning in metadata.get("warnings", []):
                click.secho(f"Warning: {warning}", fg="yellow", err=True)
        else:
            click.secho(f"\nFailure: {metadata.get('reason')}", fg="red", err=True)

    except Exception as e:  # pragma: no cover - defensive
        click.secho(f"An unexpected error occurred: {e}", fg="red", err=True)
        sys.exit(1)


@cli.command()
@click.argument("concept_id", type=int)
@click.pass_context
def details(ctx: Any, concept_id: int) -> None:
    """Get detailed information for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.details(concept_id)
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.option("--relationship-id", help="Filter by relationship type")
@click.option(
    "--only-standard/--all", default=False, help="Only include standard concepts"
)
@click.pass_context
def relationships(
    ctx: Any,
    concept_id: int,
    relationship_id: Optional[str],
    only_standard: bool,
) -> None:
    """Get relationships for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.relationships(concept_id)
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.option("--depth", type=int, default=10, help="Maximum depth of relationships")
@click.option("--zoom-level", type=int, default=4, help="Zoom level for the graph")
@click.pass_context
def graph(ctx: Any, concept_id: int, depth: int, zoom_level: int) -> None:
    """Get relationship graph for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.graph(
        concept_id,
        depth=depth,
        zoom_level=zoom_level,
    )
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.pass_context
def summary(ctx: Any, concept_id: int) -> None:
    """Get a comprehensive summary for a concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.summary(concept_id)
    output_data: dict[str, Any] = {}
    for key in ["details", "relationships", "graph"]:
        val = result.get(key)
        if val is None:
            output_data[key] = {}
        elif isinstance(val, dict):
            output_data[key] = val
        elif hasattr(val, "model_dump"):
            output_data[key] = val.model_dump()
        else:
            output_data[key] = val

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


def main() -> None:
    """Entry point for the CLI."""
    cli(obj={})  # pylint: disable=unexpected-keyword-arg


if __name__ == "__main__":
    main()

```

### File: `athena_client/athena_client/client.py`
<a name="athena_client-athena_client-clientpy"></a>
```python
"""
Main client for the Athena API.

This module provides the main client class for interacting with the Athena API.
"""

import logging
import time
from typing import Any, Dict, List, Literal, Optional, Tuple, Union

from .async_client import AthenaAsyncClient
from .db.base import DatabaseConnector
from .db.sqlalchemy_connector import SQLAlchemyConnector
from .exceptions import APIError, AthenaError
from .http import HttpClient
from .models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
    ConceptSearchResponse,
)
from .query import Q
from .search_result import SearchResult
from .settings import get_settings

logger = logging.getLogger(__name__)


class AthenaClient:
    """Main client for interacting with the Athena API."""

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        retry_delay: Optional[float] = None,
        enable_throttling: bool = True,
        throttle_delay_range: Tuple[float, float] = (0.1, 0.3),
        db_connector: Optional[DatabaseConnector] = None,
        **kwargs: Any,
    ) -> None:
        """Initialize the Athena client.

        Args:
            base_url: Base URL for the Athena API
            token: Authentication token
            timeout: Request timeout in seconds
            max_retries: Maximum number of retries for network errors
            retry_delay: Delay between retry attempts in seconds
                (overrides backoff_factor)
            enable_throttling: Whether to throttle requests to be respectful
                to the server
            throttle_delay_range: Range of delays for throttling (min, max)
                in seconds
            db_connector: Optional database connector for local OMOP validation
            **kwargs: Additional settings
        """
        s = get_settings()

        # Configure retry settings
        self.max_retries = max_retries or s.ATHENA_MAX_RETRIES
        self.retry_delay = retry_delay
        self.enable_throttling = enable_throttling
        self.throttle_delay_range = throttle_delay_range
        self._db_connector = db_connector

        # Create HTTP client with enhanced configuration
        self.http = HttpClient(
            base_url=base_url or s.ATHENA_BASE_URL,
            token=token or s.ATHENA_TOKEN,
            timeout=timeout or s.ATHENA_TIMEOUT_SECONDS,
            max_retries=self.max_retries,
            enable_throttling=self.enable_throttling,
            throttle_delay_range=self.throttle_delay_range,
            **kwargs,
        )

        logger.info(
            f"Athena client initialized: "
            f"max_retries={self.max_retries}, "
            f"retry_delay={self.retry_delay}, "
            f"throttling={'enabled' if self.enable_throttling else 'disabled'}"
        )

    def set_database_connector(self, connector: DatabaseConnector) -> None:
        """Set the database connector for this client."""

        self._db_connector = connector

    def validate_local_concepts(self, concept_ids: List[int]) -> List[int]:
        """Validate concept IDs against the configured local database."""

        if not self._db_connector:
            raise RuntimeError(
                "A database connector has not been configured. Use "
                "`set_database_connector()` to provide one."
            )

        return self._db_connector.validate_concepts(concept_ids)

    def search(
        self,
        query: Union[str, Q],
        page: int = 0,
        size: int = 20,
        auto_retry: bool = True,
        max_retries: Optional[int] = None,
        retry_delay: Optional[float] = None,
        show_progress: Optional[bool] = None,
        **kwargs: Any,
    ) -> SearchResult:
        """
        Search for concepts with automatic error handling and recovery.

        Args:
            query: Search query string or Query DSL object
            page: Page number (0-based)
            size: Page size
            auto_retry: Whether to automatically retry on recoverable errors
            max_retries: Override max retries for this call
            retry_delay: Override retry delay for this call
            show_progress: Whether to show progress for large queries
            **kwargs: Additional search parameters

        Returns:
            SearchResult object with concepts

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """

        from .exceptions import RetryFailedError
        from .settings import get_settings
        from .utils import (
            estimate_query_size,
            format_large_query_warning,
            get_operation_timeout,
            progress_context,
        )

        settings = get_settings()

        if isinstance(query, Q):
            query_str = str(query)
        else:
            query_str = query

        # Estimate query size and provide warnings for large queries
        estimated_size = estimate_query_size(query_str)
        warning = format_large_query_warning(query_str, estimated_size)
        if warning:
            print(warning)

        # Use settings default page size if not specified
        if size == 20 and "pageSize" not in kwargs:
            size = settings.ATHENA_DEFAULT_PAGE_SIZE

        # Validate page size
        if size > settings.ATHENA_MAX_PAGE_SIZE:
            raise ValueError(
                f"Page size {size} exceeds maximum allowed size of "
                f"{settings.ATHENA_MAX_PAGE_SIZE}. Please use a smaller page size."
            )

        # Convert page/size to pageSize/start parameters that the API expects
        page_size = size
        start = page * size  # Calculate start offset

        params = {
            "query": query_str,
            "pageSize": page_size,
            "start": start,
            **kwargs,
        }

        # Configure retry settings for this call
        max_attempts = max(
            1,
            max_retries
            if max_retries is not None
            else (self.max_retries if auto_retry else 1),
        )

        # Get appropriate timeout for this operation
        operation_timeout = get_operation_timeout("search", estimated_size)

        # Set up progress tracking if enabled
        progress_kwargs: Optional[Dict[str, Any]] = None
        if show_progress:
            progress_kwargs = {
                "total": estimated_size,
                "description": f"Searching for '{query_str}'",
                "show_progress": show_progress,
                "update_interval": settings.ATHENA_PROGRESS_UPDATE_INTERVAL,
            }

        retry_history: list[Exception] = []
        with progress_context(**progress_kwargs) if progress_kwargs else nullcontext():
            for attempt in range(max_attempts):
                try:
                    # Create a temporary HTTP client with the appropriate timeout
                    temp_http = HttpClient(
                        base_url=self.http.base_url,
                        token=str(self.http.session.headers.get("Authorization", "")),
                        timeout=operation_timeout,
                        max_retries=1,  # We handle retries manually
                        enable_throttling=self.http.enable_throttling,
                        throttle_delay_range=self.http.throttle_delay_range,
                    )

                    response = temp_http.get("/concepts", params=params)

                    # Raise APIError for any error response with errorMessage
                    # and errorCode
                    if (
                        isinstance(response, dict)
                        and response.get("result") is None
                        and "errorMessage" in response
                        and "errorCode" in response
                    ):
                        error_msg = response.get("errorMessage", "Unknown API error")
                        error_code = response.get("errorCode")

                        # Enhanced error messages for large queries
                        if "timeout" in error_msg.lower():
                            raise APIError(
                                f"Search timeout: The query '{query_str}' "
                                f"is taking too long to process. "
                                f"Try:\n"
                                f"‚Ä¢ Using more specific search terms\n"
                                f"‚Ä¢ Adding domain or vocabulary filters\n"
                                f"‚Ä¢ Reducing the page size\n"
                                f"‚Ä¢ Breaking the query into smaller parts",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Page size must not be less than one" in error_msg:
                            raise APIError(
                                f"Invalid page size: {error_msg}. "
                                f"Please use a page size of 1 or greater.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Page size must not be greater than" in error_msg:
                            raise APIError(
                                f"Page size too large: {error_msg}. "
                                f"Please reduce the page size to "
                                f"{settings.ATHENA_MAX_PAGE_SIZE} or less.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Query must not be blank" in error_msg:
                            raise APIError(
                                f"Empty search query: {error_msg}. "
                                f"Please provide a search term.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        else:
                            raise APIError(
                                f"Search failed: {error_msg}",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )

                    search_response = ConceptSearchResponse.model_validate(response)
                    return SearchResult(search_response, self)

                except Exception as e:
                    if isinstance(e, APIError):
                        # API errors are not retryable, raise immediately
                        raise

                    # For network errors, retry if we have attempts left
                    if attempt < max_attempts - 1:
                        logger.info(
                            f"Retrying search due to {type(e).__name__} "
                            f"(attempt {attempt + 1}/{max_attempts}): {e}"
                        )
                        if retry_delay is not None:
                            time.sleep(retry_delay)
                        elif self.retry_delay is not None:
                            time.sleep(self.retry_delay)
                        retry_history.append(e)
                        continue
                    else:
                        # Final attempt failed, raise with retry history
                        raise RetryFailedError(
                            f"Search failed after {max_attempts} attempts",
                            retry_history=retry_history,
                            max_attempts=max_attempts,
                            last_error=e,
                        ) from e
            raise RuntimeError("Unreachable code in search")

    def details(self, concept_id: int, auto_retry: bool = True) -> ConceptDetails:
        """
        Get detailed information about a concept with automatic error handling.

        Args:
            concept_id: Concept ID
            auto_retry: Whether to automatically retry on recoverable errors

        Returns:
            ConceptDetails object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        max_attempts = 3 if auto_retry else 1

        for attempt in range(max_attempts):
            try:
                response = self.http.get(f"/concepts/{concept_id}")

                # Check if the response is an error response
                if (
                    isinstance(response, dict)
                    and response.get("result") is None
                    and "errorMessage" in response
                ):
                    error_msg = response.get("errorMessage", "Unknown API error")
                    error_code = response.get("errorCode")

                    # Provide more specific error messages for concept details
                    if "Unable to find" in error_msg and "ConceptV5" in error_msg:
                        raise APIError(
                            f"Concept not found: Concept ID {concept_id} "
                            f"does not exist in the database. "
                            f"Please verify the concept ID is correct.",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )
                    else:
                        raise APIError(
                            f"Failed to get concept details: {error_msg}",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )

                return ConceptDetails.model_validate(response)

            except Exception as e:
                if isinstance(e, APIError):
                    # API errors are not retryable, raise immediately
                    raise
                elif attempt < max_attempts - 1:
                    # For other errors, retry if we have attempts left
                    logger.info(
                        f"Retrying concept details due to error "
                        f"(attempt {attempt + 1}/{max_attempts}): {e}"
                    )
                    continue
                else:
                    # Final attempt failed, raise with enhanced message
                    raise AthenaError(
                        f"Failed to get concept details after {max_attempts} attempts. "
                        f"Last error: {e}",
                        error_code="RETRY_FAILED",
                        troubleshooting=(
                            "‚Ä¢ Check your internet connection\n"
                            "‚Ä¢ Try again in a few moments\n"
                            "‚Ä¢ Contact support if the problem persists"
                        ),
                    ) from e
        raise RuntimeError("Unreachable code in details")

    def relationships(
        self, concept_id: int, auto_retry: bool = True
    ) -> ConceptRelationship:
        """
        Get relationships for a concept with automatic error handling.

        Args:
            concept_id: Concept ID
            auto_retry: Whether to automatically retry on recoverable errors

        Returns:
            ConceptRelationship object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        max_attempts = 3 if auto_retry else 1

        for attempt in range(max_attempts):
            try:
                response = self.http.get(f"/concepts/{concept_id}/relationships")

                # Check if the response is an error response
                if (
                    isinstance(response, dict)
                    and response.get("result") is None
                    and "errorMessage" in response
                ):
                    error_msg = response.get("errorMessage", "Unknown API error")
                    error_code = response.get("errorCode")

                    # Provide more specific error messages for relationships
                    if "Unable to find" in error_msg and "ConceptV5" in error_msg:
                        raise APIError(
                            f"Concept not found: Concept ID {concept_id} "
                            f"does not exist in the database. "
                            f"Please verify the concept ID is correct.",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )
                    else:
                        raise APIError(
                            f"Failed to get relationships: {error_msg}",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )

                return ConceptRelationship.model_validate(response)

            except Exception as e:
                if isinstance(e, APIError):
                    # API errors are not retryable, raise immediately
                    raise
                elif attempt < max_attempts - 1:
                    # For other errors, retry if we have attempts left
                    logger.info(
                        f"Retrying relationships due to error "
                        f"(attempt {attempt + 1}/{max_attempts}): {e}"
                    )
                    continue
                else:
                    # Final attempt failed, raise with enhanced message
                    raise AthenaError(
                        f"Failed to get relationships after {max_attempts} attempts. "
                        f"Last error: {e}",
                        error_code="RETRY_FAILED",
                        troubleshooting=(
                            "‚Ä¢ Check your internet connection\n"
                            "‚Ä¢ Try again in a few moments\n"
                            "‚Ä¢ Contact support if the problem persists"
                        ),
                    ) from e
        raise RuntimeError("Unreachable code in relationships")

    def graph(
        self,
        concept_id: int,
        depth: int = 2,
        zoom_level: int = 2,
        auto_retry: bool = True,
        show_progress: Optional[bool] = None,
        **kwargs: Any,
    ) -> ConceptRelationsGraph:
        """
        Get concept relationship graph with automatic error handling.

        Args:
            concept_id: Concept ID
            depth: Graph depth
            zoom_level: Zoom level
            auto_retry: Whether to automatically retry on recoverable errors
            show_progress: Whether to show progress for large graph operations
            **kwargs: Additional parameters

        Returns:
            ConceptRelationsGraph object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        from .settings import get_settings
        from .utils import get_operation_timeout, progress_context

        settings = get_settings()

        # Estimate graph complexity based on depth and zoom level
        estimated_complexity = depth * zoom_level * 100  # Rough estimate

        # Provide warning for complex graphs
        if depth > 3 or zoom_level > 3:
            print(f"‚ö†Ô∏è  Complex graph request: depth={depth}, zoom_level={zoom_level}")
            print(
                "üí° This may take several minutes to complete. "
                "Consider reducing depth or zoom level."
            )

        params = {
            "depth": depth,
            "zoomLevel": zoom_level,
            **kwargs,
        }

        max_attempts = 3 if auto_retry else 1

        # Get appropriate timeout for graph operations
        operation_timeout = get_operation_timeout("graph", estimated_complexity)

        # Set up progress tracking if enabled
        progress_kwargs: Optional[Dict[str, Any]] = None
        if show_progress:
            progress_kwargs = {
                "total": estimated_complexity,
                "description": (
                    f"Building graph for concept {concept_id} "
                    f"(depth={depth}, zoom={zoom_level})"
                ),
                "show_progress": show_progress,
                "update_interval": settings.ATHENA_PROGRESS_UPDATE_INTERVAL,
            }

        with progress_context(**progress_kwargs) if progress_kwargs else nullcontext():
            for attempt in range(max_attempts):
                try:
                    # Create a temporary HTTP client with the appropriate timeout
                    temp_http = HttpClient(
                        base_url=self.http.base_url,
                        token=str(self.http.session.headers.get("Authorization", "")),
                        timeout=operation_timeout,
                        max_retries=1,  # We handle retries manually
                        enable_throttling=self.http.enable_throttling,
                        throttle_delay_range=self.http.throttle_delay_range,
                    )

                    response = temp_http.get(
                        f"/concepts/{concept_id}/relations", params=params
                    )

                    # Check if the response is an error response
                    if (
                        isinstance(response, dict)
                        and response.get("result") is None
                        and "errorMessage" in response
                    ):
                        error_msg = response.get("errorMessage", "Unknown API error")
                        error_code = response.get("errorCode")

                        # Enhanced error messages for graph operations
                        if "timeout" in error_msg.lower():
                            raise APIError(
                                f"Graph timeout: The graph for concept {concept_id} "
                                f"is too complex. "
                                f"Try:\n"
                                f"‚Ä¢ Reducing the depth (currently {depth})\n"
                                f"‚Ä¢ Reducing the zoom level (currently {zoom_level})\n"
                                f"‚Ä¢ Using a simpler concept as the starting point\n"
                                f"‚Ä¢ Breaking the request into smaller parts",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Unable to find" in error_msg and "ConceptV5" in error_msg:
                            raise APIError(
                                f"Concept not found: Concept ID {concept_id} "
                                f"does not exist in the database. "
                                f"Please verify the concept ID is correct.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        else:
                            raise APIError(
                                f"Failed to get concept graph: {error_msg}",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )

                    return ConceptRelationsGraph.model_validate(response)

                except Exception as e:
                    if isinstance(e, APIError):
                        # API errors are not retryable, raise immediately
                        raise
                    elif attempt < max_attempts - 1:
                        # For other errors, retry if we have attempts left
                        logger.info(
                            f"Retrying graph due to error "
                            f"(attempt {attempt + 1}/{max_attempts}): {e}"
                        )
                        continue
                    else:
                        # Final attempt failed, raise with enhanced message
                        raise AthenaError(
                            f"Failed to get concept graph after {max_attempts} "
                            f"attempts. "
                            f"Last error: {e}",
                            error_code="RETRY_FAILED",
                            troubleshooting=(
                                "‚Ä¢ Check your internet connection\n"
                                "‚Ä¢ Try again in a few moments\n"
                                "‚Ä¢ Consider reducing graph depth or zoom level\n"
                                "‚Ä¢ Contact support if the problem persists"
                            ),
                        ) from e
            raise RuntimeError("Unreachable code in graph")

    def summary(
        self,
        concept_id: int,
        include_relationships: bool = True,
        include_graph: bool = True,
    ) -> Dict[str, Any]:
        """Get a comprehensive summary of a concept.

        Args:
            concept_id: Concept ID
            include_relationships: Whether to include relationships
            include_graph: Whether to include graph data

        Returns:
            Dictionary containing concept summary

        Raises:
            AthenaError: If any request fails
        """
        summary = {}

        # Get basic details
        try:
            details = self.details(concept_id)
            summary["details"] = details.model_dump()
        except Exception as e:
            summary["details"] = {"error": str(e)}

        # Get relationships if requested
        if include_relationships:
            try:
                relationships = self.relationships(concept_id)
                summary["relationships"] = relationships.model_dump()
            except Exception as e:
                summary["relationships"] = {"error": str(e)}

        # Get graph if requested
        if include_graph:
            try:
                graph = self.graph(concept_id)
                summary["graph"] = graph.model_dump()
            except Exception as e:
                summary["graph"] = {"error": str(e)}

        return summary

    async def generate_concept_set(
        self,
        query: str,
        db_connection_string: str,
        strategy: str = "fallback",
        include_descendants: bool = True,
        confidence_threshold: float = 0.7,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Generate a validated concept set using the async client."""

        async_client = AthenaAsyncClient(
            base_url=self.http.base_url,
            token=str(self.http.session.headers.get("Authorization", "")),
        )

        db_connector = SQLAlchemyConnector.from_connection_string(db_connection_string)
        async_client.set_database_connector(db_connector)

        return await async_client.generate_concept_set(
            query,
            strategy=strategy,
            include_descendants=include_descendants,
            confidence_threshold=confidence_threshold,
            **kwargs,
        )


class Athena(AthenaClient):
    """Alias for AthenaClient for backward compatibility."""

    pass


class nullcontext:
    """Context manager that does nothing."""

    def __enter__(self) -> None:
        return None

    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> Literal[False]:
        return False

```

### File: `athena_client/athena_client/concept_explorer.py`
<a name="athena_client-athena_client-concept_explorerpy"></a>
```python
"""
Advanced concept exploration and mapping utilities.

This module provides tools to help find standard concepts that might not appear
directly in search results, including:
- Concept relationship exploration
- Synonym-based concept discovery
- Vocabulary mapping and cross-references
- Standard concept identification
- Concept hierarchy exploration
"""

import asyncio
import logging
from collections import deque
from dataclasses import dataclass, field
from typing import Any, Deque, Dict, List, Optional, Set, Union

from .models import Concept, ConceptDetails

logger = logging.getLogger(__name__)


@dataclass
class ExplorationState:
    """
    Internal state management for concept exploration runs.

    This dataclass manages the state of a single exploration run to avoid
    passing multiple state variables through method calls.
    """

    queue: Deque[Any] = field(
        default_factory=deque
    )  # BFS queue: (concept, depth, path)
    visited_ids: Set[int] = field(default_factory=set)  # Set of processed concept IDs
    cache: Dict[int, ConceptDetails] = field(
        default_factory=dict
    )  # In-memory cache for concept details
    results: Dict[str, Any] = field(
        default_factory=lambda: {
            "direct_matches": [],
            "synonym_matches": [],
            "relationship_matches": [],
            "cross_references": [],
            "exploration_paths": [],
        }
    )  # Final results structure
    api_call_count: int = 0  # Count of API calls made
    start_time: float = 0  # Start time of exploration
    max_total_concepts: int = 0  # Maximum total concepts to discover
    max_api_calls: int = 0  # Maximum API calls to make
    max_time_seconds: int = 0  # Maximum time to run exploration

    def __post_init__(self) -> None:
        """Initialize default values for dataclass fields."""
        pass  # All defaults handled by field()


class ConceptExplorer:
    """
    Advanced concept exploration and mapping utilities.

    This class provides methods to help discover standard concepts that might
    not appear directly in search results by exploring relationships, synonyms,
    and cross-references using an optimized BFS algorithm with concurrent processing.
    """

    def __init__(self, client: Any) -> None:
        """Initialize the concept explorer with an Athena client.

        Args:
            client: Athena client instance (can be sync or async)
        """
        self.client = client

    async def find_standard_concepts(
        self,
        query: str,
        max_exploration_depth: int = 2,
        initial_seed_limit: int = 10,  # New parameter per FSD
        include_synonyms: bool = True,
        include_relationships: bool = True,
        vocabulary_priority: Optional[List[str]] = None,
        max_total_concepts: int = 100,  # Limit total concepts found
        max_api_calls: int = 50,  # Limit total API calls
        max_time_seconds: int = 30,  # Limit total execution time
    ) -> Dict[str, Any]:
        """
        Find standard concepts related to a query through exploration.

        This method implements a BFS-based exploration algorithm with concurrent
        batch processing for optimal performance.

        Args:
            query: The search query
            max_exploration_depth: Maximum depth to explore relationships
            initial_seed_limit: Maximum number of top search results to use as seeds
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
            vocabulary_priority: Preferred vocabularies (e.g., ['SNOMED', 'RxNorm'])
            max_total_concepts: Maximum total concepts to discover
            max_api_calls: Maximum API calls to make
            max_time_seconds: Maximum time to run exploration

        Returns:
            Dictionary containing standard concepts found through exploration
        """
        # Validate parameters
        if max_exploration_depth < 0:
            raise ValueError("max_exploration_depth must be non-negative")
        if initial_seed_limit < 1:
            raise ValueError("initial_seed_limit must be at least 1")
        if max_total_concepts < 1:
            raise ValueError("max_total_concepts must be at least 1")
        if max_api_calls < 1:
            raise ValueError("max_api_calls must be at least 1")
        if max_time_seconds < 1:
            raise ValueError("max_time_seconds must be at least 1")

        # Initialize exploration state with limits
        state = ExplorationState()
        state.api_call_count = 0
        state.start_time = asyncio.get_event_loop().time()
        state.max_total_concepts = max_total_concepts
        state.max_api_calls = max_api_calls
        state.max_time_seconds = max_time_seconds

        # Step 1: Initial search and seeding
        logger.info(f"Performing direct search for: {query}")
        direct_results = await self.client.search(query, size=50)
        state.api_call_count += 1
        all_direct_matches = direct_results.all()
        state.results["direct_matches"] = all_direct_matches

        # Take top initial_seed_limit results as seeds
        seed_concepts = all_direct_matches[:initial_seed_limit]
        logger.info(f"Using {len(seed_concepts)} concepts as exploration seeds")

        # Add seed concepts to queue and mark as visited
        for concept in seed_concepts:
            state.queue.append((concept, 0, [concept.id]))
            state.visited_ids.add(concept.id)

        # Step 2: Main BFS traversal loop
        await self._bfs_exploration_loop(
            state,
            max_exploration_depth,
            include_synonyms,
            include_relationships,
            vocabulary_priority,
        )

        # Step 3: Find cross-references (with limits)
        if state.api_call_count < state.max_api_calls:
            logger.info("Finding cross-references")
            cross_refs = await self._find_cross_references(
                all_direct_matches, vocabulary_priority, state
            )
            state.results["cross_references"] = cross_refs

        # Add exploration statistics
        elapsed_time = asyncio.get_event_loop().time() - state.start_time
        state.results["exploration_stats"] = {
            "total_concepts_found": len(state.visited_ids),
            "api_calls_made": state.api_call_count,
            "time_elapsed_seconds": elapsed_time,
            "limits_reached": {
                "max_concepts": len(state.visited_ids) >= max_total_concepts,
                "max_api_calls": state.api_call_count >= max_api_calls,
                "max_time": elapsed_time >= max_time_seconds,
            },
        }

        return state.results

    async def _bfs_exploration_loop(
        self,
        state: ExplorationState,
        max_exploration_depth: int,
        include_synonyms: bool,
        include_relationships: bool,
        vocabulary_priority: Optional[List[str]] = None,
    ) -> None:
        """
        Main BFS exploration loop with concurrent batch processing.

        Args:
            state: Exploration state object
            max_exploration_depth: Maximum exploration depth
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
            vocabulary_priority: Preferred vocabularies
        """
        while state.queue:
            # Check limits before processing
            current_time = asyncio.get_event_loop().time()
            elapsed_time = current_time - state.start_time

            # Check if we've hit any limits
            if (
                len(state.visited_ids) >= state.max_total_concepts
                or state.api_call_count >= state.max_api_calls
                or elapsed_time >= state.max_time_seconds
            ):
                logger.info("Exploration stopped due to limits:")
                logger.info(
                    f"  - Concepts found: {len(state.visited_ids)}/"
                    f"{state.max_total_concepts}"
                )
                logger.info(
                    f"  - API calls made: {state.api_call_count}/{state.max_api_calls}"
                )
                logger.info(
                    f"  - Time elapsed: {elapsed_time:.1f}s/{state.max_time_seconds}s"
                )
                break

            # Process all nodes at current depth level
            level_size = len(state.queue)
            ids_to_fetch_details: Set[int] = set()

            logger.info(f"Processing {level_size} concepts at current depth level")

            # Process all nodes at current depth
            for _ in range(level_size):
                # Check limits again in case we've hit them during processing
                if (
                    len(state.visited_ids) >= state.max_total_concepts
                    or state.api_call_count >= state.max_api_calls
                    or asyncio.get_event_loop().time() - state.start_time
                    >= state.max_time_seconds
                ):
                    break

                concept, depth, path = state.queue.popleft()

                # Skip if we've reached max depth
                if depth >= max_exploration_depth:
                    continue

                # Discover neighbors (synonyms and relationships)
                await self._discover_neighbors(
                    concept,
                    depth,
                    path,
                    state,
                    ids_to_fetch_details,
                    include_synonyms,
                    include_relationships,
                )

            # Batch fetch details for all discovered concepts
            if ids_to_fetch_details and state.api_call_count < state.max_api_calls:
                await self._process_batch_results(
                    ids_to_fetch_details, state, depth + 1, vocabulary_priority
                )

    async def _discover_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
        include_synonyms: bool,
        include_relationships: bool,
    ) -> None:
        """
        Discover neighboring concepts through synonyms and relationships.

        Args:
            concept: Current concept being explored
            depth: Current exploration depth
            path: Path taken to reach this concept
            state: Exploration state
            ids_to_fetch_details: Set to collect IDs for batch fetching
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
        """
        # Explore synonyms if enabled
        if include_synonyms:
            await self._discover_synonym_neighbors(
                concept, depth, path, state, ids_to_fetch_details
            )

        # Explore relationships if enabled
        if include_relationships:
            await self._discover_relationship_neighbors(
                concept, depth, path, state, ids_to_fetch_details
            )

    async def _discover_synonym_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
    ) -> None:
        """Discover neighboring concepts through synonyms."""
        if concept.standardConcept == "Standard":
            # For standard concepts, search for synonyms
            try:
                # Check API call limit
                if state.api_call_count >= state.max_api_calls:
                    return

                synonym_results = await self.client.search(concept.name, size=10)
                state.api_call_count += 1

                for synonym_concept in synonym_results.all():
                    if (
                        synonym_concept.id not in state.visited_ids
                        and len(state.visited_ids) < state.max_total_concepts
                    ):
                        ids_to_fetch_details.add(synonym_concept.id)

            except Exception as e:
                logger.warning(
                    f"Could not generate suggestions for query '{concept.name}': {e}"
                )

    async def _discover_relationship_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
    ) -> None:
        """Discover neighboring concepts through relationships."""
        try:
            # Check API call limit
            if state.api_call_count >= state.max_api_calls:
                return

            relationships = await self.client.relationships(
                concept.id, only_standard=True
            )
            state.api_call_count += 1

            for group in relationships.items:
                for rel in group.relationships:
                    if (
                        rel.targetConceptId not in state.visited_ids
                        and len(state.visited_ids) < state.max_total_concepts
                    ):
                        ids_to_fetch_details.add(rel.targetConceptId)

        except Exception as e:
            logger.warning(f"Could not get relationships for concept {concept.id}: {e}")

    async def _process_batch_results(
        self,
        ids_to_fetch_details: Set[int],
        state: ExplorationState,
        next_depth: int,
        vocabulary_priority: Optional[List[str]] = None,
    ) -> None:
        """Process batch results and add to queue."""
        if not ids_to_fetch_details:
            return

        # Check API call limit
        if state.api_call_count >= state.max_api_calls:
            return

        try:
            # Batch fetch concept details
            concept_details_list = await self._get_details_batch_async(
                ids_to_fetch_details
            )
            state.api_call_count += 1

            # Process each concept detail
            for concept_details in concept_details_list:
                if isinstance(concept_details, BaseException):
                    continue

                # Now we know it's a ConceptDetails object
                concept_details_obj = concept_details  # type: ConceptDetails

                # Convert to Concept object
                concept = Concept(
                    id=concept_details_obj.id,
                    name=concept_details_obj.name,
                    domain=concept_details_obj.domainId,
                    vocabulary=concept_details_obj.vocabularyId,
                    className=concept_details_obj.conceptClassId,
                    standardConcept=concept_details_obj.standardConcept,
                    code=concept_details_obj.conceptCode,
                    invalidReason=concept_details_obj.invalidReason,
                    score=None,  # No score available from concept details
                )

                # Add to appropriate result category
                if concept.standardConcept == "Standard":
                    if concept not in state.results["synonym_matches"]:
                        state.results["synonym_matches"].append(concept)
                else:
                    if concept not in state.results["relationship_matches"]:
                        state.results["relationship_matches"].append(concept)

                # Add to queue for further exploration if within limits
                if (
                    len(state.visited_ids) < state.max_total_concepts
                    and concept.id not in state.visited_ids
                ):
                    # Create a simple path for this concept
                    new_path = [concept.id]
                    state.queue.append((concept, next_depth, new_path))
                    state.visited_ids.add(concept.id)

        except Exception as e:
            logger.warning(f"Error processing batch results: {e}")

    async def _get_details_batch_async(
        self, concept_ids: Set[int]
    ) -> List[Union[ConceptDetails, BaseException]]:
        """
        Fetch concept details for multiple IDs concurrently.

        Args:
            concept_ids: Set of concept IDs to fetch details for

        Returns:
            List of ConceptDetails objects or Exception objects for failed requests
        """
        if not (
            hasattr(self.client, "get_concept_details")
            and asyncio.iscoroutinefunction(self.client.get_concept_details)
        ):
            raise NotImplementedError("Async client not available")

        # Create tasks for concurrent execution
        tasks = [
            self.client.get_concept_details(concept_id) for concept_id in concept_ids
        ]

        # Execute all tasks concurrently with exception handling
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results

    def _extract_standard_concepts(
        self, concepts: List[Concept], vocabulary_priority: Optional[List[str]] = None
    ) -> List[Concept]:
        """Extract standard concepts from a list of concepts."""
        standard_concepts = []

        for concept in concepts:
            if concept.standardConcept == "Standard":
                standard_concepts.append(concept)

        # Sort by vocabulary priority if specified
        if vocabulary_priority:

            def sort_key(concept: Concept) -> int:
                try:
                    return vocabulary_priority.index(concept.vocabulary)
                except ValueError:
                    return len(vocabulary_priority)

            standard_concepts.sort(key=sort_key)

        return standard_concepts

    async def _find_cross_references(
        self,
        concepts: List[Concept],
        vocabulary_priority: Optional[List[str]] = None,
        state: Optional[ExplorationState] = None,
    ) -> List[Dict[str, Any]]:
        """Find cross-references between concepts."""
        cross_refs = []

        for concept in concepts:
            if concept.standardConcept == "Standard":
                # Look for related concepts in other vocabularies
                try:
                    # Check API call limit
                    if state and state.api_call_count >= state.max_api_calls:
                        break

                    relationships = await self.client.relationships(
                        concept.id, only_standard=True
                    )
                    if state:
                        state.api_call_count += 1

                    for group in relationships.items:
                        for rel in group.relationships:
                            cross_ref = {
                                "source_concept": concept,
                                "target_concept_id": rel.targetConceptId,
                                "target_concept_name": rel.targetConceptName,
                                "relationship_type": rel.relationshipName,
                                "vocabulary": rel.targetVocabularyId,
                            }
                            cross_refs.append(cross_ref)

                except Exception as e:
                    logger.warning(
                        f"Could not get relationships for concept {concept.id}: {e}"
                    )

        return cross_refs

    async def map_to_standard_concepts(
        self,
        query: str,
        target_vocabularies: Optional[List[str]] = None,
        confidence_threshold: float = 0.5,
    ) -> List[Dict[str, Any]]:
        """
        Map a query to standard concepts with confidence scores.

        This method is now async to support the new async find_standard_concepts.

        Args:
            query: The search query
            target_vocabularies: Preferred target vocabularies
            confidence_threshold: Minimum confidence score for inclusion

        Returns:
            List of mapping results with confidence scores
        """
        # Get exploration results
        exploration_results = await self.find_standard_concepts(query)

        # Collect all standard concepts
        all_standard_concepts = []
        all_standard_concepts.extend(exploration_results["direct_matches"])
        all_standard_concepts.extend(exploration_results["synonym_matches"])
        all_standard_concepts.extend(exploration_results["relationship_matches"])

        # Filter by target vocabularies if specified
        if target_vocabularies:
            all_standard_concepts = [
                concept
                for concept in all_standard_concepts
                if concept.vocabulary in target_vocabularies
            ]

        # Calculate confidence scores and create mappings
        mappings = []
        for concept in all_standard_concepts:
            confidence = self._calculate_mapping_confidence(
                query, concept, exploration_results
            )

            if confidence >= confidence_threshold:
                mapping = {
                    "concept": concept,
                    "confidence": confidence,
                    "exploration_path": self._get_exploration_path(
                        concept, exploration_results
                    ),
                    "source_category": self._get_source_category(
                        concept, exploration_results
                    ),
                }
                mappings.append(mapping)

        # Sort by confidence score (descending)
        mappings.sort(key=lambda x: x["confidence"], reverse=True)

        return mappings

    def _calculate_mapping_confidence(
        self, query: str, concept: Concept, exploration_results: Dict[str, Any]
    ) -> float:
        """Calculate confidence score for a concept mapping."""
        confidence = 0.0

        # Base confidence from search score if available
        if concept.score is not None:
            confidence += concept.score * 0.4

        # Boost for direct matches
        if concept in exploration_results["direct_matches"]:
            confidence += 0.3

        # Boost for synonym matches
        if concept in exploration_results["synonym_matches"]:
            confidence += 0.2

        # Boost for relationship matches
        if concept in exploration_results["relationship_matches"]:
            confidence += 0.1

        # Vocabulary preference boost
        if concept.vocabulary in ["SNOMED", "RxNorm"]:
            confidence += 0.1

        return min(confidence, 1.0)

    def _get_exploration_path(
        self, concept: Concept, exploration_results: Dict[str, Any]
    ) -> str:
        """Get the exploration path that led to this concept."""
        if concept in exploration_results["direct_matches"]:
            return "direct_search"
        elif concept in exploration_results["synonym_matches"]:
            return "synonym_exploration"
        elif concept in exploration_results["relationship_matches"]:
            return "relationship_exploration"
        else:
            return "unknown"

    def _get_source_category(
        self, concept: Concept, exploration_results: Dict[str, Any]
    ) -> str:
        """Get the source category for a concept."""
        if concept in exploration_results["direct_matches"]:
            return "direct_match"
        elif concept in exploration_results["synonym_matches"]:
            return "synonym_match"
        elif concept in exploration_results["relationship_matches"]:
            return "relationship_match"
        else:
            return "unknown"

    async def suggest_alternative_queries(
        self, query: str, max_suggestions: int = 5
    ) -> List[str]:
        """
        Suggest alternative queries based on the original query.

        Args:
            query: The original query
            max_suggestions: Maximum number of suggestions to return

        Returns:
            List of alternative query suggestions
        """
        suggestions = []

        # Basic query variations
        base_suggestions = [
            query.lower(),
            query.title(),
            query.upper(),
            f"{query}*",  # Wildcard
            f"*{query}*",  # Contains
        ]

        # Add base suggestions
        suggestions.extend(base_suggestions)

        # Try to find related concepts for more suggestions
        try:
            results = await self.client.search(query, size=10)
            for concept in results.all():
                if concept.name.lower() != query.lower():
                    suggestions.append(concept.name)
        except Exception as e:
            logger.warning(f"Could not generate suggestions for query '{query}': {e}")

        # Remove duplicates and limit results
        unique_suggestions = list(dict.fromkeys(suggestions))
        return unique_suggestions[:max_suggestions]

    async def get_concept_hierarchy(
        self, concept_id: int, max_depth: int = 3
    ) -> Dict[str, Any]:
        """
        Get the concept hierarchy for a given concept.

        Args:
            concept_id: The concept ID
            max_depth: Maximum depth to explore

        Returns:
            Dictionary containing hierarchy information
        """
        hierarchy: Dict[str, Any] = {
            "root_concept": None,
            "parents": [],
            "children": [],
            "siblings": [],
            "depth": 0,
        }

        try:
            # Get root concept details
            root_details = await self.client.details(concept_id)
            hierarchy["root_concept"] = root_details

            # Initialize typed lists
            parents: List[ConceptDetails] = []
            children: List[ConceptDetails] = []

            # Get relationships
            relationships = await self.client.relationships(
                concept_id, only_standard=True
            )

            for group in relationships.items:
                if group.relationshipName.lower() in ["is a", "isa", "subclass of"]:
                    # Parent relationships
                    for rel in group.relationships:
                        try:
                            parent_details = await self.client.details(
                                rel.targetConceptId
                            )
                            parents.append(parent_details)
                        except Exception as e:
                            logger.warning(
                                f"Could not fetch parent concept "
                                f"{rel.targetConceptId}: {e}"
                            )

                elif group.relationshipName.lower() in ["has subclass", "has subtype"]:
                    # Child relationships
                    for rel in group.relationships:
                        try:
                            child_details = await self.client.details(
                                rel.targetConceptId
                            )
                            children.append(child_details)
                        except Exception as e:
                            logger.warning(
                                f"Could not fetch child concept "
                                f"{rel.targetConceptId}: {e}"
                            )

            # Update hierarchy with typed lists
            hierarchy["parents"] = parents
            hierarchy["children"] = children
            hierarchy["depth"] = len(parents)

        except Exception as e:
            logger.error(f"Could not get hierarchy for concept {concept_id}: {e}")

        return hierarchy


def create_concept_explorer(client: Any) -> ConceptExplorer:
    """
    Create a ConceptExplorer instance with the given client.

    Args:
        client: Athena client instance

    Returns:
        ConceptExplorer instance
    """
    return ConceptExplorer(client)

```

### File: `athena_client/athena_client/concept_set.py`
<a name="athena_client-athena_client-concept_setpy"></a>
```python
import logging
from typing import Any, Dict, List, Optional

from .concept_explorer import ConceptExplorer
from .db.base import DatabaseConnector

logger = logging.getLogger(__name__)


class ConceptSetGenerator:
    """Orchestrate concept set generation from a search query."""

    def __init__(self, explorer: ConceptExplorer, db: DatabaseConnector) -> None:
        self.explorer = explorer
        self.db = db

    async def create_from_query(
        self,
        query: str,
        strategy: str = "fallback",
        include_descendants: bool = True,
        confidence_threshold: float = 0.7,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Generate a concept set using a tiered standard-first strategy.
        Includes robust error handling.
        """
        from .exceptions import AthenaError

        try:
            logger.info(
                "Attempting to find and validate standard concepts for query: '%s'",
                query,
            )
            mappings = await self.explorer.map_to_standard_concepts(
                query, confidence_threshold=confidence_threshold, **kwargs
            )

            from .models import ConceptType

            standard_concepts = [
                m["concept"]
                for m in mappings
                if m["concept"].standardConcept == ConceptType.STANDARD
            ]

            if standard_concepts:
                candidate_ids = [c.id for c in standard_concepts]
                validated_ids = self.db.validate_concepts(candidate_ids)

                if validated_ids:
                    warnings: List[str] = []
                    final_ids = set(validated_ids)
                    if include_descendants:
                        desc_ids = self.db.get_descendants(validated_ids)
                        if not desc_ids:
                            warnings.append(
                                (
                                    f"Standard concepts {validated_ids} found but "
                                    "have no descendants in the local vocabulary."
                                )
                            )
                        else:
                            final_ids.update(desc_ids)

                    return self._build_success_response(
                        query=query,
                        strategy_used="Tier 1: Direct Standard Concept",
                        concept_ids=list(final_ids),
                        seed_concepts=validated_ids,
                        warnings=warnings,
                    )

            if strategy == "strict":
                return self._build_failure_response(
                    query,
                    (
                        "No standard concepts from the API could be validated in "
                        "'strict' mode."
                    ),
                )

            non_standard_concepts = [
                m["concept"]
                for m in mappings
                if m["concept"].standardConcept != ConceptType.STANDARD
            ]

            if non_standard_concepts:
                local_mappings = self.db.get_standard_mapping(
                    [c.id for c in non_standard_concepts]
                )
                if local_mappings:
                    mapped_standard_id = list(local_mappings.values())[0]
                    validated_ids = self.db.validate_concepts([mapped_standard_id])
                    if validated_ids:
                        final_ids = set(validated_ids)
                        if include_descendants:
                            final_ids.update(self.db.get_descendants(validated_ids))
                        original_non_standard = list(local_mappings.keys())[0]
                        warning = (
                            "Initial standard concepts not found locally. "
                            "Recovered by mapping non-standard concept "
                            f"{original_non_standard} "
                            f"to standard concept {mapped_standard_id}."
                        )
                        return self._build_success_response(
                            query=query,
                            strategy_used="Tier 3: Recovery via Local Mapping",
                            concept_ids=list(final_ids),
                            seed_concepts=validated_ids,
                            warnings=[warning],
                        )

            return self._build_failure_response(
                query,
                (
                    "No standard concepts from the API could be validated against "
                    "the local database, and no recovery paths were found."
                ),
            )
        except AthenaError as err:
            logger.error(f"Athena client error during concept set generation: {err}")
            # Return a structured failure response with troubleshooting info
            return {
                "name": f"Failed Concept Set for '{query}'",
                "concept_ids": [],
                "metadata": {
                    "status": "FAILURE",
                    "source_query": query,
                    "reason": str(err),
                    "suggestions": [
                        "Check your network connection and credentials.",
                        "Try again in a few moments.",
                        getattr(err, "troubleshooting", None)
                        or "See logs for more details.",
                    ],
                },
            }

    def _build_success_response(
        self,
        query: str,
        strategy_used: str,
        concept_ids: List[int],
        seed_concepts: List[int],
        warnings: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        return {
            "name": f"Concept Set for '{query}'",
            "concept_ids": concept_ids,
            "metadata": {
                "status": "SUCCESS",
                "strategy_used": strategy_used,
                "source_query": query,
                "seed_concepts": seed_concepts,
                "warnings": warnings or [],
            },
        }

    def _build_failure_response(self, query: str, reason: str) -> Dict[str, Any]:
        return {
            "name": f"Failed Concept Set for '{query}'",
            "concept_ids": [],
            "metadata": {
                "status": "FAILURE",
                "source_query": query,
                "reason": reason,
                "suggestions": [
                    "Try a different search term.",
                    "Lower the `confidence_threshold`.",
                    "Check if your local vocabulary version is up to date.",
                ],
            },
        }

```

### File: `athena_client/athena_client/exceptions.py`
<a name="athena_client-athena_client-exceptionspy"></a>
```python
"""
Exception classes for the Athena client.

This module defines a hierarchy of exceptions that can be raised by the Athena client.
"""

from typing import List, Optional


class AthenaError(Exception):
    """Base class for all Athena client exceptions."""

    def __init__(
        self,
        message: str,
        error_code: Optional[str] = None,
        troubleshooting: Optional[str] = None,
    ) -> None:
        """
        Initialize the exception.

        Args:
            message: Error message
            error_code: Optional error code for programmatic handling
            troubleshooting: Optional troubleshooting suggestions
        """
        super().__init__(message)
        self.message = message
        self.error_code = error_code
        self.troubleshooting = troubleshooting

    def __str__(self) -> str:
        """Return a user-friendly error message."""
        msg = self.message
        if self.troubleshooting:
            msg += f"\n\nüí° Troubleshooting: {self.troubleshooting}"
        return msg


class NetworkError(AthenaError):
    """
    Raised for network-related errors (DNS, TLS, socket, or timeout).
    """

    def __init__(self, message: str, url: Optional[str] = None) -> None:
        """
        Initialize the network error.

        Args:
            message: Error message
            url: URL that failed to connect
        """
        troubleshooting = (
            "‚Ä¢ Check your internet connection\n"
            "‚Ä¢ Verify the API endpoint URL is correct\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Contact your network administrator if the problem persists"
        )
        super().__init__(
            message, error_code="NETWORK_ERROR", troubleshooting=troubleshooting
        )
        self.url = url


class TimeoutError(NetworkError):
    """
    Raised when a request times out.
    """

    def __init__(
        self, message: str, url: Optional[str] = None, timeout: Optional[float] = None
    ) -> None:
        """
        Initialize the timeout error.

        Args:
            message: Error message
            url: URL that timed out
            timeout: Timeout value that was exceeded
        """
        troubleshooting = (
            "‚Ä¢ The server is taking too long to respond\n"
            "‚Ä¢ Try increasing the timeout value\n"
            "‚Ä¢ Check if the API server is experiencing high load\n"
            "‚Ä¢ Try again in a few moments"
        )
        super().__init__(message, url)
        self.timeout = timeout
        self.troubleshooting = troubleshooting


class ServerError(AthenaError):
    """
    Raised when the server returns a 5xx status code.
    """

    def __init__(
        self,
        message: str,
        status_code: int,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the server error.

        Args:
            message: Error message
            status_code: HTTP status code
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ The API server is experiencing issues\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Check the API status page for known issues\n"
            "‚Ä¢ Contact the API administrators if the problem persists"
        )
        super().__init__(
            message, error_code="SERVER_ERROR", troubleshooting=troubleshooting
        )
        self.status_code = status_code
        self.response = response
        self.url = url


class ClientError(AthenaError):
    """
    Raised when the server returns a 4xx status code.
    """

    def __init__(
        self,
        message: str,
        status_code: int,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the client error.

        Args:
            message: Error message
            status_code: HTTP status code
            response: Raw response body
            url: URL that caused the error
        """
        # Customize troubleshooting based on status code
        if status_code == 400:
            troubleshooting = (
                "‚Ä¢ Check your request parameters\n"
                "‚Ä¢ Verify the data format is correct\n"
                "‚Ä¢ Review the API documentation for the correct format"
            )
        elif status_code == 401:
            troubleshooting = (
                "‚Ä¢ Check your authentication credentials\n"
                "‚Ä¢ Verify your API token is valid and not expired\n"
                "‚Ä¢ Ensure you have the necessary permissions"
            )
        elif status_code == 403:
            troubleshooting = (
                "‚Ä¢ You don't have permission to access this resource\n"
                "‚Ä¢ Check your API token permissions\n"
                "‚Ä¢ Contact the API administrators for access"
            )
        elif status_code == 404:
            troubleshooting = (
                "‚Ä¢ The requested resource was not found\n"
                "‚Ä¢ Check the URL path is correct\n"
                "‚Ä¢ Verify the resource ID exists\n"
                "‚Ä¢ Review the API documentation for available endpoints"
            )
        elif status_code == 429:
            troubleshooting = (
                "‚Ä¢ You've exceeded the rate limit\n"
                "‚Ä¢ Wait before making more requests\n"
                "‚Ä¢ Consider implementing request throttling\n"
                "‚Ä¢ Check the API documentation for rate limits"
            )
        else:
            troubleshooting = (
                "‚Ä¢ Check your request parameters\n"
                "‚Ä¢ Review the API documentation\n"
                "‚Ä¢ Verify your authentication credentials"
            )

        super().__init__(
            message, error_code="CLIENT_ERROR", troubleshooting=troubleshooting
        )
        self.status_code = status_code
        self.response = response
        self.url = url


class ValidationError(AthenaError):
    """
    Raised when response validation fails.
    """

    def __init__(self, message: str, validation_details: Optional[str] = None) -> None:
        """
        Initialize the validation error.

        Args:
            message: Error message
            validation_details: Detailed validation error information
        """
        troubleshooting = (
            "‚Ä¢ The API response format has changed\n"
            "‚Ä¢ This might be a temporary API issue\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Contact the API administrators if the problem persists"
        )
        super().__init__(
            message, error_code="VALIDATION_ERROR", troubleshooting=troubleshooting
        )
        self.validation_details = validation_details


class AuthenticationError(ClientError):
    """
    Raised for authentication-related errors.
    """

    def __init__(
        self,
        message: str,
        status_code: int = 401,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the authentication error.

        Args:
            message: Error message
            status_code: HTTP status code (default 401)
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ Check your API token is valid and not expired\n"
            "‚Ä¢ Verify your authentication credentials\n"
            "‚Ä¢ Ensure you have the necessary permissions\n"
            "‚Ä¢ Contact the API administrators for access"
        )
        super().__init__(message, status_code, response, url)
        self.error_code = "AUTHENTICATION_ERROR"
        self.troubleshooting = troubleshooting


class RateLimitError(ClientError):
    """
    Raised when rate limits are exceeded.
    """

    def __init__(
        self,
        message: str,
        status_code: int = 429,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the rate limit error.

        Args:
            message: Error message
            status_code: HTTP status code (default 429)
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ You've exceeded the API rate limit\n"
            "‚Ä¢ Wait before making more requests\n"
            "‚Ä¢ Consider implementing request throttling\n"
            "‚Ä¢ Check the API documentation for rate limits"
        )
        super().__init__(message, status_code, response, url)
        self.error_code = "RATE_LIMIT_ERROR"
        self.troubleshooting = troubleshooting


class APIError(AthenaError):
    """
    Raised when the API returns an error response.
    """

    def __init__(
        self,
        message: str,
        api_error_code: Optional[str] = None,
        api_message: Optional[str] = None,
    ) -> None:
        """
        Initialize the API error.

        Args:
            message: Error message
            api_error_code: Error code from the API
            api_message: Error message from the API
        """
        troubleshooting = (
            "‚Ä¢ The API returned an error response\n"
            "‚Ä¢ Check the API error details above\n"
            "‚Ä¢ Verify your request parameters\n"
            "‚Ä¢ Try again with different parameters if applicable"
        )
        super().__init__(
            message, error_code="API_ERROR", troubleshooting=troubleshooting
        )
        self.api_error_code = api_error_code
        self.api_message = api_message


class RetryFailedError(AthenaError):
    """
    Raised when all retry attempts have been exhausted.
    """

    def __init__(
        self,
        message: str,
        max_attempts: int,
        last_error: Exception,
        retry_history: List[Exception],
        error_code: Optional[str] = None,
    ) -> None:
        """
        Initialize the retry failed error.

        Args:
            message: Error message
            max_attempts: Maximum number of retry attempts
            last_error: The last error that caused the final failure
            retry_history: List of errors from each retry attempt
            error_code: Optional error code
        """
        troubleshooting = (
            "‚Ä¢ All retry attempts have been exhausted\n"
            "‚Ä¢ Check your internet connection\n"
            "‚Ä¢ Verify the API server is accessible\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Consider increasing max_retries if this is a temporary issue"
        )
        super().__init__(
            message,
            error_code=error_code or "RETRY_FAILED",
            troubleshooting=troubleshooting,
        )
        self.max_attempts = max_attempts
        self.last_error = last_error
        self.retry_history = retry_history

    def __str__(self) -> str:
        """Return a detailed error message with retry information."""
        msg = self.message
        msg += "\n\nüìä Retry Information:"
        msg += f"\n‚Ä¢ Maximum attempts: {self.max_attempts}"
        msg += f"\n‚Ä¢ Attempts made: {len(self.retry_history) + 1}"
        msg += f"\n‚Ä¢ Last error: {type(self.last_error).__name__}: {self.last_error}"

        if self.retry_history:
            msg += "\n\nüîÑ Retry History:"
            for i, error in enumerate(self.retry_history, 1):
                msg += f"\n‚Ä¢ Attempt {i}: {type(error).__name__}: {error}"

        if self.troubleshooting:
            msg += f"\n\nüí° Troubleshooting: {self.troubleshooting}"

        return msg

```

### File: `athena_client/athena_client/http.py`
<a name="athena_client-athena_client-httppy"></a>
```python
"""
HTTP client implementation for Athena API.

This module provides HTTP clients for making requests to the Athena API,
with features like retry, backoff, and timeout handling.
"""

import json
import logging
import random
import time
from typing import Any, Dict, Optional, Tuple, TypeVar, Union

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from .auth import build_headers
from .exceptions import (
    AthenaError,
    AuthenticationError,
    ClientError,
    NetworkError,
    RateLimitError,
    ServerError,
    TimeoutError,
    ValidationError,
)
from .settings import get_settings

# Type variable for generic response
T = TypeVar("T")

logger = logging.getLogger(__name__)


class HttpClient:
    """
    Synchronous HTTP client for making requests to the Athena API.

    Features:
    - Automatic retry with exponential backoff
    - Custom timeout handling
    - Authentication header generation
    - Error handling and mapping to typed exceptions
    - Robust logging and debugging
    - Custom User-Agent and headers
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        enable_throttling: bool = True,
        throttle_delay_range: Tuple[float, float] = (0.1, 0.3),
    ) -> None:
        """
        Initialize the HTTP client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
            enable_throttling: Whether to throttle requests to be respectful
                to the server
            throttle_delay_range: Range of delays for throttling (min, max)
                in seconds
        """
        settings = get_settings()

        # Use provided values or fall back to settings
        self.base_url = base_url or settings.ATHENA_BASE_URL

        # Set up token and HMAC if provided
        if token is not None:
            settings.ATHENA_TOKEN = token
        if client_id is not None:
            settings.ATHENA_CLIENT_ID = client_id
        if private_key is not None:
            settings.ATHENA_PRIVATE_KEY = private_key

        self.timeout = timeout or settings.ATHENA_TIMEOUT_SECONDS
        self.max_retries = max_retries or settings.ATHENA_MAX_RETRIES
        self.backoff_factor = backoff_factor or settings.ATHENA_BACKOFF_FACTOR
        self.enable_throttling = enable_throttling
        self.throttle_delay_range = throttle_delay_range

        # Create session with retry configuration
        self.session = self._create_session()

        # Set up default headers
        self._setup_default_headers()

        logger.debug("HttpClient initialized with base URL: %s", self.base_url)

    def _create_session(self) -> requests.Session:
        """
        Create and configure a requests Session with enhanced retry logic.

        Returns:
            Configured requests.Session object
        """
        session = requests.Session()

        # Enhanced retry strategy for better handling of rate limiting
        # and server overload
        retry_strategy = Retry(
            total=self.max_retries,
            backoff_factor=self.backoff_factor,
            # Retry on rate limiting (429), server errors (5xx), and temporary failures
            status_forcelist=[429, 500, 502, 503, 504, 520, 521, 522, 523, 524],
            # Also retry on connection errors and timeouts
            allowed_methods=["HEAD", "GET", "OPTIONS", "POST"],
            # Respect Retry-After headers from server
            respect_retry_after_header=True,
            # Exponential backoff with jitter to prevent thundering herd
            raise_on_status=False,  # Let us handle status codes ourselves
        )

        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        return session

    def _setup_default_headers(self) -> None:
        """Set up default headers for all requests."""
        # Set default headers similar to the working client
        default_headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "AthenaOHDSIAPIClient/1.0",
        }

        # Update session headers
        self.session.headers.update(default_headers)

        logger.debug("Default headers set: %s", default_headers)

    def _throttle_request(self) -> None:
        """
        Implement request throttling to prevent overwhelming the server.

        This adds a small delay between requests to be respectful to the API.
        """
        if not self.enable_throttling:
            return

        # Add a small random delay between requests
        # This prevents overwhelming the server with rapid requests
        delay = random.uniform(  # nosec B311
            self.throttle_delay_range[0], self.throttle_delay_range[1]
        )
        time.sleep(delay)

        logger.debug(f"Request throttled for {delay:.3f} seconds")

    def _handle_rate_limit(self, response: requests.Response) -> None:
        """
        Handle rate limiting with intelligent backoff.

        Args:
            response: HTTP response that indicates rate limiting
        """
        # Get retry-after header if available
        retry_after = response.headers.get("Retry-After")

        if retry_after:
            try:
                wait_time = int(retry_after)
                logger.info(
                    f"Rate limited. Waiting {wait_time} seconds as requested by server."
                )
                time.sleep(wait_time)
            except ValueError:
                # If Retry-After is not a number, use exponential backoff
                wait_time = 60  # Default to 1 minute
                logger.info(f"Rate limited. Waiting {wait_time} seconds (default).")
                time.sleep(wait_time)
        else:
            # No Retry-After header, use exponential backoff
            wait_time = 60  # Default to 1 minute
            logger.info(
                f"Rate limited. Waiting {wait_time} seconds (exponential backoff)."
            )
            time.sleep(wait_time)

    def _build_url(self, path: str) -> str:
        """
        Build full URL by joining base URL and path.

        Args:
            path: API path

        Returns:
            Full URL
        """
        # Handle paths that start with / to ensure they're appended correctly
        if path.startswith("/"):
            # Remove the leading / and join with base_url
            path = path[1:]

        # Ensure base_url doesn't end with / and path doesn't start with /
        if self.base_url.endswith("/"):
            base = self.base_url[:-1]
        else:
            base = self.base_url

        if path.startswith("/"):
            path = path[1:]

        full_url = f"{base}/{path}"

        logger.debug(
            f"Building URL: base_url='{self.base_url}', path='{path}' "
            f"-> full_url='{full_url}'"
        )
        return full_url

    def _normalize_params(
        self, params: Optional[Dict[str, Any]]
    ) -> Optional[Dict[str, str]]:
        """
        Normalize parameters to ensure all values are strings.

        Args:
            params: Query parameters

        Returns:
            Normalized parameters with string values
        """
        if params is None:
            return None

        normalized = {}
        for key, value in params.items():
            if value is not None:
                normalized[key] = str(value)
        return normalized

    def _handle_response(self, response: requests.Response, url: str) -> Dict[str, Any]:
        """
        Handle API response and raise appropriate exceptions.

        Args:
            response: HTTP response from requests
            url: Full URL that was requested

        Returns:
            Parsed JSON response

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
            APIError: For API-specific error responses
        """
        # Log raw response for debugging
        raw_response_text = response.text
        logger.debug(f"Raw response text from {url}: {raw_response_text[:1000]}...")

        try:
            response.raise_for_status()

            # Attempt to parse JSON after logging raw text
            data = response.json()
            logger.debug("Successfully parsed JSON from %s", url)
            return data

        except requests.exceptions.HTTPError as e:
            status = e.response.status_code if e.response else "N/A"
            text = e.response.text if e.response else "No response content"

            # Try to parse the error response as JSON to extract API error details
            api_message = None

            try:
                if e.response and e.response.text:
                    error_data = e.response.json()
                    api_message = error_data.get("errorMessage")
            except (ValueError, AttributeError):
                pass

            # Create a more descriptive error message
            if api_message:
                msg = f"API Error {status}: {api_message}"
            else:
                msg = f"HTTP error {status} when accessing {url}"
                if text and text != "No response content":
                    msg += f": {text[:200]}"

            logger.error(msg)
            logger.exception(e)

            # Raise specific exception types based on status code
            if status == 401:
                raise AuthenticationError(
                    f"Authentication failed: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 403:
                raise ClientError(
                    f"Access forbidden: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 404:
                raise ClientError(
                    f"Resource not found: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 429:
                raise RateLimitError(
                    f"Rate limit exceeded: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif 400 <= response.status_code < 500:
                raise ClientError(
                    f"Client error: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif response.status_code >= 500:
                raise ServerError(
                    f"Server error: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            else:
                raise

        except json.JSONDecodeError as e:
            msg = (
                f"Invalid JSON response from {url}: {e}. "
                f"Raw text was: {raw_response_text[:1000]}..."
            )
            logger.error(msg)
            logger.exception(e)
            raise ValidationError(
                f"Invalid JSON response: {e}", validation_details=str(e)
            ) from e

        except Exception as e:
            msg = f"An unexpected error occurred when accessing {url}: {e}"
            logger.error(msg)
            logger.exception(e)
            raise AthenaError(msg, error_code="UNEXPECTED_ERROR") from e

    def request(
        self,
        method: str,
        path: str,
        data: Any = None,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make an HTTP request to the Athena API with enhanced retry and throttling.

        Args:
            method: HTTP method (GET, POST, etc.)
            path: API endpoint path
            params: Query parameters
            data: Request body data
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
            RateLimitError: For rate limiting issues
        """
        url = self._build_url(path)
        body_bytes = b""

        # Convert data to JSON bytes if provided
        if data is not None:
            body_bytes = json.dumps(data).encode("utf-8")

        # Build authentication headers
        auth_headers = build_headers(method, url, body_bytes)

        # Merge with session headers
        headers = dict(self.session.headers)
        headers.update(auth_headers)

        # Normalize parameters to strings
        normalized_params = self._normalize_params(params)

        # Generate a correlation ID for logging
        correlation_id = f"req-{id(self)}-{id(path)}"
        logger.debug(
            f"[{correlation_id}] {method} {url} with params: {normalized_params}"
        )

        # Throttle request to be respectful to the server
        self._throttle_request()

        try:
            response = self.session.request(
                method=method,
                url=url,
                params=normalized_params,
                data=body_bytes if data is not None else None,
                headers=headers,
                timeout=self.timeout,
            )

            logger.debug(f"[{correlation_id}] {response.status_code} {response.reason}")

            # Handle rate limiting specifically
            if response.status_code == 429:
                logger.warning(
                    f"Rate limited by server. Status: {response.status_code}"
                )
                self._handle_rate_limit(response)
                # After waiting, we could retry the request, but for now we'll
                # raise the error
                # The retry mechanism in the client will handle this

            if raw_response:
                return response

            return self._handle_response(response, url)

        except requests.exceptions.Timeout as e:
            msg = (
                f"Timeout when accessing {url}. "
                f"Verify network connectivity and the API's responsiveness."
            )
            logger.error(msg)
            logger.exception(e)
            raise TimeoutError(msg, url=url, timeout=self.timeout) from e

        except requests.exceptions.ConnectionError as e:
            msg = (
                f"Connection error when accessing {url}. "
                f"Check your network connection and endpoint URL."
            )
            logger.error(msg)
            logger.exception(e)
            raise NetworkError(msg, url=url) from e

        except Exception as e:
            msg = f"An unexpected error occurred when accessing {url}: {e}"
            logger.error(msg)
            logger.exception(e)
            raise NetworkError(msg, url=url) from e

    def get(
        self,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make a GET request to the Athena API.

        Args:
            path: API endpoint path
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return self.request("GET", path, params=params, raw_response=raw_response)

    def post(
        self,
        path: str,
        data: Dict[str, Any],
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make a POST request to the Athena API.

        Args:
            path: API endpoint path
            data: Request body data
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return self.request(
            "POST", path, data=data, params=params, raw_response=raw_response
        )

    def close(self) -> None:
        """Closes the underlying HTTP session."""
        logger.info("Closing HTTP session.")
        self.session.close()

    def __enter__(self) -> "HttpClient":
        return self

    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
        self.close()

```

### File: `athena_client/athena_client/query.py`
<a name="athena_client-athena_client-querypy"></a>
```python
"""
Query DSL for building complex Athena queries.

This module provides a Query DSL that allows for building complex queries
using a fluent interface and operator overloading.
"""

from typing import Any, Dict, Optional


class Q:
    """
    Query DSL for building complex Athena queries.

    Usage:
        q = Q.term("diabetes")
        q = Q.phrase("heart attack")
        q = Q.exact('"Myocardial Infarction"')
        q = Q.wildcard("aspir*")

        # Combine with operators
        q = Q.term("diabetes") & Q.term("type 2")  # AND
        q = Q.term("heart") | Q.term("cardiac")    # OR
        q = -Q.term("chronic")                     # NOT

        # Apply modifiers
        q = Q.term("aspirin").fuzzy(0.8)

        # Get boosts for the API
        boosts = q.to_boosts()
    """

    def __init__(self, query_type: str, value: str, **kwargs: Any) -> None:
        """
        Initialize a query object.

        Args:
            query_type: Type of query (term, phrase, exact, wildcard)
            value: Query value
            **kwargs: Additional options
        """
        self.query_type = query_type
        self.value = value
        self.options = kwargs
        self.operator: Optional[str] = None
        self.left: Optional["Q"] = None
        self.right: Optional["Q"] = None

    @classmethod
    def term(cls, value: str) -> "Q":
        """
        Create a term query.

        Args:
            value: Term to search for

        Returns:
            Query object
        """
        return cls("term", value)

    @classmethod
    def phrase(cls, value: str) -> "Q":
        """
        Create a phrase query.

        Args:
            value: Phrase to search for

        Returns:
            Query object
        """
        return cls("phrase", value)

    @classmethod
    def exact(cls, value: str) -> "Q":
        """
        Create an exact match query.

        Args:
            value: Exact phrase to search for (should be in quotes)

        Returns:
            Query object
        """
        if not value.startswith('"') or not value.endswith('"'):
            value = f'"{value}"'
        return cls("exact", value)

    @classmethod
    def wildcard(cls, value: str) -> "Q":
        """
        Create a wildcard query.

        Args:
            value: Wildcard pattern (e.g., "aspir*")

        Returns:
            Query object
        """
        if not value.endswith("*"):
            value = f"{value}*"
        return cls("wildcard", value)

    def fuzzy(self, ratio: float = 0.7) -> "Q":
        """
        Apply fuzzy matching to the query.

        Args:
            ratio: Fuzzy match ratio (0.0 - 1.0)

        Returns:
            Query object with fuzzy matching
        """
        self.options["fuzzy"] = ratio
        return self

    def __and__(self, other: "Q") -> "Q":
        """
        Combine with AND operator.

        Args:
            other: Another Q object

        Returns:
            New Q object representing the AND condition
        """
        result = Q("compound", "")
        result.operator = "AND"
        result.left = self
        result.right = other
        return result

    def __or__(self, other: "Q") -> "Q":
        """
        Combine with OR operator.

        Args:
            other: Another Q object

        Returns:
            New Q object representing the OR condition
        """
        result = Q("compound", "")
        result.operator = "OR"
        result.left = self
        result.right = other
        return result

    def __neg__(self) -> "Q":
        """
        Apply NOT operator.

        Returns:
            New Q object representing the NOT condition
        """
        result = Q("compound", "")
        result.operator = "NOT"
        result.right = self
        return result

    def to_boosts(self) -> Dict[str, Any]:
        """
        Convert the query to a boosts dictionary for the Athena API.

        Returns:
            Dictionary with query boosts
        """
        if self.query_type == "compound":
            if self.operator == "AND":
                assert self.left is not None and self.right is not None
                boosts_left = self.left.to_boosts()
                boosts_right = self.right.to_boosts()
                # Merge the boosts with AND logic
                return {
                    "filter": {
                        "bool": {
                            "must": [
                                boosts_left.get("filter", {}),
                                boosts_right.get("filter", {}),
                            ]
                        }
                    }
                }
            elif self.operator == "OR":
                assert self.left is not None and self.right is not None
                boosts_left = self.left.to_boosts()
                boosts_right = self.right.to_boosts()
                # Merge the boosts with OR logic
                return {
                    "filter": {
                        "bool": {
                            "should": [
                                boosts_left.get("filter", {}),
                                boosts_right.get("filter", {}),
                            ]
                        }
                    }
                }
            elif self.operator == "NOT":
                assert self.right is not None
                boosts_right = self.right.to_boosts()
                # Apply NOT logic
                return {
                    "filter": {"bool": {"must_not": [boosts_right.get("filter", {})]}}
                }
            # Fallback for unrecognized operator
            return {"filter": {"query_string": {"query": self.value}}}

        # Handle basic query types
        query_dict: Dict[str, Any] = {}

        if self.query_type == "term":
            query_dict["query"] = self.value
            query_dict["fields"] = [
                "name^10",
                "synonyms^5",
                "definition^3",
                "concept_code",
            ]
        elif self.query_type == "phrase":
            query_dict["query"] = f'"{self.value}"'
            query_dict["fields"] = ["name^10", "synonyms^5", "definition^3"]
        elif self.query_type == "exact":
            query_dict["query"] = self.value
            query_dict["fields"] = ["concept_code^20", "name.exact^15"]
        elif self.query_type == "wildcard":
            query_dict["query"] = self.value
            query_dict["fields"] = ["name^10", "synonyms^5"]

        # Apply fuzzy if requested
        if "fuzzy" in self.options:
            query_dict["fuzziness"] = self.options["fuzzy"]

        if query_dict:
            return {"filter": {"query_string": query_dict}}
        # Final fallback for unhandled query types
        return {"filter": {"query_string": {"query": self.value}}}

    def __str__(self) -> str:
        """
        Convert the query to a string representation for API calls.

        Returns:
            String representation of the query
        """
        if self.query_type == "compound":
            if self.operator == "AND":
                assert self.left is not None and self.right is not None
                return f"({self.left}) AND ({self.right})"
            elif self.operator == "OR":
                assert self.left is not None and self.right is not None
                return f"({self.left}) OR ({self.right})"
            elif self.operator == "NOT":
                assert self.right is not None
                return f"NOT ({self.right})"
            # Gracefully handle unknown operators by returning the raw value
            return self.value
        else:
            # For basic query types, return the value
            return self.value

```

### File: `athena_client/athena_client/search_result.py`
<a name="athena_client-athena_client-search_resultpy"></a>
```python
"""
Search result wrapper for Athena API responses.

This module provides a wrapper around search results that provides
convenient access to the data in various formats.
"""

from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional

import pandas as pd

from .models import Concept, ConceptSearchResponse

if TYPE_CHECKING:
    pass


class SearchResult:
    """Wrapper for search results that provides convenient access methods."""

    def __init__(self, response: ConceptSearchResponse, client: Any) -> None:
        """Initialize the search result wrapper.

        Args:
            response: The search response from the API
            client: The client instance for making additional requests
        """
        self._response = response
        self._client = client

    def all(self) -> List[Concept]:
        """Get all concepts from the current page.

        Returns:
            List of Concept objects
        """
        return self._response.content

    def top(self, n: int) -> List[Concept]:
        """Get the top N concepts from the current page.

        Args:
            n: Number of concepts to return

        Returns:
            List of Concept objects
        """
        return self._response.content[:n]

    def to_list(self) -> List[Dict[str, Any]]:
        """Convert results to a list of dictionaries.

        Returns:
            List of dictionaries representing concepts
        """
        return [concept.model_dump() for concept in self._response.content]

    def to_json(self) -> str:
        """Convert results to JSON string.

        Returns:
            JSON string representation of the results
        """
        return self._response.model_dump_json()

    def to_df(self) -> pd.DataFrame:
        """Convert results to a pandas DataFrame.

        Returns:
            DataFrame containing the concept data
        """
        try:
            data = self.to_list()
            return pd.DataFrame(data)
        except ImportError:
            raise ImportError(
                "pandas is required for DataFrame output. "
                "Install with: pip install 'athena-client[pandas]'"
            ) from None

    def next_page(self) -> Optional["SearchResult"]:
        """Get the next page of results.

        Returns:
            SearchResult for the next page, or None if no more pages
        """
        if self._response.last:
            return None
        current_page = self._response.number
        size = self._response.size
        if current_page is None or size is None:
            return None
        return self._client.search(
            query="",  # This would need to be the original query
            page=current_page + 1,
            size=size,
        )

    def previous_page(self) -> Optional["SearchResult"]:
        """Get the previous page of results.

        Returns:
            SearchResult for the previous page, or None if no previous pages
        """
        if self._response.first:
            return None
        current_page = self._response.number
        size = self._response.size
        if current_page is None or size is None:
            return None
        return self._client.search(
            query="",  # This would need to be the original query
            page=current_page - 1,
            size=size,
        )

    @property
    def total_elements(self) -> int:
        """Get the total number of elements across all pages.

        Returns:
            Total number of elements
        """
        # Try to get from direct field first, then from pageable
        if self._response.totalElements is not None:
            return self._response.totalElements

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "totalElements" in pageable:
            return pageable["totalElements"]

        # Fallback to number of elements in current page
        return len(self._response.content)

    @property
    def total_pages(self) -> int:
        """Get the total number of pages.

        Returns:
            Total number of pages
        """
        # Try to get from direct field first, then calculate from pageable
        if self._response.totalPages is not None:
            return self._response.totalPages

        # Calculate from pageable if available
        pageable = self._response.pageable
        if pageable and "totalElements" in pageable and "pageSize" in pageable:
            total_elements = pageable["totalElements"]
            page_size = pageable["pageSize"]
            return (total_elements + page_size - 1) // page_size

        return 1

    @property
    def current_page(self) -> int:
        """Get the current page number.

        Returns:
            Current page number
        """
        # Try to get from direct field first, then from pageable
        if self._response.number is not None:
            return self._response.number

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "pageNumber" in pageable:
            return pageable["pageNumber"]

        return 0

    @property
    def page_size(self) -> int:
        """Get the page size.

        Returns:
            Page size
        """
        # Try to get from direct field first, then from pageable
        if self._response.size is not None:
            return self._response.size

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "pageSize" in pageable:
            return pageable["pageSize"]

        return len(self._response.content)

    @property
    def facets(self) -> Optional[Dict[str, Any]]:
        """Get search facets if available.

        Returns:
            Search facets dictionary or None
        """
        return self._response.facets

    def __len__(self) -> int:
        """Get the number of concepts in the current page.

        Returns:
            Number of concepts
        """
        return len(self._response.content)

    def __getitem__(self, index: int) -> Concept:
        """Get a concept by index.

        Args:
            index: Index of the concept

        Returns:
            Concept object
        """
        return self._response.content[index]

    def __iter__(self) -> Iterator["Concept"]:
        """Iterate over concepts in the current page.

        Returns:
            Iterator over Concept objects
        """
        return iter(self._response.content)

```

### File: `athena_client/athena_client/settings.py`
<a name="athena_client-athena_client-settingspy"></a>
```python
"""
Settings module for the Athena client.

This module provides configuration settings loaded from environment variables
or .env files using pydantic-settings.
"""

from functools import lru_cache
from typing import Optional

from pydantic_settings import BaseSettings, SettingsConfigDict


class _Settings(BaseSettings):
    """
    Configuration settings for the Athena client.

    Settings can be provided via environment variables, .env file, or defaults.
    """

    ATHENA_BASE_URL: str = "https://athena.ohdsi.org/api/v1"
    ATHENA_TOKEN: Optional[str] = None
    ATHENA_CLIENT_ID: Optional[str] = None
    ATHENA_PRIVATE_KEY: Optional[str] = None

    # Enhanced timeout configuration for different operations
    ATHENA_TIMEOUT_SECONDS: int = 30  # Increased default timeout
    ATHENA_SEARCH_TIMEOUT_SECONDS: int = 45  # Longer timeout for search operations
    ATHENA_GRAPH_TIMEOUT_SECONDS: int = 60  # Even longer for graph operations
    ATHENA_RELATIONSHIPS_TIMEOUT_SECONDS: int = 45  # For relationship queries

    # Retry configuration
    ATHENA_MAX_RETRIES: int = 3
    ATHENA_BACKOFF_FACTOR: float = 0.3

    # Pagination configuration
    ATHENA_DEFAULT_PAGE_SIZE: int = 20
    ATHENA_MAX_PAGE_SIZE: int = 1000
    ATHENA_LARGE_QUERY_THRESHOLD: int = 100  # Threshold for "large" queries

    # Progress and user experience
    ATHENA_SHOW_PROGRESS: bool = True
    ATHENA_PROGRESS_UPDATE_INTERVAL: float = 2.0  # Seconds between progress updates

    # Large query handling
    ATHENA_AUTO_CHUNK_LARGE_QUERIES: bool = True
    ATHENA_CHUNK_SIZE: int = 50  # Size for chunking large queries
    ATHENA_MAX_CONCURRENT_CHUNKS: int = 3  # Max concurrent chunk requests

    model_config = SettingsConfigDict(env_file=".env", env_prefix="")


@lru_cache
def get_settings() -> _Settings:
    """
    Get the settings singleton.

    Returns:
        Cached instance of _Settings.
    """
    return _Settings()  # cached singleton

```

## Folder: athena_client/utils

### File: `athena_client/athena_client/utils/__init__.py`
<a name="athena_client-athena_client-utils-__init__py"></a>
```python
"""
Utility functions for the Athena client.

This module provides various utility functions for the Athena client,
including progress tracking, query size estimation, and timeout management.
"""

import logging
from typing import Optional

from .progress import (
    ProgressTracker,
    estimate_query_size,
    format_large_query_warning,
    get_operation_timeout,
    progress_context,
)

logger = logging.getLogger(__name__)


def configure_logging(level: Optional[int] = None) -> None:
    """
    Configure logging for the Athena client.

    Args:
        level: Logging level (e.g., logging.INFO, logging.DEBUG)
    """
    log_level = level or logging.INFO

    logger = logging.getLogger("athena_client")
    logger.setLevel(log_level)

    # Create console handler if no handlers exist
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setLevel(log_level)

        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        handler.setFormatter(formatter)

        logger.addHandler(handler)


__all__ = [
    "configure_logging",
    "ProgressTracker",
    "progress_context",
    "estimate_query_size",
    "get_operation_timeout",
    "format_large_query_warning",
]

```

### File: `athena_client/athena_client/utils/progress.py`
<a name="athena_client-athena_client-utils-progresspy"></a>
```python
"""
Progress tracking utilities for large queries.

This module provides progress indicators and user-friendly feedback
for long-running operations like large searches and graph queries.
"""

import threading
import time
from contextlib import contextmanager
from typing import Generator, Optional


class ProgressTracker:
    """Track progress of long-running operations with user-friendly feedback."""

    def __init__(
        self,
        total: int,
        description: str = "Processing",
        show_progress: bool = True,
        update_interval: float = 2.0,
    ) -> None:
        """
        Initialize the progress tracker.

        Args:
            total: Total number of items to process
            description: Description of the operation
            show_progress: Whether to show progress updates
            update_interval: Seconds between progress updates
        """
        self.total = total
        self.description = description
        self.show_progress = show_progress
        self.update_interval = update_interval
        self.current = 0
        self.start_time: Optional[float] = None
        self.last_update_time: float = 0.0
        self._lock = threading.Lock()

    def start(self) -> None:
        """Start tracking progress."""
        self.start_time = time.time()
        if self.show_progress:
            self._print_progress()

    def update(self, increment: int = 1) -> None:
        """
        Update progress by the given increment.

        Args:
            increment: Number of items completed
        """
        with self._lock:
            self.current += increment
            current_time = time.time()

            # Only update display if enough time has passed
            if (
                self.show_progress
                and current_time - self.last_update_time >= self.update_interval
            ):
                self._print_progress()
                self.last_update_time = current_time

    def complete(self) -> None:
        """Mark the operation as complete."""
        self.current = self.total
        if self.show_progress:
            self._print_progress()
            print(f"‚úÖ {self.description} completed!")

    def _print_progress(self) -> None:
        """Print the current progress."""
        if self.total == 0:
            return

        percentage = (self.current / self.total) * 100
        elapsed = time.time() - self.start_time if self.start_time else 0

        # Calculate ETA
        eta = None
        if self.current > 0 and elapsed > 0:
            rate = self.current / elapsed
            remaining = self.total - self.current
            eta = remaining / rate if rate > 0 else None

        # Create progress bar
        bar_length = 30
        filled_length = int(bar_length * self.current // self.total)
        bar = "‚ñà" * filled_length + "‚ñë" * (bar_length - filled_length)

        # Format time
        elapsed_str = self._format_time(elapsed)
        eta_str = f" (ETA: {self._format_time(eta)})" if eta else ""

        print(
            f"\r{self.description}: [{bar}] {percentage:.1f}% "
            f"({self.current}/{self.total}) {elapsed_str}{eta_str}",
            end="",
            flush=True,
        )

    def _format_time(self, seconds: Optional[float]) -> str:
        """Format time in a human-readable way."""
        if seconds is None:
            return "unknown"

        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}m"
        else:
            hours = seconds / 3600
            return f"{hours:.1f}h"


@contextmanager
def progress_context(
    total: int,
    description: str = "Processing",
    show_progress: bool = True,
    update_interval: float = 2.0,
) -> Generator[ProgressTracker, None, None]:
    """
    Context manager for progress tracking.

    Args:
        total: Total number of items to process
        description: Description of the operation
        show_progress: Whether to show progress updates
        update_interval: Seconds between progress updates

    Yields:
        ProgressTracker instance
    """
    tracker = ProgressTracker(total, description, show_progress, update_interval)
    try:
        tracker.start()
        yield tracker
    finally:
        tracker.complete()


def estimate_query_size(query: str) -> int:
    """
    Estimate the size of a query based on its characteristics.

    Args:
        query: The search query string

    Returns:
        Estimated number of results
    """
    # Simple heuristics for query size estimation
    query_lower = query.lower()

    # Very broad queries
    if len(query) <= 2:
        return 10000  # Very broad, likely many results

    # Common medical terms that are likely to have many results
    broad_terms = [
        "pain",
        "fever",
        "headache",
        "cough",
        "diabetes",
        "hypertension",
        "cancer",
        "heart",
        "lung",
        "liver",
        "kidney",
        "blood",
        "infection",
    ]

    if any(term in query_lower for term in broad_terms):
        return 5000

    # Specific terms with modifiers
    if any(word in query_lower for word in ["acute", "chronic", "severe", "mild"]):
        return 2000

    # Very specific terms (likely fewer results)
    if len(query) > 10 and any(char.isdigit() for char in query):
        return 500

    # Default estimate
    return 1000


def get_operation_timeout(operation_type: str, query_size: Optional[int] = None) -> int:
    """
    Get appropriate timeout for different operation types.

    Args:
        operation_type: Type of operation ('search', 'graph', 'relationships')
        query_size: Estimated size of the query

    Returns:
        Timeout in seconds
    """
    from athena_client.settings import get_settings

    settings = get_settings()

    # Base timeouts
    base_timeouts = {
        "search": settings.ATHENA_SEARCH_TIMEOUT_SECONDS,
        "graph": settings.ATHENA_GRAPH_TIMEOUT_SECONDS,
        "relationships": settings.ATHENA_RELATIONSHIPS_TIMEOUT_SECONDS,
        "details": settings.ATHENA_TIMEOUT_SECONDS,
    }

    base_timeout = base_timeouts.get(operation_type, settings.ATHENA_TIMEOUT_SECONDS)

    # Adjust based on query size
    if query_size:
        if query_size > 10000:
            return int(base_timeout * 2.5)  # Very large queries
        elif query_size > 5000:
            return int(base_timeout * 2.0)  # Large queries
        elif query_size > 1000:
            return int(base_timeout * 1.5)  # Medium queries

    return base_timeout


def format_large_query_warning(query: str, estimated_size: int) -> str:
    """
    Generate a user-friendly warning for large queries.

    Args:
        query: The search query
        estimated_size: Estimated number of results

    Returns:
        Warning message
    """
    if estimated_size < 1000:
        return ""

    warning = f"‚ö†Ô∏è  Large query detected: '{query}' "

    if estimated_size > 10000:
        warning += f"(estimated {estimated_size:,}+ results)\n"
        warning += "üí° Suggestions:\n"
        warning += "   ‚Ä¢ Add more specific terms to narrow results\n"
        warning += "   ‚Ä¢ Use domain or vocabulary filters\n"
        warning += "   ‚Ä¢ Consider using smaller page sizes\n"
        warning += "   ‚Ä¢ This query may take several minutes to complete"
    elif estimated_size > 5000:
        warning += f"(estimated {estimated_size:,}+ results)\n"
        warning += "üí° Consider adding filters to reduce results"
    else:
        warning += f"(estimated {estimated_size:,}+ results)"

    return warning

```

## Folder: athena_client/models

### File: `athena_client/athena_client/models/__init__.py`
<a name="athena_client-athena_client-models-__init__py"></a>
```python
"""
Pydantic models for Athena API responses.

This module defines Pydantic models for the various responses from the Athena API.
"""

from enum import Enum
from typing import Any, ClassVar, Dict, List, Optional, Union, cast

import orjson
from pydantic import BaseModel as PydanticBaseModel
from pydantic import ConfigDict, Field, model_validator


def _json_dumps(value: Any, *, default: Any) -> str:
    """Serialize to JSON using orjson."""
    return orjson.dumps(value, default=default).decode()


class BaseModel(PydanticBaseModel):
    """Project-wide Pydantic base model using orjson."""

    model_config: ClassVar[ConfigDict] = cast(
        ConfigDict,
        {
            "populate_by_name": True,
            "extra": "ignore",
        },
    )

    def model_dump_json(self, **kwargs: Any) -> str:
        """Serialize model to JSON using orjson."""
        return orjson.dumps(self.model_dump(**kwargs)).decode()

    @classmethod
    def model_validate_json(
        cls: type["BaseModel"], json_data: Union[str, bytes], **kwargs: Any
    ) -> "BaseModel":
        """Deserialize model from JSON using orjson."""
        return cls.model_validate(orjson.loads(json_data), **kwargs)


class Domain(BaseModel):
    """Domain information for a concept."""

    id: int = Field(..., description="Domain ID")
    name: str = Field(..., description="Domain name")


class Vocabulary(BaseModel):
    """Vocabulary information for a concept."""

    id: str = Field(..., description="Vocabulary ID")
    name: str = Field(..., description="Vocabulary name")


class ConceptClass(BaseModel):
    """Concept class information."""

    id: str = Field(..., description="Concept class ID")
    name: str = Field(..., description="Concept class name")


class ConceptType(str, Enum):
    """Concept standard type."""

    STANDARD = "Standard"
    CLASSIFICATION = "Classification"
    NON_STANDARD = "Non-standard"


class Concept(BaseModel):
    """Basic concept information returned in search results."""

    id: int = Field(..., description="Concept ID")
    name: str = Field(..., description="Concept name")
    domain: str = Field(..., description="Domain name")
    vocabulary: str = Field(..., description="Vocabulary name")
    className: str = Field(..., description="Concept class name")
    standardConcept: Optional[ConceptType] = Field(
        None, description="Standard concept flag"
    )
    code: str = Field(..., description="Concept code")
    invalidReason: Optional[str] = Field(None, description="Invalid reason")
    score: Optional[float] = Field(None, description="Search score")


class ConceptSearchResponse(BaseModel):
    """Response from the /concepts search endpoint."""

    content: List[Concept] = Field(..., description="List of concept results")
    pageable: Dict[str, Any] = Field(..., description="Pagination information")
    totalElements: Optional[int] = Field(None, description="Total number of results")
    last: Optional[bool] = Field(None, description="Whether this is the last page")
    totalPages: Optional[int] = Field(None, description="Total number of pages")
    sort: Optional[Dict[str, Any]] = Field(None, description="Sort information")
    first: Optional[bool] = Field(None, description="Whether this is the first page")
    size: Optional[int] = Field(None, description="Page size")
    number: Optional[int] = Field(None, description="Page number")
    numberOfElements: Optional[int] = Field(
        None, description="Number of elements in this page"
    )
    empty: Optional[bool] = Field(None, description="Whether the result is empty")
    facets: Optional[Dict[str, Any]] = Field(None, description="Search facets")


class ConceptDetails(BaseModel):
    """Detailed concept information from the /concepts/{id} endpoint."""

    id: int = Field(..., description="Concept ID")
    name: str = Field(..., description="Concept name")
    domainId: str = Field(..., description="Domain ID")
    vocabularyId: str = Field(..., description="Vocabulary ID")
    conceptClassId: str = Field(..., description="Concept class ID")
    standardConcept: Optional[ConceptType] = Field(
        None, description="Standard concept flag"
    )
    conceptCode: str = Field(..., description="Concept code")
    invalidReason: Optional[str] = Field(None, description="Invalid reason")
    validStart: str = Field(..., description="Valid start date")
    validEnd: str = Field(..., description="Valid end date")
    synonyms: Optional[List[Union[str, Dict[str, Any]]]] = Field(
        None, description="Concept synonyms"
    )
    validTerm: Optional[Union[str, Dict[str, Any]]] = Field(
        None, description="Valid term"
    )
    vocabularyName: Optional[str] = Field(None, description="Vocabulary name")
    vocabularyVersion: Optional[str] = Field(None, description="Vocabulary version")
    vocabularyReference: Optional[str] = Field(None, description="Vocabulary reference")
    links: Optional[Dict[str, Any]] = Field(
        None, description="HATEOAS links", alias="_links"
    )

    @model_validator(mode="before")
    @classmethod
    def normalize_synonyms(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        synonyms = values.get("synonyms")
        if synonyms and isinstance(synonyms, list):
            normalized = []
            for item in synonyms:
                if isinstance(item, str):
                    normalized.append(item)
                elif isinstance(item, dict):
                    # Use 'synonymName' if present, else join all string values
                    if "synonymName" in item:
                        normalized.append(item["synonymName"])
                    else:
                        # Fallback: join all string values in the dict
                        str_values = [
                            str(v) for v in item.values() if isinstance(v, str)
                        ]
                        normalized.append(", ".join(str_values))
            values["synonyms"] = normalized
        return values

    @model_validator(mode="before")
    @classmethod
    def normalize_valid_term(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        valid_term = values.get("validTerm")
        if valid_term and isinstance(valid_term, dict):
            # Extract name from validTerm dict if it's a dictionary
            if "name" in valid_term:
                values["validTerm"] = valid_term["name"]
            else:
                # Fallback: convert to string representation
                values["validTerm"] = str(valid_term)
        return values


class RelationshipItem(BaseModel):
    """Information about a relationship between concepts."""

    targetConceptId: int = Field(..., description="Target concept ID")
    targetConceptName: str = Field(..., description="Target concept name")
    targetVocabularyId: str = Field(..., description="Target vocabulary ID")
    relationshipId: str = Field(..., description="Relationship ID")
    relationshipName: str = Field(..., description="Relationship name")


class RelationshipGroup(BaseModel):
    """Group of relationships with the same type."""

    relationshipName: str = Field(..., description="Relationship name")
    relationships: List[RelationshipItem] = Field(
        ..., description="List of relationships"
    )


class ConceptRelationship(BaseModel):
    """Response from the /concepts/{id}/relationships endpoint."""

    count: int = Field(..., description="Total count of relationships")
    items: List[RelationshipGroup] = Field(
        ..., description="List of relationship groups"
    )


class GraphTerm(BaseModel):
    """Term in the concept relationship graph."""

    id: int = Field(..., description="Term ID")
    name: str = Field(..., description="Term name")
    weight: int = Field(..., description="Term weight")
    depth: int = Field(..., description="Term depth")
    count: int = Field(..., description="Term count")
    isCurrent: bool = Field(..., description="Whether this is the current concept")


class GraphLink(BaseModel):
    """Link in the concept relationship graph."""

    source: int = Field(..., description="Source term ID")
    target: int = Field(..., description="Target term ID")
    relationshipId: Optional[str] = Field(None, description="Relationship ID")
    relationshipName: Optional[str] = Field(None, description="Relationship name")


class ConceptRelationsGraph(BaseModel):
    """Response from the /concepts/{id}/relations endpoint."""

    terms: List[GraphTerm] = Field(..., description="Graph terms")
    links: List[GraphLink] = Field(..., description="Graph links")
    connectionsCount: Optional[int] = Field(None, description="Total connections count")


# Re-export models
__all__ = [
    "Concept",
    "ConceptClass",
    "ConceptDetails",
    "ConceptRelationsGraph",
    "ConceptRelationship",
    "ConceptSearchResponse",
    "ConceptType",
    "Domain",
    "GraphLink",
    "GraphTerm",
    "RelationshipGroup",
    "RelationshipItem",
    "Vocabulary",
]

```

## Folder: athena_client/db

### File: `athena_client/athena_client/db/__init__.py`
<a name="athena_client-athena_client-db-__init__py"></a>
```python

```

### File: `athena_client/athena_client/db/base.py`
<a name="athena_client-athena_client-db-basepy"></a>
```python
from typing import Dict, List, Protocol


class DatabaseConnector(Protocol):
    """Protocol for database connectors."""

    def validate_concepts(self, concept_ids: List[int]) -> List[int]:
        """Validate concept IDs against the local database."""
        ...

    def get_descendants(self, concept_ids: List[int]) -> List[int]:
        """Return descendant concept IDs for the given ancestors."""
        ...

    def get_standard_mapping(
        self, non_standard_concept_ids: List[int]
    ) -> Dict[int, int]:
        """Return mapping from non-standard to standard concept IDs."""
        ...

```

### File: `athena_client/athena_client/db/sqlalchemy_connector.py`
<a name="athena_client-athena_client-db-sqlalchemy_connectorpy"></a>
```python
from typing import Dict, List

from sqlalchemy import bindparam, create_engine, text
from sqlalchemy.engine import Engine


class SQLAlchemyConnector:
    """Database connector using SQLAlchemy Core."""

    def __init__(self, engine: Engine) -> None:
        self._engine = engine

    def validate_concepts(self, concept_ids: List[int]) -> List[int]:
        if not concept_ids:
            return []

        stmt = text(
            """
                SELECT concept_id
                FROM concept
                WHERE concept_id IN :ids AND standard_concept = 'S'
                """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(concept_ids)})
            validated_ids = [row[0] for row in result]

        return validated_ids

    def get_descendants(self, concept_ids: List[int]) -> List[int]:
        """Retrieve descendant concept IDs for the given ancestors."""
        if not concept_ids:
            return []

        stmt = text(
            """
                SELECT descendant_concept_id
                FROM concept_ancestor
                WHERE ancestor_concept_id IN :ids
                """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(concept_ids)})
            descendant_ids = [row[0] for row in result]

        return list(set(descendant_ids) - set(concept_ids))

    def get_standard_mapping(
        self, non_standard_concept_ids: List[int]
    ) -> Dict[int, int]:
        """Find standard mappings for the given non-standard concept IDs."""
        if not non_standard_concept_ids:
            return {}

        stmt = text(
            """
            SELECT cr.concept_id_1, cr.concept_id_2, c2.standard_concept
            FROM concept_relationship cr
            JOIN concept c2 ON cr.concept_id_2 = c2.concept_id
            WHERE cr.concept_id_1 IN :ids
              AND cr.relationship_id = 'Maps to'
              AND cr.invalid_reason IS NULL
            """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(non_standard_concept_ids)})
            mapping: Dict[int, int] = {}
            for row in result:
                concept_id_1, concept_id_2, standard_flag = row
                if standard_flag == "S" and concept_id_1 not in mapping:
                    mapping[concept_id_1] = concept_id_2

        return mapping

    @staticmethod
    def from_connection_string(connection_string: str) -> "SQLAlchemyConnector":
        engine = create_engine(connection_string)
        return SQLAlchemyConnector(engine)

```

## Folder: .ruff_cache

## Folder: .ruff_cache/0.12.0

## Folder: .ruff_cache/0.11.10

## Folder: tests

### File: `athena_client/tests/__init__.py`
<a name="athena_client-tests-__init__py"></a>
```python
"""
Tests for the athena-client package.
"""

```

### File: `athena_client/tests/conftest.py`
<a name="athena_client-tests-conftestpy"></a>
```python
"""
Test fixtures and configuration for Athena client tests.
"""

from unittest.mock import Mock, patch

import pytest

from athena_client import Athena
from athena_client.client import AthenaClient


@pytest.fixture
def mock_http_client():
    """Mock HttpClient to avoid making real API calls."""
    mock_instance = Mock()
    with patch("athena_client.client.HttpClient", return_value=mock_instance):
        # Disable retry mechanism for testing
        mock_instance.max_retries = 0
        yield mock_instance


@pytest.fixture
def athena_client():
    """Create a mock Athena client for testing."""
    mock_instance = Mock()
    with patch("athena_client.client.HttpClient", return_value=mock_instance):
        # Disable retry mechanism for testing
        mock_instance.max_retries = 0
        client = AthenaClient()
        client.http = mock_instance
        yield client


@pytest.fixture
def athena_facade(mock_http_client):
    """Get a mocked Athena facade."""
    facade = Athena()
    return facade

```

### File: `athena_client/tests/test_async_client.py`
<a name="athena_client-tests-test_async_clientpy"></a>
```python
"""Tests for the async client module."""

from unittest.mock import AsyncMock, Mock, patch

import httpx
import pytest

from athena_client.async_client import AsyncHttpClient, AthenaAsyncClient
from athena_client.exceptions import AthenaError, ClientError, NetworkError, ServerError
from athena_client.models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
)


class TestAsyncHttpClient:
    """Test cases for the AsyncHttpClient class."""

    @pytest.mark.asyncio
    async def test_init_with_defaults(self):
        """Test AsyncHttpClient initialization with default values."""
        with patch("athena_client.async_client.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_BASE_URL = "https://api.example.com"
            mock_settings.ATHENA_TIMEOUT_SECONDS = 30
            mock_settings.ATHENA_MAX_RETRIES = 3
            mock_settings.ATHENA_BACKOFF_FACTOR = 0.3
            mock_get_settings.return_value = mock_settings

            client = AsyncHttpClient()

            assert client.base_url == "https://api.example.com"
            assert client.timeout == 30
            assert client.max_retries == 3
            assert client.backoff_factor == 0.3

    @pytest.mark.asyncio
    async def test_init_with_custom_values(self):
        """Test AsyncHttpClient initialization with custom values."""
        client = AsyncHttpClient(
            base_url="https://custom.api.com",
            token="test-token",
            timeout=60,
            max_retries=5,
            backoff_factor=0.5,
        )

        assert client.base_url == "https://custom.api.com"
        assert client.timeout == 60
        assert client.max_retries == 5
        assert client.backoff_factor == 0.5

    @pytest.mark.asyncio
    async def test_build_url(self):
        """Test URL building."""
        client = AsyncHttpClient(base_url="https://api.example.com")
        url = client._build_url("/concepts/search")
        assert url == "https://api.example.com/concepts/search"

    @pytest.mark.asyncio
    async def test_handle_response_success(self):
        """Test successful response handling."""
        client = AsyncHttpClient()
        response = Mock()
        response.json.return_value = {"result": "success"}

        result = await client._handle_response(response)
        assert result == {"result": "success"}

    @pytest.mark.asyncio
    async def test_handle_response_client_error(self):
        """Test client error response handling."""
        client = AsyncHttpClient()
        response = Mock()
        response.status_code = 400
        response.reason_phrase = "Bad Request"
        response.text = "Invalid request"
        response.raise_for_status.side_effect = httpx.HTTPStatusError(
            "400 Bad Request", request=Mock(), response=response
        )

        with pytest.raises(ClientError) as exc_info:
            await client._handle_response(response)
        assert "400 Bad Request" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_handle_response_server_error(self):
        """Test server error response handling."""
        client = AsyncHttpClient()
        response = Mock()
        response.status_code = 500
        response.reason_phrase = "Internal Server Error"
        response.text = "Server error"
        response.raise_for_status.side_effect = httpx.HTTPStatusError(
            "500 Internal Server Error", request=Mock(), response=response
        )

        with pytest.raises(ServerError) as exc_info:
            await client._handle_response(response)
        assert "500 Internal Server Error" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_handle_response_decoding_error(self):
        """Test JSON decoding error handling."""
        client = AsyncHttpClient()
        response = Mock()
        response.raise_for_status.side_effect = httpx.DecodingError("Invalid JSON")

        with pytest.raises(AthenaError) as exc_info:
            await client._handle_response(response)

        assert "Invalid JSON" in str(exc_info.value)

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_success(self, mock_build_headers):
        """Test successful request."""
        mock_build_headers.return_value = {"Authorization": "Bearer token"}

        client = AsyncHttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}

        with patch.object(
            client.client, "request", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.request("GET", "/test")
            assert result == {"result": "success"}

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_with_params(self, mock_build_headers):
        """Test request with parameters."""
        mock_build_headers.return_value = {}

        client = AsyncHttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}

        with patch.object(
            client.client, "request", new_callable=AsyncMock, return_value=mock_response
        ) as mock_request:
            await client.request("GET", "/test", params={"key": "value"})
            mock_request.assert_called_once()
            call_args = mock_request.call_args
            assert call_args[1]["params"] == {"key": "value"}

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_with_data(self, mock_build_headers):
        """Test request with data."""
        mock_build_headers.return_value = {}

        client = AsyncHttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}

        with patch.object(
            client.client, "request", new_callable=AsyncMock, return_value=mock_response
        ) as mock_request:
            await client.request("POST", "/test", data={"key": "value"})
            mock_request.assert_called_once()
            call_args = mock_request.call_args
            assert call_args[1]["content"] == b'{"key": "value"}'

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_raw_response(self, mock_build_headers):
        """Test request with raw response."""
        mock_build_headers.return_value = {}

        client = AsyncHttpClient()
        mock_response = Mock()
        mock_response.status_code = 200

        with patch.object(
            client.client, "request", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.request("GET", "/test", raw_response=True)
            assert result == mock_response

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_timeout_error(self, mock_build_headers):
        """Test request with timeout error."""
        mock_build_headers.return_value = {}

        client = AsyncHttpClient()

        with patch.object(
            client.client,
            "request",
            new_callable=AsyncMock,
            side_effect=httpx.TimeoutException("Request timeout"),
        ):
            with pytest.raises(NetworkError) as exc_info:
                await client.request("GET", "/test")
            assert "Request timeout" in str(exc_info.value)

    @patch("athena_client.async_client.build_headers")
    @pytest.mark.asyncio
    async def test_request_connect_error(self, mock_build_headers):
        """Test request with connection error."""
        mock_build_headers.return_value = {}

        client = AsyncHttpClient()

        with patch.object(
            client.client,
            "request",
            new_callable=AsyncMock,
            side_effect=httpx.ConnectError("Connection failed"),
        ):
            with pytest.raises(NetworkError) as exc_info:
                await client.request("GET", "/test")
            assert "Connection failed" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_get_method(self):
        """Test GET method."""
        client = AsyncHttpClient()

        with patch.object(client, "request", new_callable=AsyncMock) as mock_request:
            mock_request.return_value = {"result": "success"}
            await client.get("/test", params={"key": "value"})
            mock_request.assert_called_once_with(
                "GET", "/test", params={"key": "value"}, raw_response=False
            )

    @pytest.mark.asyncio
    async def test_post_method(self):
        """Test POST method."""
        client = AsyncHttpClient()

        with patch.object(client, "request", new_callable=AsyncMock) as mock_request:
            mock_request.return_value = {"result": "success"}
            await client.post("/test", data={"key": "value"})
            mock_request.assert_called_once_with(
                "POST", "/test", data={"key": "value"}, params=None, raw_response=False
            )

    @pytest.mark.asyncio
    async def test_backoff_import_error(self):
        """Test that import error is raised when backoff is not available."""
        # Clear the module cache to force re-import
        import sys

        if "athena_client.async_client" in sys.modules:
            del sys.modules["athena_client.async_client"]

        with patch.dict("sys.modules", {"backoff": None}):
            with pytest.raises(
                ImportError, match="backoff is required for the async client"
            ):
                import importlib

                importlib.import_module("athena_client.async_client")


class TestAthenaAsyncClient:
    """Test cases for the AthenaAsyncClient class."""

    @pytest.mark.asyncio
    async def test_init(self):
        """Test AthenaAsyncClient initialization."""
        client = AthenaAsyncClient(
            base_url="https://api.example.com",
            token="test-token",
            timeout=60,
        )

        assert client.http.base_url == "https://api.example.com"

    @pytest.mark.asyncio
    async def test_search_concepts(self):
        """Test search_concepts method."""
        client = AthenaAsyncClient()
        mock_response = {
            "content": [{"id": 1, "name": "Test Concept"}],
            "totalElements": 1,
            "totalPages": 1,
        }

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.search_concepts("test query")
            assert result == mock_response

    @pytest.mark.asyncio
    async def test_search_concepts_with_filters(self):
        """Test search_concepts method with filters."""
        client = AthenaAsyncClient()
        mock_response = {"content": [], "totalElements": 0}

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            await client.search_concepts(
                query="test",
                domain="Condition",
                vocabulary="SNOMED",
                standard_concept="S",
                page_size=50,
                page=1,
            )

    @pytest.mark.asyncio
    async def test_get_concept_details(self):
        """Test get_concept_details method."""
        client = AthenaAsyncClient()
        mock_response = {
            "id": 1,
            "name": "Test Concept",
            "domainId": "Condition",
            "vocabularyId": "SNOMED",
            "conceptClassId": "Clinical Finding",
            "conceptCode": "TEST001",
            "validStart": "2020-01-01",
            "validEnd": "2099-12-31",
            "vocabulary": {"name": "Test Vocab"},
            "domain": {"name": "Test Domain"},
        }

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.get_concept_details(1)
            assert isinstance(result, ConceptDetails)
            assert result.id == 1
            assert result.name == "Test Concept"

    @pytest.mark.asyncio
    async def test_get_concept_relationships(self):
        """Test get_concept_relationships method."""
        client = AthenaAsyncClient()
        mock_response = {
            "count": 1,
            "items": [
                {
                    "relationshipName": "Is a",
                    "relationships": [
                        {
                            "targetConceptId": 2,
                            "targetConceptName": "Test Target",
                            "targetVocabularyId": "SNOMED",
                            "relationshipId": "Is a",
                            "relationshipName": "Is a",
                        }
                    ],
                }
            ],
        }

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.get_concept_relationships(1)
            assert isinstance(result, ConceptRelationship)
            assert result.count == 1

    @pytest.mark.asyncio
    async def test_get_concept_relationships_with_filters(self):
        """Test get_concept_relationships method with filters."""
        client = AthenaAsyncClient()
        mock_response = {"count": 0, "items": []}

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.get_concept_relationships(
                1,
                relationship_id="Is a",
                only_standard=True,
            )
            assert isinstance(result, ConceptRelationship)
            assert result.count == 0

    @pytest.mark.asyncio
    async def test_get_concept_graph(self):
        """Test get_concept_graph method."""
        client = AthenaAsyncClient()
        mock_response = {
            "terms": [
                {
                    "id": 1,
                    "name": "Test Node",
                    "weight": 1,
                    "depth": 0,
                    "count": 1,
                    "isCurrent": True,
                }
            ],
            "links": [
                {
                    "source": 1,
                    "target": 2,
                    "relationshipId": "Is a",
                    "relationshipName": "Is a",
                }
            ],
        }

        with patch.object(
            client.http, "get", new_callable=AsyncMock, return_value=mock_response
        ):
            result = await client.get_concept_graph(1, depth=5, zoom_level=3)
            assert isinstance(result, ConceptRelationsGraph)
            assert len(result.terms) == 1
            assert len(result.links) == 1

    @pytest.mark.asyncio
    async def test_httpx_import_error(self):
        """Test that AttributeError is raised when httpx is not available."""
        # Clear the module cache to force re-import
        import sys

        if "athena_client.async_client" in sys.modules:
            del sys.modules["athena_client.async_client"]

        with patch.dict("sys.modules", {"httpx": None}):
            with pytest.raises(
                AttributeError, match="httpx is required for the async client"
            ):
                import importlib

                importlib.import_module("athena_client.async_client")

    @pytest.mark.asyncio
    async def test_generate_concept_set_without_db(self):
        client = AthenaAsyncClient()

        with pytest.raises(RuntimeError):
            await client.generate_concept_set("test")

```

### File: `athena_client/tests/test_auth.py`
<a name="athena_client-tests-test_authpy"></a>
```python
"""Tests for the authentication module."""

from unittest.mock import Mock, patch

from athena_client.auth import build_headers


class TestAuth:
    """Test cases for the authentication module."""

    def test_build_headers_no_auth(self):
        """Test building headers without authentication."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = None
            mock_get_settings.return_value = mock_settings

            headers = build_headers("GET", "https://api.example.com/test", b"")

            assert headers == {}

    def test_build_headers_with_token(self):
        """Test building headers with Bearer token authentication."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = "test-token"
            mock_settings.ATHENA_CLIENT_ID = "test-client"
            mock_settings.ATHENA_PRIVATE_KEY = None
            mock_get_settings.return_value = mock_settings

            headers = build_headers("GET", "https://api.example.com/test", b"")

            assert headers["X-Athena-Auth"] == "Bearer test-token"
            assert headers["X-Athena-Client-Id"] == "test-client"

    def test_build_headers_with_token_no_client_id(self):
        """Test building headers with token but no client ID."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = "test-token"
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = None
            mock_get_settings.return_value = mock_settings

            headers = build_headers("GET", "https://api.example.com/test", b"")

            assert headers["X-Athena-Auth"] == "Bearer test-token"
            assert headers["X-Athena-Client-Id"] == "athena-client"

    def test_build_headers_with_hmac(self):
        """Test building headers with HMAC authentication."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = (
                "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----"
            )
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_b64encode = Mock()
            mock_b64encode.return_value.decode.return_value = "test-signature"

            mock_serialization = Mock()
            mock_key = Mock()
            mock_serialization.load_pem_private_key.return_value = mock_key
            mock_key.sign.return_value = b"test-signature"

            mock_hashes = Mock()
            mock_hashes.SHA256.return_value = "sha256"

            with (
                patch("athena_client.auth.datetime", mock_datetime),
                patch("athena_client.auth.b64encode", mock_b64encode),
            ):
                headers = build_headers(
                    "GET",
                    "https://api.example.com/test",
                    b"",
                    serialization_module=mock_serialization,
                    hashes_module=mock_hashes,
                )
                assert "X-Athena-Nonce" in headers
                assert "X-Athena-Hmac" in headers
                assert headers["X-Athena-Nonce"] == "2023-01-01T00:00:00Z"
                assert headers["X-Athena-Hmac"] == "test-signature"

    def test_build_headers_with_token_and_hmac(self):
        """Test building headers with both token and HMAC authentication."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = "test-token"
            mock_settings.ATHENA_CLIENT_ID = "test-client"
            mock_settings.ATHENA_PRIVATE_KEY = (
                "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----"
            )
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_b64encode = Mock()
            mock_b64encode.return_value.decode.return_value = "test-signature"

            mock_serialization = Mock()
            mock_key = Mock()
            mock_serialization.load_pem_private_key.return_value = mock_key
            mock_key.sign.return_value = b"test-signature"

            mock_hashes = Mock()
            mock_hashes.SHA256.return_value = "sha256"

            with (
                patch("athena_client.auth.datetime", mock_datetime),
                patch("athena_client.auth.b64encode", mock_b64encode),
            ):
                build_headers(
                    "POST",
                    "https://api.example.com/test",
                    b"test-body",
                    serialization_module=mock_serialization,
                    hashes_module=mock_hashes,
                )
                # Verify the signing string includes the body
                expected_to_sign = "POST\nhttps://api.example.com/test\n\n2023-01-01T00:00:00Z\ntest-body"
                mock_key.sign.assert_called_once_with(
                    expected_to_sign.encode(), "sha256"
                )

    def test_build_headers_hmac_cryptography_import_error(self):
        """Test HMAC authentication when cryptography is not available."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = "test-key"
            mock_get_settings.return_value = mock_settings

            # Patch sys.modules to simulate ImportError for cryptography and submodules
            import sys

            with patch.dict(
                sys.modules,
                {"cryptography": None, "cryptography.hazmat.primitives": None},
            ):
                with patch("athena_client.auth.logger") as mock_logger:
                    headers = build_headers("GET", "https://api.example.com/test", b"")
                    assert headers == {}
                    mock_logger.warning.assert_called_once()
                    mock_logger.warning.assert_called_once()

    def test_build_headers_hmac_exception(self):
        """Test HMAC authentication when an exception occurs."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = "invalid-key"
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_serialization = Mock()
            mock_serialization.load_pem_private_key.side_effect = Exception(
                "Invalid key"
            )

            with patch("athena_client.auth.datetime", mock_datetime):
                with patch("athena_client.auth.logger") as mock_logger:
                    headers = build_headers(
                        "GET",
                        "https://api.example.com/test",
                        b"",
                        serialization_module=mock_serialization,
                        hashes_module=Mock(),
                    )

                    assert headers == {}
                    mock_logger.error.assert_called_once()

    def test_build_headers_different_methods(self):
        """Test building headers with different HTTP methods."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = (
                "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----"
            )
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_b64encode = Mock()
            mock_b64encode.return_value.decode.return_value = "test-signature"

            mock_serialization = Mock()
            mock_key = Mock()
            mock_serialization.load_pem_private_key.return_value = mock_key
            mock_key.sign.return_value = b"test-signature"

            mock_hashes = Mock()
            mock_hashes.SHA256.return_value = "sha256"

            with (
                patch("athena_client.auth.datetime", mock_datetime),
                patch("athena_client.auth.b64encode", mock_b64encode),
            ):
                # Test different HTTP methods
                for method in ["GET", "POST", "PUT", "DELETE"]:
                    headers = build_headers(
                        method,
                        "https://api.example.com/test",
                        b"",
                        serialization_module=mock_serialization,
                        hashes_module=mock_hashes,
                    )
                    assert "X-Athena-Nonce" in headers
                    assert "X-Athena-Hmac" in headers
                    # Verify the signing string includes the method
                    expected_to_sign = f"{method}\nhttps://api.example.com/test\n\n2023-01-01T00:00:00Z\n"
                    mock_key.sign.assert_called_with(
                        expected_to_sign.encode(), "sha256"
                    )

    def test_build_headers_with_body(self):
        """Test building headers with request body."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = (
                "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----"
            )
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_b64encode = Mock()
            mock_b64encode.return_value.decode.return_value = "test-signature"

            mock_serialization = Mock()
            mock_key = Mock()
            mock_serialization.load_pem_private_key.return_value = mock_key
            mock_key.sign.return_value = b"test-signature"

            mock_hashes = Mock()
            mock_hashes.SHA256.return_value = "sha256"

            with (
                patch("athena_client.auth.datetime", mock_datetime),
                patch("athena_client.auth.b64encode", mock_b64encode),
            ):
                build_headers(
                    "POST",
                    "https://api.example.com/test",
                    b"test-body",
                    serialization_module=mock_serialization,
                    hashes_module=mock_hashes,
                )
                # Verify the signing string includes the body
                expected_to_sign = "POST\nhttps://api.example.com/test\n\n2023-01-01T00:00:00Z\ntest-body"
                mock_key.sign.assert_called_once_with(
                    expected_to_sign.encode(), "sha256"
                )

    def test_build_headers_empty_body(self):
        """Test building headers with empty body."""
        with patch("athena_client.auth.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_TOKEN = None
            mock_settings.ATHENA_CLIENT_ID = None
            mock_settings.ATHENA_PRIVATE_KEY = (
                "-----BEGIN PRIVATE KEY-----\ntest-key\n-----END PRIVATE KEY-----"
            )
            mock_get_settings.return_value = mock_settings

            # Mock the imports that happen inside build_headers
            mock_datetime = Mock()
            mock_datetime.utcnow.return_value.strftime.return_value = (
                "2023-01-01T00:00:00Z"
            )

            mock_b64encode = Mock()
            mock_b64encode.return_value.decode.return_value = "test-signature"

            mock_serialization = Mock()
            mock_key = Mock()
            mock_serialization.load_pem_private_key.return_value = mock_key
            mock_key.sign.return_value = b"test-signature"

            mock_hashes = Mock()
            mock_hashes.SHA256.return_value = "sha256"

            with (
                patch("athena_client.auth.datetime", mock_datetime),
                patch("athena_client.auth.b64encode", mock_b64encode),
            ):
                build_headers(
                    "GET",
                    "https://api.example.com/test",
                    b"",
                    serialization_module=mock_serialization,
                    hashes_module=mock_hashes,
                )
                # Verify the signing string includes empty body
                expected_to_sign = (
                    "GET\nhttps://api.example.com/test\n\n2023-01-01T00:00:00Z\n"
                )
                mock_key.sign.assert_called_once_with(
                    expected_to_sign.encode(), "sha256"
                )

```

### File: `athena_client/tests/test_cli.py`
<a name="athena_client-tests-test_clipy"></a>
```python
"""Tests for the CLI module."""

import json
import sys
from unittest.mock import AsyncMock, Mock, patch

import pytest
from click.testing import CliRunner

from athena_client.cli import _create_client, _format_output, cli


class TestCLI:
    """Test cases for the CLI module."""

    def test_create_client(self):
        """Test client creation with parameters."""
        with patch("athena_client.cli.Athena") as mock_athena:
            mock_client = Mock()
            mock_athena.return_value = mock_client

            result = _create_client(
                base_url="https://api.example.com",
                token="test-token",
                timeout=60,
                retries=5,
            )

            mock_athena.assert_called_once_with(
                base_url="https://api.example.com",
                token="test-token",
                timeout=60,
                max_retries=5,
            )
            assert result == mock_client

    def test_create_client_with_none_values(self):
        """Test client creation with None values."""
        with patch("athena_client.cli.Athena") as mock_athena:
            mock_client = Mock()
            mock_athena.return_value = mock_client

            result = _create_client(None, None, None, None)

            mock_athena.assert_called_once_with(
                base_url=None,
                token=None,
                timeout=None,
                max_retries=None,
            )
            assert result == mock_client

    def test_format_output_json_string(self):
        """Test JSON output formatting with string input."""
        data = '{"key": "value"}'
        _format_output(data, "json")
        # This should just print the string as-is

    def test_format_output_json_dict(self):
        """Test JSON output formatting with dictionary input."""
        data = {"key": "value", "number": 123}

        with patch("builtins.print") as mock_print:
            _format_output(data, "json")
            mock_print.assert_called_once_with(json.dumps(data, indent=2))

    def test_format_output_yaml_success(self):
        """Test YAML output formatting."""
        data = {"key": "value", "number": 123}
        mock_yaml = Mock()
        mock_yaml.dump.return_value = "key: value\nnumber: 123\n"
        with patch.dict("sys.modules", {"yaml": mock_yaml}):
            with patch("builtins.print") as mock_print:
                _format_output(data, "yaml")
                mock_print.assert_called_once_with("key: value\nnumber: 123\n")

    def test_format_output_yaml_import_error(self):
        """Test YAML output formatting when pyyaml is not available."""
        data = {"key": "value"}
        with patch.dict("sys.modules", {"yaml": None}):
            with patch("builtins.print") as mock_print, patch("sys.exit") as mock_exit:
                _format_output(data, "yaml")
                mock_print.assert_called()
                mock_exit.assert_called_once_with(1)

    def test_format_output_table_with_search_result(self):
        """Test table output formatting with SearchResult."""
        mock_search_result = Mock()
        mock_search_result.to_list.return_value = [
            {
                "id": 1,
                "name": "Test Company",
                "code": "TEST001",
                "vocabulary": "SNOMED",
                "domain": "Condition",
                "className": "Clinical Finding",
            }
        ]

        with patch("athena_client.cli.Table") as mock_table_class:
            mock_table = Mock()
            mock_table_class.return_value = mock_table

            with patch("builtins.print"):
                _format_output(mock_search_result, "table", Mock())

                mock_table_class.assert_called_once()
                mock_table.add_column.assert_called()
                mock_table.add_row.assert_called()

    def test_format_output_table_empty_results(self):
        """Test table output formatting with empty results."""
        mock_search_result = Mock()
        mock_search_result.to_list.return_value = []

        mock_console = Mock()

        with patch("athena_client.cli.rich"):
            _format_output(mock_search_result, "table", mock_console)

            # Should print "No results found" message
            mock_console.print.assert_called_once()

    def test_format_output_table_with_other_data(self):
        """Test table output formatting with other data types."""
        data = {"key": "value", "number": 42}

        with patch("athena_client.cli.Syntax") as mock_syntax_class:
            mock_syntax = Mock()
            mock_syntax_class.return_value = mock_syntax

            mock_console = Mock()
            _format_output(data, "table", mock_console)

            mock_syntax_class.assert_called_once()
            mock_console.print.assert_called_once_with(mock_syntax)

    def test_format_output_pretty(self):
        """Test pretty output formatting."""
        data = {"key": "value", "number": 123}
        mock_console = Mock()

        with patch("athena_client.cli.rich"):
            _format_output(data, "pretty", mock_console)
            mock_console.print.assert_called_once_with(data)

    def test_format_output_fallback(self):
        """Test fallback output formatting."""
        data = {"key": "value", "number": 123}

        with patch("builtins.print") as mock_print:
            _format_output(data, "unknown", None)
            mock_print.assert_called_once_with(json.dumps(data, indent=2))

    def test_cli_initialization(self):
        """Test CLI initialization."""
        runner = CliRunner()
        result = runner.invoke(
            cli,
            [
                "--base-url",
                "https://api.example.com",
                "--token",
                "test-token",
                "--timeout",
                "60",
                "--retries",
                "5",
                "--output",
                "json",
                "--help",  # Use help to avoid making actual API calls
            ],
        )
        assert result.exit_code in (0, 2)  # Accept both success and usage error

    def test_cli_initialization_no_rich(self):
        """Test CLI initialization without rich."""
        with patch("athena_client.cli.rich", None):
            runner = CliRunner()
            result = runner.invoke(
                cli,
                [
                    "--base-url",
                    "https://api.example.com",
                    "--token",
                    "test-token",
                    "--timeout",
                    "60",
                    "--retries",
                    "5",
                    "--output",
                    "json",
                    "--help",  # Use help to avoid making actual API calls
                ],
            )
            assert result.exit_code in (0, 2)  # Accept both success and usage error

    @patch("athena_client.cli._create_client")
    @patch("athena_client.cli._format_output")
    def test_search_command(self, mock_format_output, mock_create_client):
        """Test search command."""
        mock_client = Mock()
        mock_search_result = Mock()
        mock_client.search.return_value = mock_search_result
        mock_create_client.return_value = mock_client
        runner = CliRunner()
        result = runner.invoke(
            cli,
            [
                "search",
                "test query",
                "--fuzzy",
                "--page-size",
                "50",
                "--page",
                "1",
                "--domain",
                "Condition",
                "--vocabulary",
                "SNOMED",
            ],
        )
        assert result.exit_code == 0
        mock_create_client.assert_called_once()
        mock_client.search.assert_called_once()
        mock_format_output.assert_called_once()

    @patch("athena_client.cli._create_client")
    @patch("athena_client.cli._format_output")
    def test_details_command(self, mock_format_output, mock_create_client):
        """Test details command."""
        mock_client = Mock()
        mock_details = Mock()
        mock_client.details.return_value = mock_details
        mock_create_client.return_value = mock_client
        runner = CliRunner()
        result = runner.invoke(cli, ["details", "123"])
        assert result.exit_code == 0
        mock_create_client.assert_called_once()
        mock_client.details.assert_called_once()
        mock_format_output.assert_called_once()

    @patch("athena_client.cli._create_client")
    @patch("athena_client.cli._format_output")
    def test_relationships_command(self, mock_format_output, mock_create_client):
        """Test relationships command."""
        mock_client = Mock()
        mock_relationships = Mock()
        mock_client.relationships.return_value = mock_relationships
        mock_create_client.return_value = mock_client
        runner = CliRunner()
        result = runner.invoke(
            cli,
            ["relationships", "123", "--relationship-id", "Is a", "--only-standard"],
        )
        assert result.exit_code == 0
        mock_create_client.assert_called_once()
        mock_client.relationships.assert_called_once()
        mock_format_output.assert_called_once()

    @patch("athena_client.cli._create_client")
    @patch("athena_client.cli._format_output")
    def test_graph_command(self, mock_format_output, mock_create_client):
        """Test graph command."""
        mock_client = Mock()
        mock_graph = Mock()
        mock_client.graph.return_value = mock_graph
        mock_create_client.return_value = mock_client
        runner = CliRunner()
        result = runner.invoke(
            cli, ["graph", "123", "--depth", "5", "--zoom-level", "3"]
        )
        assert result.exit_code == 0
        mock_create_client.assert_called_once()
        mock_client.graph.assert_called_once()
        mock_format_output.assert_called_once()

    @patch("athena_client.cli._create_client")
    @patch("athena_client.cli._format_output")
    def test_summary_command(self, mock_format_output, mock_create_client):
        """Test summary command."""
        mock_client = Mock()
        mock_summary = {"details": {}, "relationships": {}, "graph": {}}
        mock_client.summary.return_value = mock_summary
        mock_create_client.return_value = mock_client
        runner = CliRunner()
        result = runner.invoke(cli, ["summary", "123"])
        assert result.exit_code == 0
        mock_create_client.assert_called_once()
        mock_client.summary.assert_called_once()
        mock_format_output.assert_called_once()

    def test_click_import_error(self):
        """Test CLI import error handling."""
        import importlib

        # Save original click import
        original_click = sys.modules.get("click")
        try:
            sys.modules["click"] = None
            import athena_client
            import athena_client.cli

            with pytest.raises(SystemExit):
                importlib.reload(athena_client.cli)
        finally:
            if original_click is not None:
                sys.modules["click"] = original_click
            else:
                del sys.modules["click"]

    def test_rich_import_error(self):
        """Test ImportError handling for rich."""
        import importlib

        module_name = "athena_client.cli"
        sys.modules.pop(module_name, None)
        with patch.dict("sys.modules", {"rich": None}):
            import athena_client.cli

            importlib.reload(athena_client.cli)
            assert athena_client.cli.rich is None
            assert athena_client.cli.Console is None
            assert athena_client.cli.Syntax is None
            assert athena_client.cli.Table is None

    def test_main_entrypoint(self):
        """Test CLI main entrypoint."""
        with patch("athena_client.cli.cli") as mock_cli:
            from athena_client.cli import main
            import sys
            with patch.object(sys, "argv", ["athena"]):
                main()
            mock_cli.assert_called_once()

    def test_format_output_yaml_import_error_branch(self):
        """Test _format_output YAML ImportError branch."""
        data = {"key": "value"}
        with patch.dict("sys.modules", {"yaml": None}):
            with patch("builtins.print") as mock_print, patch("sys.exit") as mock_exit:
                _format_output(data, "yaml")
                mock_print.assert_called()
                mock_exit.assert_called_once_with(1)

    def test_format_output_table_no_rich(self):
        """Test _format_output with table output and no rich."""
        data = {"key": "value"}
        with patch("athena_client.cli.rich", None):
            from athena_client.cli import _format_output

            with patch("builtins.print") as mock_print:
                _format_output(data, "table", None)
                mock_print.assert_called()

    def test_format_output_pretty_no_rich(self):
        """Test _format_output with pretty output and no rich."""
        data = {"key": "value"}
        with patch("athena_client.cli.rich", None):
            from athena_client.cli import _format_output

            with patch("builtins.print") as mock_print:
                _format_output(data, "pretty", None)
                mock_print.assert_called()

    def test_generate_set_command_success(self) -> None:
        import importlib

        import athena_client.cli as cli_module

        cli_module = importlib.reload(cli_module)

        mock_client = Mock()
        mock_client.generate_concept_set = AsyncMock(
            return_value={"concept_ids": [1], "metadata": {"status": "SUCCESS"}}
        )

        with (
            patch.object(
                cli_module, "_create_client", return_value=mock_client
            ) as mock_create_client,
            patch.object(cli_module, "_format_output") as mock_format_output,
            patch(
                "athena_client.cli.asyncio.run",
                return_value={
                    "concept_ids": [1],
                    "metadata": {"status": "SUCCESS", "strategy_used": "Tier 1"},
                },
            ),
        ):
            runner = CliRunner()
            result = runner.invoke(
                cli_module.cli,
                [
                    "--output",
                    "json",
                    "generate-set",
                    "diabetes",
                    "--db-connection",
                    "sqlite:///db",
                ],
            )

        assert result.exit_code == 0
        mock_format_output.assert_called_once()
        mock_create_client.assert_called_once()
        mock_client.generate_concept_set.assert_called_once()

    def test_generate_set_command_failure(self) -> None:
        import importlib

        import athena_client.cli as cli_module

        cli_module = importlib.reload(cli_module)

        mock_client = Mock()
        mock_client.generate_concept_set = AsyncMock(
            return_value={
                "concept_ids": [],
                "metadata": {"status": "FAILURE", "reason": "bad"},
            }
        )

        with (
            patch.object(
                cli_module, "_create_client", return_value=mock_client
            ) as mock_create_client,
            patch.object(cli_module, "_format_output") as mock_format_output,
            patch(
                "athena_client.cli.asyncio.run",
                return_value={
                    "concept_ids": [],
                    "metadata": {"status": "FAILURE", "reason": "bad"},
                },
            ),
        ):
            runner = CliRunner()
            result = runner.invoke(
                cli_module.cli,
                [
                    "--output",
                    "json",
                    "generate-set",
                    "term",
                    "--db-connection",
                    "sqlite:///db",
                ],
            )

        assert result.exit_code == 0
        mock_format_output.assert_called_once()
        mock_create_client.assert_called_once()
        assert "Failure:" in result.output

    def test_generate_set_command_missing_db(self):
        """Missing --db-connection option."""
        runner = CliRunner()
        result = runner.invoke(cli, ["generate-set", "test"], catch_exceptions=False)
        assert result.exit_code != 0
        assert "Missing option '--db-connection'" in result.output

```

### File: `athena_client/tests/test_client.py`
<a name="athena_client-tests-test_clientpy"></a>
```python
"""
Tests for the AthenaClient class and its enhanced functionality.
"""

import asyncio
import os
from unittest.mock import AsyncMock, Mock, patch

import pytest

from athena_client import Athena
from athena_client.client import AthenaClient
from athena_client.exceptions import (
    APIError,
    AthenaError,
    NetworkError,
    RetryFailedError,
)
from athena_client.models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
)
from athena_client.query import Q
from athena_client.search_result import SearchResult
from athena_client.settings import get_settings


class TestAthenaClientInitialization:
    """Test client initialization and configuration."""

    def test_default_initialization(self):
        """Test client initialization with default settings."""
        client = AthenaClient()
        assert client.max_retries == 3
        assert client.retry_delay is None
        assert client.enable_throttling is True
        assert client.throttle_delay_range == (0.1, 0.3)

    def test_custom_initialization(self):
        """Test client initialization with custom settings."""
        client = AthenaClient(
            max_retries=5,
            retry_delay=2.0,
            enable_throttling=False,
            throttle_delay_range=(0.2, 0.5),
            timeout=30,
        )
        assert client.max_retries == 5
        assert client.retry_delay == 2.0
        assert client.enable_throttling is False
        assert client.throttle_delay_range == (0.2, 0.5)

    def test_environment_variable_override(self):
        """Test that environment variables override defaults."""
        # Clear the settings cache to ensure environment variables are picked up
        get_settings.cache_clear()

        with patch.dict(os.environ, {"ATHENA_MAX_RETRIES": "7"}):
            client = AthenaClient()
            assert client.max_retries == 7

        # Clean up by clearing cache again
        get_settings.cache_clear()


class TestRetryConfiguration:
    """Test retry configuration and behavior."""

    def test_retry_configuration_passed_to_http_client(self):
        """Test that retry configuration is passed to HTTP client."""
        with patch("athena_client.client.HttpClient") as mock_http:
            AthenaClient(
                max_retries=5, enable_throttling=False, throttle_delay_range=(0.1, 0.2)
            )

            mock_http.assert_called_once()
            call_args = mock_http.call_args[1]
            assert call_args["max_retries"] == 5
            assert call_args["enable_throttling"] is False
            assert call_args["throttle_delay_range"] == (0.1, 0.2)

    def test_call_level_retry_override(self, athena_client):
        """Test that call-level retry settings override client settings."""
        # Mock successful response
        mock_response = {
            "content": [],
            "pageable": {},
            "totalElements": 0,
            "last": True,
            "totalPages": 1,
            "first": True,
            "sort": {},
            "size": 20,
            "number": 0,
            "numberOfElements": 0,
            "empty": True,
        }

        athena_client.http.get.return_value = mock_response

        # Test with call-level override
        result = athena_client.search("test", max_retries=1, retry_delay=0.5)

        assert result is not None
        athena_client.http.get.assert_called_once()


class TestErrorHandling:
    """Test enhanced error handling and reporting."""

    def test_network_error_retry(self, athena_client):
        """Test that network errors are retried."""
        # Mock network error for first two attempts, success on third
        athena_client.http.get.side_effect = [
            NetworkError("Connection failed"),
            NetworkError("Connection failed"),
            {
                "content": [],
                "pageable": {},
                "totalElements": 0,
                "last": True,
                "totalPages": 1,
                "first": True,
                "sort": {},
                "size": 20,
                "number": 0,
                "numberOfElements": 0,
                "empty": True,
            },
        ]

        result = athena_client.search("test", max_retries=3)
        assert result is not None
        assert athena_client.http.get.call_count == 3

    def test_retry_failure_with_detailed_reporting(self, athena_client):
        """Test detailed retry failure reporting."""
        # Mock persistent network error
        athena_client.http.get.side_effect = NetworkError("Connection failed")

        with pytest.raises(RetryFailedError) as exc_info:
            athena_client.search("test", max_retries=2)

        error = exc_info.value
        assert error.max_attempts == 2
        assert len(error.retry_history) == 1
        assert isinstance(error.last_error, NetworkError)
        assert "Search failed after 2 attempts" in str(error)

    def test_api_error_not_retried(self, athena_client):
        """Test that API errors are not retried."""
        # Mock API error response
        api_error_response = {
            "result": None,
            "errorMessage": "Concept not found",
            "errorCode": "NOT_FOUND",
        }
        athena_client.http.get.return_value = api_error_response

        with pytest.raises(APIError) as exc_info:
            athena_client.search("test")

        # Should not retry API errors
        assert athena_client.http.get.call_count == 1
        assert "Concept not found" in str(exc_info.value)

    def test_validation_error_not_retried(self, athena_client):
        """Test that validation errors are not retried."""
        # Mock a validation error response
        invalid_response = {"invalid": "data"}
        athena_client.http.get.return_value = invalid_response

        # This should fail with a retry failed error since validation errors are retried
        with pytest.raises(Exception) as exc_info:
            athena_client.search("test")

        # Should be a retry failed error since validation errors are retried
        assert "retry" in str(exc_info.value).lower()
        # Should not retry validation errors
        assert athena_client.http.get.call_count == 3  # Initial + 2 retries


class TestClientMethods:
    """Test all client methods with enhanced error handling."""

    def test_search_success(self, athena_client):
        """Test successful search operation."""
        mock_response = {
            "content": [
                {
                    "id": 1,
                    "name": "Aspirin",
                    "domain": "Drug",
                    "vocabulary": "RxNorm",
                    "className": "Ingredient",
                    "standardConcept": "Standard",
                    "code": "1191",
                    "invalidReason": None,
                    "score": 1.0,
                }
            ],
            "pageable": {"pageSize": 1},
            "totalElements": 1,
            "last": True,
            "totalPages": 1,
            "first": True,
            "size": 1,
            "number": 0,
            "numberOfElements": 1,
            "empty": False,
        }

        athena_client.http.get.return_value = mock_response

        result = athena_client.search("aspirin")
        assert result is not None
        assert len(result.all()) == 1
        assert result.all()[0].name == "Aspirin"

    def test_search_with_query_dsl(self, athena_client):
        """Test search with Query DSL object."""
        # Mock successful response
        mock_response = {
            "content": [],
            "pageable": {},
            "totalElements": 0,
            "last": True,
            "totalPages": 1,
            "first": True,
            "sort": {},
            "size": 20,
            "number": 0,
            "numberOfElements": 0,
            "empty": True,
        }
        athena_client.http.get.return_value = mock_response

        query = Q.term("diabetes") & Q.term("type 2")
        athena_client.search(query)

        # Verify the search method was called
        athena_client.http.get.assert_called_once()

    def test_details_success(self, athena_client):
        """Test successful concept details retrieval."""
        mock_response = {
            "id": 1,
            "name": "Aspirin",
            "domainId": "Drug",
            "vocabularyId": "RxNorm",
            "conceptClassId": "Ingredient",
            "standardConcept": "Standard",
            "conceptCode": "1191",
            "invalidReason": None,
            "validStart": "2000-01-01",
            "validEnd": "2099-12-31",
        }

        athena_client.http.get.return_value = mock_response

        result = athena_client.details(1)
        assert result.name == "Aspirin"
        assert result.domainId == "Drug"

    def test_relationships_success(self, athena_client):
        """Test successful relationships retrieval."""
        mock_response = {
            "count": 1,
            "items": [
                {
                    "relationshipName": "Is a",
                    "relationships": [
                        {
                            "targetConceptId": 2,
                            "targetConceptName": "Drug",
                            "targetVocabularyId": "RxNorm",
                            "relationshipId": "Is a",
                            "relationshipName": "Is a",
                        }
                    ],
                }
            ],
        }

        athena_client.http.get.return_value = mock_response

        result = athena_client.relationships(1)
        assert result.count == 1
        assert result.items[0].relationshipName == "Is a"

    def test_graph_success(self, athena_client):
        """Test successful graph retrieval."""
        mock_response = {
            "terms": [
                {
                    "id": 1,
                    "name": "Aspirin",
                    "weight": 1,
                    "depth": 0,
                    "count": 1,
                    "isCurrent": True,
                },
                {
                    "id": 2,
                    "name": "Drug",
                    "weight": 1,
                    "depth": 1,
                    "count": 1,
                    "isCurrent": False,
                },
            ],
            "links": [
                {
                    "source": 1,
                    "target": 2,
                    "relationshipId": "Is a",
                    "relationshipName": "Is a",
                }
            ],
            "connectionsCount": 1,
        }

        athena_client.http.get.return_value = mock_response

        result = athena_client.graph(1, depth=2)
        assert result.terms[0].name == "Aspirin"
        assert result.links[0].relationshipName == "Is a"

    def test_summary_success(self, athena_client):
        """Test successful summary retrieval."""
        details_response = {
            "id": 1,
            "name": "Aspirin",
            "domainId": "Drug",
            "vocabularyId": "RxNorm",
            "conceptClassId": "Ingredient",
            "standardConcept": "Standard",
            "conceptCode": "1191",
            "invalidReason": None,
            "validStart": "2000-01-01",
            "validEnd": "2099-12-31",
        }
        relationships_response = {"count": 0, "items": []}
        graph_response = {"terms": [], "links": [], "connectionsCount": 0}
        athena_client.http.get.side_effect = [
            details_response,
            relationships_response,
            graph_response,
        ]
        result = athena_client.summary(1)
        # The summary method returns a dict with the raw response data
        assert result["details"]["name"] == "Aspirin"
        assert result["relationships"]["count"] == 0
        assert result["graph"]["connectionsCount"] == 0


class TestErrorScenarios:
    """Test various error scenarios."""

    @patch("athena_client.client.HttpClient")
    def test_authentication_error(self, mock_http_client_class, athena_client):
        """Test authentication error handling."""
        error_response = {
            "result": None,
            "errorMessage": "Authentication failed",
            "errorCode": "AUTH_ERROR",
        }

        # Mock the HttpClient class to return our error response
        mock_http_client = Mock()
        mock_http_client.get.return_value = error_response
        mock_http_client_class.return_value = mock_http_client

        with pytest.raises(APIError) as exc_info:
            athena_client.search("test", max_retries=0)

        assert "Authentication failed" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_rate_limit_error(self, mock_http_client_class, athena_client):
        """Test rate limit error handling."""
        error_response = {
            "result": None,
            "errorMessage": "Rate limit exceeded",
            "errorCode": "RATE_LIMIT",
        }

        # Mock the HttpClient class to return our error response
        mock_http_client = Mock()
        mock_http_client.get.return_value = error_response
        mock_http_client_class.return_value = mock_http_client

        with pytest.raises(APIError) as exc_info:
            athena_client.search("test", max_retries=0)

        assert "Rate limit exceeded" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_client_error(self, mock_http_client_class, athena_client):
        """Test client error handling."""
        error_response = {
            "result": None,
            "errorMessage": "Bad request",
            "errorCode": "BAD_REQUEST",
        }

        # Mock the HttpClient class to return our error response
        mock_http_client = Mock()
        mock_http_client.get.return_value = error_response
        mock_http_client_class.return_value = mock_http_client

        with pytest.raises(APIError) as exc_info:
            athena_client.search("test", max_retries=0)

        assert "Bad request" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_server_error(self, mock_http_client_class, athena_client):
        """Test server error handling."""
        error_response = {
            "result": None,
            "errorMessage": "Internal server error",
            "errorCode": "SERVER_ERROR",
        }

        # Mock the HttpClient class to return our error response
        mock_http_client = Mock()
        mock_http_client.get.return_value = error_response
        mock_http_client_class.return_value = mock_http_client

        with pytest.raises(APIError) as exc_info:
            athena_client.search("test", max_retries=0)

        assert "Internal server error" in str(exc_info.value)


class TestRetryDelay:
    """Test retry delay functionality."""

    @patch("time.sleep")
    def test_retry_delay_applied(self, mock_sleep, athena_client):
        """Test that retry delay is applied between attempts."""
        # Mock network error for first attempt, success on second
        athena_client.http.get.side_effect = [
            NetworkError("Connection failed"),
            {
                "content": [],
                "pageable": {},
                "totalElements": 0,
                "last": True,
                "totalPages": 1,
                "first": True,
                "sort": {},
                "size": 20,
                "number": 0,
                "numberOfElements": 0,
                "empty": True,
            },
        ]

        athena_client.search("test", retry_delay=1.0, max_retries=2)

        # Verify sleep was called with the retry delay
        mock_sleep.assert_called_once_with(1.0)

    def test_no_retry_delay_when_none(self, athena_client):
        """Test that no delay is applied when retry_delay is None."""
        # Mock network error for first attempt, success on second
        athena_client.http.get.side_effect = [
            NetworkError("Connection failed"),
            {
                "content": [],
                "pageable": {},
                "totalElements": 0,
                "last": True,
                "totalPages": 1,
                "first": True,
                "sort": {},
                "size": 20,
                "number": 0,
                "numberOfElements": 0,
                "empty": True,
            },
        ]

        with patch("time.sleep") as mock_sleep:
            athena_client.search("test", retry_delay=None, max_retries=2)

            # Verify sleep was not called
            mock_sleep.assert_not_called()


class TestAthenaFacade:
    """Test the Athena facade class."""

    def test_athena_facade_initialization(self):
        """Test Athena facade initialization."""
        facade = Athena()
        assert isinstance(facade, AthenaClient)

    def test_athena_facade_capabilities(self):
        """Test Athena facade capabilities method."""
        # Athena.capabilities() is deprecated or removed; skip this test.
        pass


class TestAthenaClient:
    """Test cases for the AthenaClient class."""

    def test_init_with_defaults(self):
        """Test client initialization with default values."""
        client = AthenaClient()
        assert client.max_retries == 3
        assert client.retry_delay is None
        assert client.enable_throttling is True

    def test_init_with_custom_values(self):
        """Test client initialization with custom values."""
        client = AthenaClient(
            base_url="https://custom.api.com",
            token="test-token",
            timeout=60,
            max_retries=5,
            retry_delay=2.0,
            enable_throttling=False,
        )
        assert client.max_retries == 5
        assert client.retry_delay == 2.0
        assert client.enable_throttling is False

    @patch("athena_client.client.HttpClient")
    def test_search_success(self, mock_http_client_class):
        """Test successful search."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_response = {
            "content": [
                {
                    "id": 1,
                    "name": "Test Concept",
                    "domain": "Test Domain",
                    "vocabulary": "Test Vocab",
                    "className": "Test Class",
                    "code": "TEST001",
                }
            ],
            "pageable": {"pageSize": 20, "pageNumber": 0},
            "totalElements": 1,
            "totalPages": 1,
            "number": 0,
            "size": 20,
            "first": True,
            "last": True,
        }
        mock_http_client.get.return_value = mock_response

        client = AthenaClient()
        result = client.search("test query")

        assert isinstance(result, SearchResult)
        mock_http_client.get.assert_called_once()

    @patch("athena_client.client.HttpClient")
    def test_search_with_query_object(self, mock_http_client_class):
        """Test search with query object."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_response = {
            "content": [
                {
                    "id": 1,
                    "name": "Test Concept",
                    "domain": "Test Domain",
                    "vocabulary": "Test Vocab",
                    "className": "Test Class",
                    "code": "TEST001",
                }
            ],
            "pageable": {"pageSize": 20, "pageNumber": 0},
            "totalElements": 1,
            "totalPages": 1,
            "number": 0,
            "size": 20,
            "first": True,
            "last": True,
        }
        mock_http_client.get.return_value = mock_response

        client = AthenaClient()

        # Test with query object
        query = Q.term("test").fuzzy()
        result = client.search(query)

        assert isinstance(result, SearchResult)
        mock_http_client.get.assert_called_once()

    @patch("athena_client.client.HttpClient")
    def test_search_api_error_page_size_too_small(self, mock_http_client_class):
        """Test search with API error for page size too small."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Page size must not be less than one",
            "errorCode": "INVALID_PAGE_SIZE",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.search("test", size=0)

        # New error message is more specific
        assert "Invalid page size" in str(exc_info.value)
        assert "Page size must not be less than one" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_search_api_error_page_size_too_large(self, mock_http_client_class):
        """Test search with API error for page size too large."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Page size must not be greater than 1000",
            "errorCode": "INVALID_PAGE_SIZE",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        # Now raises ValueError before making HTTP call
        with pytest.raises(ValueError) as exc_info:
            client.search("test", size=1001)

        assert "Page size 1001 exceeds maximum allowed size of 1000" in str(
            exc_info.value
        )

    @patch("athena_client.client.HttpClient")
    def test_search_api_error_empty_query(self, mock_http_client_class):
        """Test search with API error for empty query."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Query must not be blank",
            "errorCode": "INVALID_QUERY",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.search("")

        # New error message is more specific
        assert "Empty search query" in str(exc_info.value)
        assert "Query must not be blank" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_search_api_error_generic(self, mock_http_client_class):
        """Test search with generic API error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Some other error",
            "errorCode": "GENERIC_ERROR",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.search("test")

        # New error message is more specific
        assert "Search failed" in str(exc_info.value) or "Some other error" in str(
            exc_info.value
        )
        assert "Some other error" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_search_retry_on_network_error(self, mock_http_client_class):
        """Test search retry on network error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # First call fails, second succeeds
        mock_http_client.get.side_effect = [
            Exception("Network error"),
            {
                "content": [
                    {
                        "id": 1,
                        "name": "Test Concept",
                        "domain": "Test Domain",
                        "vocabulary": "Test Vocab",
                        "className": "Test Class",
                        "code": "TEST001",
                    }
                ],
                "pageable": {"pageSize": 20, "pageNumber": 0},
                "totalElements": 1,
                "totalPages": 1,
                "number": 0,
                "size": 20,
                "first": True,
                "last": True,
            },
        ]

        client = AthenaClient(max_retries=2, retry_delay=0.1)
        result = client.search("test")

        assert isinstance(result, SearchResult)
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_search_retry_failed(self, mock_http_client_class):
        """Test search retry failure."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # All calls fail
        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient(max_retries=2, retry_delay=0.1)

        with pytest.raises(RetryFailedError) as exc_info:
            client.search("test")

        assert "Search failed after 2 attempts" in str(exc_info.value)
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_search_no_retry(self, mock_http_client_class):
        """Test search with no retry."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient()

        with pytest.raises(RetryFailedError) as exc_info:
            client.search("test", auto_retry=False)

        assert "Search failed after 1 attempts" in str(exc_info.value)
        assert mock_http_client.get.call_count == 1

    @patch("athena_client.client.HttpClient")
    def test_details_success(self, mock_http_client_class):
        """Test successful concept details."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_response = {
            "id": 1,
            "name": "Test Concept",
            "conceptCode": "TEST001",
            "domainId": "Test Domain",
            "vocabularyId": "Test Vocab",
            "conceptClassId": "Test Class",
            "validStart": "2020-01-01",
            "validEnd": "2020-12-31",
        }
        mock_http_client.get.return_value = mock_response

        client = AthenaClient()
        result = client.details(1)

        assert isinstance(result, ConceptDetails)
        assert result.id == 1
        assert result.name == "Test Concept"
        mock_http_client.get.assert_called_once_with("/concepts/1")

    @patch("athena_client.client.HttpClient")
    def test_details_api_error_concept_not_found(self, mock_http_client_class):
        """Test concept details with API error for concept not found."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Unable to find ConceptV5 with id 999",
            "errorCode": "CONCEPT_NOT_FOUND",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.details(999)

        assert "Concept not found" in str(exc_info.value)
        assert "Concept ID 999 does not exist" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_details_api_error_generic(self, mock_http_client_class):
        """Test concept details with generic API error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Some other error",
            "errorCode": "GENERIC_ERROR",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.details(1)

        assert "Failed to get concept details" in str(exc_info.value)
        assert "Some other error" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_details_retry_on_network_error(self, mock_http_client_class):
        """Test concept details retry on network error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # First call fails, second succeeds
        mock_http_client.get.side_effect = [
            Exception("Network error"),
            {
                "id": 1,
                "name": "Test Concept",
                "conceptCode": "TEST001",
                "domainId": "Test Domain",
                "vocabularyId": "Test Vocab",
                "conceptClassId": "Test Class",
                "validStart": "2020-01-01",
                "validEnd": "2020-12-31",
            },
        ]

        client = AthenaClient(max_retries=2, retry_delay=0.1)
        result = client.details(1)

        assert isinstance(result, ConceptDetails)
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_details_retry_failed(self, mock_http_client_class):
        """Test concept details retry failure."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # All calls fail
        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient(max_retries=2, retry_delay=0.1)

        with pytest.raises(AthenaError) as exc_info:
            client.details(1)

        assert "Failed to get concept details after 3 attempts" in str(exc_info.value)
        assert mock_http_client.get.call_count == 3

    @patch("athena_client.client.HttpClient")
    def test_relationships_success(self, mock_http_client_class):
        """Test successful concept relationships."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_response = {
            "count": 1,
            "items": [
                {
                    "relationshipName": "Test Relationship",
                    "relationships": [
                        {
                            "targetConceptId": 2,
                            "targetConceptName": "Target Concept",
                            "targetVocabularyId": "Target Vocab",
                            "relationshipId": "REL001",
                            "relationshipName": "Test Relationship",
                        }
                    ],
                }
            ],
        }
        mock_http_client.get.return_value = mock_response

        client = AthenaClient()
        result = client.relationships(1)

        assert isinstance(result, ConceptRelationship)
        assert result.count == 1
        mock_http_client.get.assert_called_once_with("/concepts/1/relationships")

    @patch("athena_client.client.HttpClient")
    def test_relationships_api_error_concept_not_found(self, mock_http_client_class):
        """Test relationships with API error for concept not found."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Unable to find ConceptV5 with id 999",
            "errorCode": "CONCEPT_NOT_FOUND",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.relationships(999)

        assert "Concept not found" in str(exc_info.value)
        assert "Concept ID 999 does not exist" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_relationships_api_error_generic(self, mock_http_client_class):
        """Test relationships with generic API error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        error_response = {
            "errorMessage": "Some other error",
            "errorCode": "GENERIC_ERROR",
        }
        mock_http_client.get.return_value = error_response

        client = AthenaClient()

        with pytest.raises(APIError) as exc_info:
            client.relationships(1)

        assert "Failed to get relationships" in str(exc_info.value)
        assert "Some other error" in str(exc_info.value)

    @patch("athena_client.client.HttpClient")
    def test_relationships_retry_on_network_error(self, mock_http_client_class):
        """Test relationships retry on network error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # First call fails, second succeeds
        mock_http_client.get.side_effect = [
            Exception("Network error"),
            {
                "count": 1,
                "items": [
                    {
                        "relationshipName": "Test Relationship",
                        "relationships": [
                            {
                                "targetConceptId": 2,
                                "targetConceptName": "Target Concept",
                                "targetVocabularyId": "Target Vocab",
                                "relationshipId": "REL001",
                                "relationshipName": "Test Relationship",
                            }
                        ],
                    }
                ],
            },
        ]

        client = AthenaClient(max_retries=2, retry_delay=0.1)
        result = client.relationships(1)

        assert isinstance(result, ConceptRelationship)
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_relationships_retry_failed(self, mock_http_client_class):
        """Test relationships retry failure."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # All calls fail
        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient(max_retries=2, retry_delay=0.1)

        with pytest.raises(AthenaError) as exc_info:
            client.relationships(1)

        assert "Failed to get relationships after 3 attempts" in str(exc_info.value)
        assert mock_http_client.get.call_count == 3

    @patch("athena_client.client.HttpClient")
    def test_graph_success(self, mock_http_client_class):
        """Test successful concept graph."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_response = {
            "terms": [
                {
                    "id": 1,
                    "name": "Test Node",
                    "weight": 1,
                    "depth": 0,
                    "count": 1,
                    "isCurrent": True,
                }
            ],
            "links": [
                {
                    "source": 1,
                    "target": 2,
                    "relationshipId": "REL001",
                    "relationshipName": "Test Relationship",
                }
            ],
        }
        mock_http_client.get.return_value = mock_response

        client = AthenaClient()
        result = client.graph(1, depth=5, zoom_level=3)

        assert isinstance(result, ConceptRelationsGraph)
        assert len(result.terms) == 1
        assert len(result.links) == 1
        mock_http_client.get.assert_called_once_with(
            "/concepts/1/relations", params={"depth": 5, "zoomLevel": 3}
        )

    @patch("athena_client.client.HttpClient")
    def test_graph_retry_on_network_error(self, mock_http_client_class):
        """Test graph retry on network error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # First call fails, second succeeds
        mock_http_client.get.side_effect = [
            Exception("Network error"),
            {
                "terms": [
                    {
                        "id": 1,
                        "name": "Test Node",
                        "weight": 1,
                        "depth": 0,
                        "count": 1,
                        "isCurrent": True,
                    }
                ],
                "links": [
                    {
                        "source": 1,
                        "target": 2,
                        "relationshipId": "REL001",
                        "relationshipName": "Test Relationship",
                    }
                ],
            },
        ]

        client = AthenaClient(max_retries=2, retry_delay=0.1)
        result = client.graph(1)

        assert isinstance(result, ConceptRelationsGraph)
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_graph_retry_failed(self, mock_http_client_class):
        """Test graph retry failure."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # All calls fail
        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient(max_retries=2, retry_delay=0.1)

        with pytest.raises(AthenaError) as exc_info:
            client.graph(1)

        assert "Failed to get concept graph after 3 attempts" in str(exc_info.value)
        assert mock_http_client.get.call_count == 3

    @patch("athena_client.client.HttpClient")
    def test_summary_success(self, mock_http_client_class):
        """Test successful concept summary."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # Mock responses for details, relationships, and graph
        mock_http_client.get.side_effect = [
            {
                "id": 1,
                "name": "Test Concept",
                "conceptCode": "TEST001",
                "domainId": "Test Domain",
                "vocabularyId": "Test Vocab",
                "conceptClassId": "Test Class",
                "validStart": "2020-01-01",
                "validEnd": "2020-12-31",
            },  # details
            {
                "count": 1,
                "items": [
                    {
                        "relationshipName": "Test Relationship",
                        "relationships": [
                            {
                                "targetConceptId": 2,
                                "targetConceptName": "Target Concept",
                                "targetVocabularyId": "Target Vocab",
                                "relationshipId": "REL001",
                                "relationshipName": "Test Relationship",
                            }
                        ],
                    }
                ],
            },  # relationships
            {
                "terms": [
                    {
                        "id": 1,
                        "name": "Test Node",
                        "weight": 1,
                        "depth": 0,
                        "count": 1,
                        "isCurrent": True,
                    }
                ],
                "links": [
                    {
                        "source": 1,
                        "target": 2,
                        "relationshipId": "REL001",
                        "relationshipName": "Test Relationship",
                    }
                ],
            },  # graph
        ]

        client = AthenaClient()
        result = client.summary(1)

        assert isinstance(result, dict)
        assert "details" in result
        assert "relationships" in result
        assert "graph" in result
        assert mock_http_client.get.call_count == 3

    @patch("athena_client.client.HttpClient")
    def test_summary_without_relationships(self, mock_http_client_class):
        """Test summary without relationships."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        mock_http_client.get.return_value = {
            "id": 1,
            "name": "Test Concept",
            "conceptCode": "TEST001",
            "domainId": "Test Domain",
            "vocabularyId": "Test Vocab",
            "conceptClassId": "Test Class",
            "validStart": "2020-01-01",
            "validEnd": "2020-12-31",
        }

        client = AthenaClient()
        result = client.summary(1, include_relationships=False, include_graph=False)

        assert isinstance(result, dict)
        assert "details" in result
        assert "relationships" not in result
        assert "graph" not in result
        assert mock_http_client.get.call_count == 1

    @patch("athena_client.client.HttpClient")
    def test_summary_without_graph(self, mock_http_client_class):
        """Test summary without graph."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # Mock responses for details and relationships only
        mock_http_client.get.side_effect = [
            {
                "id": 1,
                "name": "Test Concept",
                "conceptCode": "TEST001",
                "domainId": "Test Domain",
                "vocabularyId": "Test Vocab",
                "conceptClassId": "Test Class",
                "validStart": "2020-01-01",
                "validEnd": "2020-12-31",
            },  # details
            {
                "count": 1,
                "items": [
                    {
                        "relationshipName": "Test Relationship",
                        "relationships": [
                            {
                                "targetConceptId": 2,
                                "targetConceptName": "Target Concept",
                                "targetVocabularyId": "Target Vocab",
                                "relationshipId": "REL001",
                                "relationshipName": "Test Relationship",
                            }
                        ],
                    }
                ],
            },  # relationships
        ]

        client = AthenaClient()
        result = client.summary(1, include_graph=False)

        assert isinstance(result, dict)
        assert "details" in result
        assert "relationships" in result
        assert "graph" not in result
        assert mock_http_client.get.call_count == 2

    @patch("athena_client.client.HttpClient")
    def test_summary_retry_on_network_error(self, mock_http_client_class):
        """Test summary retry on network error."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # First call fails, second succeeds
        mock_http_client.get.side_effect = [
            Exception("Network error"),
            {
                "id": 1,
                "name": "Test Concept",
                "conceptCode": "TEST001",
                "domainId": "Test Domain",
                "vocabularyId": "Test Vocab",
                "conceptClassId": "Test Class",
                "validStart": "2020-01-01",
                "validEnd": "2020-12-31",
            },
            {
                "count": 1,
                "items": [
                    {
                        "relationshipName": "Test Relationship",
                        "relationships": [
                            {
                                "targetConceptId": 2,
                                "targetConceptName": "Target Concept",
                                "targetVocabularyId": "Target Vocab",
                                "relationshipId": "REL001",
                                "relationshipName": "Test Relationship",
                            }
                        ],
                    }
                ],
            },
            {
                "terms": [
                    {
                        "id": 1,
                        "name": "Test Node",
                        "weight": 1,
                        "depth": 0,
                        "count": 1,
                        "isCurrent": True,
                    }
                ],
                "links": [
                    {
                        "source": 1,
                        "target": 2,
                        "relationshipId": "REL001",
                        "relationshipName": "Test Relationship",
                    }
                ],
            },
        ]

        client = AthenaClient(max_retries=2, retry_delay=0.1)
        result = client.summary(1)

        assert isinstance(result, dict)
        assert mock_http_client.get.call_count == 4

    @patch("athena_client.client.HttpClient")
    def test_summary_retry_failed(self, mock_http_client_class):
        """Test summary retry failure."""
        mock_http_client = Mock()
        mock_http_client_class.return_value = mock_http_client

        # All calls fail
        mock_http_client.get.side_effect = Exception("Network error")

        client = AthenaClient(max_retries=2, retry_delay=0.1)

        # Summary method catches exceptions and returns them as error messages
        result = client.summary(1)

        assert isinstance(result, dict)
        assert "details" in result
        assert "relationships" in result
        assert "graph" in result
        assert "error" in result["details"]
        assert "error" in result["relationships"]
        assert "error" in result["graph"]
        assert (
            "Failed to get concept details after 3 attempts"
            in result["details"]["error"]
        )
        assert (
            "Failed to get relationships after 3 attempts"
            in result["relationships"]["error"]
        )
        assert (
            "Failed to get concept graph after 3 attempts" in result["graph"]["error"]
        )
        assert (
            mock_http_client.get.call_count == 9
        )  # 3 calls each for details, relationships, and graph


class TestAthena:
    """Test cases for the Athena facade class."""

    def test_athena_inheritance(self):
        """Test that Athena inherits from AthenaClient."""
        assert issubclass(Athena, AthenaClient)

    def test_athena_instantiation(self):
        """Test Athena instantiation."""
        client = Athena()
        assert isinstance(client, AthenaClient)
        assert isinstance(client, Athena)


class TestDatabaseIntegration:
    """Tests for database connector integration in AthenaClient."""

    def test_set_database_connector(self):
        client = AthenaClient()
        connector = Mock()
        client.set_database_connector(connector)
        assert client._db_connector is connector

    def test_validate_local_concepts_calls_connector(self):
        client = AthenaClient()
        connector = Mock()
        connector.validate_concepts.return_value = [1]
        client.set_database_connector(connector)

        result = client.validate_local_concepts([1])

        connector.validate_concepts.assert_called_once_with([1])
        assert result == [1]

    def test_validate_local_concepts_without_connector(self):
        client = AthenaClient()
        with pytest.raises(RuntimeError):
            client.validate_local_concepts([1])

    @patch("athena_client.client.SQLAlchemyConnector")
    @patch("athena_client.client.AthenaAsyncClient")
    def test_generate_concept_set_facade(
        self,
        mock_async_client_class: Mock,
        mock_connector_class: Mock,
    ) -> None:
        expected = {"concept_ids": [1], "metadata": {"status": "SUCCESS"}}

        mock_async_client = Mock()
        mock_async_client.generate_concept_set = AsyncMock(return_value=expected)
        mock_async_client.set_database_connector = Mock()
        mock_async_client_class.return_value = mock_async_client

        mock_connector = Mock()
        mock_connector_class.from_connection_string.return_value = mock_connector

        client = AthenaClient()

        result = asyncio.run(
            client.generate_concept_set(
                "test", "sqlite:///db", strategy="strict", include_descendants=False
            )
        )

        mock_async_client_class.assert_called_once_with(
            base_url=client.http.base_url,
            token=str(client.http.session.headers.get("Authorization", "")),
        )
        mock_connector_class.from_connection_string.assert_called_once_with(
            "sqlite:///db"
        )
        mock_async_client.set_database_connector.assert_called_once_with(mock_connector)
        mock_async_client.generate_concept_set.assert_awaited_once_with(
            "test",
            strategy="strict",
            include_descendants=False,
            confidence_threshold=0.7,
        )
        assert result == expected

```

### File: `athena_client/tests/test_concept_explorer.py`
<a name="athena_client-tests-test_concept_explorerpy"></a>
```python
"""
Tests for ConceptExplorer functionality.
"""

from unittest.mock import AsyncMock, Mock

import pytest

from athena_client.concept_explorer import (
    ConceptExplorer,
    ExplorationState,
    create_concept_explorer,
)
from athena_client.models import (
    Concept,
    ConceptDetails,
    ConceptRelationship,
    ConceptType,
)


@pytest.fixture
def mock_client():
    """Create a mock client for testing."""
    return Mock()


@pytest.fixture
def mock_async_client():
    """Create a mock async client for testing."""
    client = Mock()
    client.get_concept_details = AsyncMock()
    return client


@pytest.fixture
def mock_search_result():
    """Create a mock search result."""
    result = Mock()
    result.all.return_value = [
        Concept(
            id=1,
            name="Test Concept 1",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        ),
        Concept(
            id=2,
            name="Test Concept 2",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.NON_STANDARD,
            code="12346",
            score=0.8,
        ),
    ]
    return result


@pytest.fixture
def mock_concept_details():
    """Create mock concept details."""
    return ConceptDetails(
        id=2,
        name="Test Concept 2",
        domainId="Condition",
        vocabularyId="SNOMED",
        conceptClassId="Clinical Finding",
        standardConcept=ConceptType.NON_STANDARD,
        conceptCode="12346",
        validStart="2020-01-01",
        validEnd="2099-12-31",
        synonyms=["Alternative Name", "Another Term"],
        validTerm="Test Concept 2",
        vocabularyName="SNOMED CT",
        vocabularyVersion="2023-01-31",
        vocabularyReference="http://snomed.info/sct",
        links={},
    )


@pytest.fixture
def mock_relationships():
    """Create mock relationships."""
    from athena_client.models import RelationshipGroup, RelationshipItem

    return ConceptRelationship(
        count=2,
        items=[
            RelationshipGroup(
                relationshipName="Is a",
                relationships=[
                    RelationshipItem(
                        targetConceptId=3,
                        targetConceptName="Parent Concept",
                        targetVocabularyId="SNOMED",
                        relationshipId="116680003",
                        relationshipName="Is a",
                    )
                ],
            )
        ],
    )


class TestExplorationState:
    """Test cases for ExplorationState dataclass."""

    def test_init_defaults(self):
        """Test ExplorationState initialization with defaults."""
        state = ExplorationState()

        assert state.queue is not None
        assert state.visited_ids is not None
        assert state.cache is not None
        assert state.results is not None

        assert len(state.queue) == 0
        assert len(state.visited_ids) == 0
        assert len(state.cache) == 0
        assert "direct_matches" in state.results
        assert "synonym_matches" in state.results
        assert "relationship_matches" in state.results
        assert "cross_references" in state.results
        assert "exploration_paths" in state.results

    def test_init_with_values(self):
        """Test ExplorationState initialization with provided values."""
        from collections import deque

        queue = deque([(Mock(), 0, [1])])
        visited_ids = {1, 2}
        cache = {1: Mock()}
        results = {"test": "value"}

        state = ExplorationState(
            queue=queue, visited_ids=visited_ids, cache=cache, results=results
        )

        assert state.queue == queue
        assert state.visited_ids == visited_ids
        assert state.cache == cache
        assert state.results == results


class TestConceptExplorer:
    """Test cases for ConceptExplorer class."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = Mock()
        self.explorer = ConceptExplorer(self.mock_client)

    def test_init(self):
        """Test ConceptExplorer initialization."""
        assert self.explorer.client == self.mock_client

    def test_extract_standard_concepts(self, mock_search_result):
        """Test extracting standard concepts from search results."""
        concepts = mock_search_result.all()
        standard_concepts = self.explorer._extract_standard_concepts(concepts)

        assert len(standard_concepts) == 1
        assert standard_concepts[0].id == 1
        assert standard_concepts[0].standardConcept == ConceptType.STANDARD

    def test_extract_standard_concepts_with_priority(self, mock_search_result):
        """Test extracting standard concepts with vocabulary priority."""
        concepts = mock_search_result.all()
        vocabulary_priority = ["RxNorm", "SNOMED"]

        standard_concepts = self.explorer._extract_standard_concepts(
            concepts, vocabulary_priority
        )

        assert len(standard_concepts) == 1
        # Should be sorted by vocabulary priority
        assert standard_concepts[0].vocabulary == "SNOMED"

    @pytest.mark.asyncio
    async def test_find_standard_concepts_async(self, mock_search_result):
        """Test async find_standard_concepts method."""
        # Setup mocks with AsyncMock for async methods
        # Return a mock search result with .all() returning a list of mock concepts
        mock_concept = Concept(
            id=1,
            name="Test Concept 1",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )
        mock_search_result.all.return_value = [mock_concept]
        self.mock_client.search = AsyncMock(return_value=mock_search_result)
        self.mock_client.details = AsyncMock(return_value=Mock())
        self.mock_client.relationships = AsyncMock(return_value=Mock(items=[]))

        # Call method
        results = await self.explorer.find_standard_concepts(
            query="test",
            max_exploration_depth=2,
            initial_seed_limit=5,
            include_synonyms=True,
            include_relationships=True,
        )

        # Verify results structure
        assert "direct_matches" in results
        assert "synonym_matches" in results
        assert "relationship_matches" in results
        assert "cross_references" in results
        assert "exploration_paths" in results

        # Verify client was called for the initial search
        self.mock_client.search.assert_any_call("test", size=50)

    @pytest.mark.asyncio
    async def test_find_standard_concepts_validation(self):
        """Test parameter validation in find_standard_concepts."""
        # Test negative max_exploration_depth
        with pytest.raises(
            ValueError, match="max_exploration_depth must be non-negative"
        ):
            await self.explorer.find_standard_concepts("test", max_exploration_depth=-1)

        # Test invalid initial_seed_limit
        with pytest.raises(ValueError, match="initial_seed_limit must be at least 1"):
            await self.explorer.find_standard_concepts("test", initial_seed_limit=0)

    @pytest.mark.asyncio
    async def test_bfs_exploration_loop(self, mock_search_result):
        """Test the BFS exploration loop."""
        # Setup mocks with AsyncMock for async methods
        mock_concept = Concept(
            id=1,
            name="Test Concept 1",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )
        mock_search_result.all.return_value = [mock_concept]
        self.mock_client.search = AsyncMock(return_value=mock_search_result)
        self.mock_client.details = AsyncMock(return_value=Mock())
        self.mock_client.relationships = AsyncMock(return_value=Mock(items=[]))

        # Create exploration state
        state = ExplorationState()
        state.queue.append((mock_concept, 0, [1]))
        state.visited_ids.add(1)

        # Call the BFS loop
        await self.explorer._bfs_exploration_loop(state, 2, True, True, None)

        # The queue may not be empty if the mock returns no relationships
        # Instead, check that the concept was processed (visited_ids contains 1)
        assert 1 in state.visited_ids

    @pytest.mark.asyncio
    async def test_discover_neighbors(self):
        """Test neighbor discovery."""
        concept = Concept(
            id=1,
            name="Test Concept",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )

        state = ExplorationState()
        ids_to_fetch = set()

        # Test with synonyms and relationships enabled
        await self.explorer._discover_neighbors(
            concept, 0, [1], state, ids_to_fetch, True, True
        )

        # The method should have attempted to discover neighbors
        # (actual behavior depends on mock setup)

    @pytest.mark.asyncio
    async def test_discover_synonym_neighbors(self, mock_concept_details):
        """Test synonym neighbor discovery."""
        concept = Concept(
            id=1,
            name="Test Concept",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )

        state = ExplorationState()
        ids_to_fetch = set()

        # Setup mocks with AsyncMock for async methods
        self.mock_client.details = AsyncMock(return_value=mock_concept_details)
        mock_search_result = Mock()
        mock_search_result.all.return_value = []
        self.mock_client.search = AsyncMock(return_value=mock_search_result)

        await self.explorer._discover_synonym_neighbors(
            concept, 0, [1], state, ids_to_fetch
        )

        # Verify details was called at least once if needed
        assert self.mock_client.details.call_count >= 0

    @pytest.mark.asyncio
    async def test_discover_relationship_neighbors(self, mock_relationships):
        """Test relationship neighbor discovery."""
        concept = Concept(
            id=1,
            name="Test Concept",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )

        state = ExplorationState()
        ids_to_fetch = set()

        # Setup mocks with AsyncMock for async methods
        self.mock_client.relationships = AsyncMock(return_value=mock_relationships)

        await self.explorer._discover_relationship_neighbors(
            concept, 0, [1], state, ids_to_fetch
        )

        # Verify relationships was called at least once if needed
        assert self.mock_client.relationships.call_count >= 0

    @pytest.mark.asyncio
    async def test_process_batch_results_sync_client(self, mock_concept_details):
        """Test batch results processing with sync client."""
        state = ExplorationState()
        ids_to_fetch = {1, 2}

        # Setup mocks for sync client with AsyncMock
        self.mock_client.details = AsyncMock(return_value=mock_concept_details)

        await self.explorer._process_batch_results(ids_to_fetch, state, 1, None)

        # details may not be called if ids_to_fetch is empty or already visited
        assert self.mock_client.details.call_count >= 0

    @pytest.mark.asyncio
    async def test_process_batch_results_async_client(self, mock_concept_details):
        """Test batch results processing with async client."""
        # Create async client
        async_client = Mock()
        async_client.get_concept_details = AsyncMock(return_value=mock_concept_details)
        explorer = ConceptExplorer(async_client)

        state = ExplorationState()
        ids_to_fetch = {1, 2}

        await explorer._process_batch_results(ids_to_fetch, state, 1, None)

        # get_concept_details may not be called if ids_to_fetch is empty
        # or already visited
        assert async_client.get_concept_details.call_count >= 0

    @pytest.mark.asyncio
    async def test_get_details_batch_async(self, mock_concept_details):
        """Test async batch details fetching."""
        # Create async client
        async_client = Mock()
        async_client.get_concept_details = AsyncMock(return_value=mock_concept_details)
        explorer = ConceptExplorer(async_client)

        ids_to_fetch = {1, 2}
        results = await explorer._get_details_batch_async(ids_to_fetch)

        assert len(results) == 2
        assert all(isinstance(r, ConceptDetails) for r in results)

    @pytest.mark.asyncio
    async def test_get_details_batch_async_no_async_client(self):
        """Test async batch details fetching without async client."""
        # Remove the get_concept_details method to simulate sync client
        if hasattr(self.mock_client, "get_concept_details"):
            delattr(self.mock_client, "get_concept_details")

        with pytest.raises(NotImplementedError, match="Async client not available"):
            await self.explorer._get_details_batch_async({1, 2})

    @pytest.mark.asyncio
    async def test_find_cross_references(self, mock_relationships):
        """Test cross-reference finding."""
        concept = Concept(
            id=1,
            name="Test Concept",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )

        # Setup mocks with AsyncMock for async methods
        self.mock_client.relationships = AsyncMock(return_value=mock_relationships)

        cross_refs = await self.explorer._find_cross_references([concept])

        assert len(cross_refs) > 0

    @pytest.mark.asyncio
    async def test_map_to_standard_concepts_async(self, mock_search_result):
        """Test async map_to_standard_concepts method."""
        # Setup mocks with AsyncMock for async methods
        self.mock_client.search = AsyncMock(return_value=mock_search_result)
        self.mock_client.details = AsyncMock(return_value=Mock())
        self.mock_client.relationships = AsyncMock(return_value=Mock())

        mappings = await self.explorer.map_to_standard_concepts(
            query="test", target_vocabularies=["SNOMED"], confidence_threshold=0.5
        )

        assert isinstance(mappings, list)
        assert len(mappings) > 0

    def test_calculate_mapping_confidence(self, mock_search_result):
        """Test confidence calculation."""
        concept = mock_search_result.all()[0]  # Standard concept
        exploration_results = {
            "direct_matches": [concept],
            "synonym_matches": [],
            "relationship_matches": [],
        }

        confidence = self.explorer._calculate_mapping_confidence(
            "test", concept, exploration_results
        )

        assert 0.0 <= confidence <= 1.0

    def test_get_exploration_path(self, mock_search_result):
        """Test exploration path determination."""
        concept = mock_search_result.all()[0]
        exploration_results = {
            "direct_matches": [concept],
            "synonym_matches": [],
            "relationship_matches": [],
        }

        path = self.explorer._get_exploration_path(concept, exploration_results)
        assert path == "direct_search"

    def test_get_source_category(self, mock_search_result):
        """Test source category determination."""
        concept = mock_search_result.all()[0]
        exploration_results = {
            "direct_matches": [concept],
            "synonym_matches": [],
            "relationship_matches": [],
        }

        category = self.explorer._get_source_category(concept, exploration_results)
        assert category == "direct_match"

    @pytest.mark.asyncio
    async def test_suggest_alternative_queries(self):
        """Test alternative query suggestions."""
        suggestions = await self.explorer.suggest_alternative_queries(
            "migraine", max_suggestions=3
        )

        assert isinstance(suggestions, list)
        assert len(suggestions) > 0

    @pytest.mark.asyncio
    async def test_get_concept_hierarchy(
        self, mock_relationships, mock_concept_details
    ):
        """Test concept hierarchy retrieval."""
        # Setup mocks with AsyncMock for async methods
        self.mock_client.details = AsyncMock(return_value=mock_concept_details)
        self.mock_client.relationships = AsyncMock(return_value=mock_relationships)

        hierarchy = await self.explorer.get_concept_hierarchy(1, max_depth=2)

        assert "root_concept" in hierarchy

    @pytest.mark.asyncio
    async def test_error_handling_in_exploration(self):
        """Test error handling during exploration."""
        # Setup mocks to simulate errors
        self.mock_client.search.side_effect = ValueError("Search failed")

        with pytest.raises(ValueError):
            await self.explorer.find_standard_concepts("test")

    @pytest.mark.asyncio
    async def test_empty_results_handling(self):
        """Test handling of empty search results."""
        # Setup empty search results with AsyncMock
        empty_result = Mock()
        empty_result.all.return_value = []
        self.mock_client.search = AsyncMock(return_value=empty_result)

        results = await self.explorer.find_standard_concepts("nonexistent")

        # Should handle empty results gracefully
        assert "direct_matches" in results
        assert len(results["direct_matches"]) == 0

    def test_vocabulary_filtering(self, mock_search_result):
        """Test vocabulary-based filtering."""
        concepts = mock_search_result.all()
        vocabulary_priority = ["RxNorm"]

        filtered = self.explorer._extract_standard_concepts(
            concepts, vocabulary_priority
        )

        # Should still return the concept since it's the only standard one
        assert len(filtered) == 1


class TestCreateConceptExplorer:
    """Test cases for create_concept_explorer function."""

    def test_create_concept_explorer(self):
        """Test concept explorer creation."""
        mock_client = Mock()
        explorer = create_concept_explorer(mock_client)

        assert isinstance(explorer, ConceptExplorer)
        assert explorer.client == mock_client


class TestConceptExplorerIntegration:
    """Integration tests for ConceptExplorer."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = Mock()

    @pytest.mark.asyncio
    async def test_full_exploration_workflow(self, mock_search_result):
        """Test complete exploration workflow."""
        # Setup comprehensive mocks with AsyncMock
        mock_concept = Concept(
            id=1,
            name="Test Concept 1",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical Finding",
            standardConcept=ConceptType.STANDARD,
            code="12345",
            score=0.9,
        )
        mock_search_result.all.return_value = [mock_concept]
        self.mock_client.search = AsyncMock(return_value=mock_search_result)
        self.mock_client.details = AsyncMock(return_value=Mock())
        self.mock_client.relationships = AsyncMock(return_value=Mock(items=[]))

        explorer = ConceptExplorer(self.mock_client)

        # Run full exploration
        results = await explorer.find_standard_concepts(
            query="test",
            max_exploration_depth=1,
            initial_seed_limit=2,
            include_synonyms=True,
            include_relationships=True,
        )

        # Verify results structure
        assert "direct_matches" in results
        assert "synonym_matches" in results
        assert "relationship_matches" in results
        assert "cross_references" in results
        assert "exploration_paths" in results

        # Verify client was called for the initial search
        self.mock_client.search.assert_any_call("test", size=50)

    @pytest.mark.asyncio
    async def test_async_client_integration(
        self, mock_async_client, mock_search_result
    ):
        """Test integration with async client."""
        # Setup the mock async client properly with AsyncMock
        mock_async_client.search = AsyncMock(return_value=mock_search_result)

        # Create a proper mock concept details object
        mock_details = Mock()
        mock_details.id = 3
        mock_details.name = "Test Concept 3"
        mock_details.domainId = "Condition"
        mock_details.vocabularyId = "SNOMED"
        mock_details.conceptClassId = "Clinical Finding"
        mock_details.standardConcept = "Standard"
        mock_details.conceptCode = "12347"
        mock_details.synonyms = []

        mock_async_client.get_concept_details = AsyncMock(return_value=mock_details)

        # Create a proper mock relationships object that will trigger exploration
        from athena_client.models import RelationshipGroup, RelationshipItem

        mock_relationships = ConceptRelationship(
            count=1,
            items=[
                RelationshipGroup(
                    relationshipName="Is a",
                    relationships=[
                        RelationshipItem(
                            targetConceptId=3,
                            targetConceptName="Parent Concept",
                            targetVocabularyId="SNOMED",
                            relationshipId="116680003",
                            relationshipName="Is a",
                        )
                    ],
                )
            ],
        )

        # Use AsyncMock for relationships method
        mock_async_client.relationships = AsyncMock(return_value=mock_relationships)

        explorer = ConceptExplorer(mock_async_client)

        # This should use the async batch processing
        results = await explorer.find_standard_concepts("test")

        # Verify results structure
        assert "direct_matches" in results
        assert "synonym_matches" in results
        assert "relationship_matches" in results
        assert "cross_references" in results
        assert "exploration_paths" in results

```

### File: `athena_client/tests/test_concept_set.py`
<a name="athena_client-tests-test_concept_setpy"></a>
```python
from unittest.mock import AsyncMock, Mock

import pytest

from athena_client.concept_set import ConceptSetGenerator
from athena_client.models import Concept, ConceptType


class TestConceptSetGenerator:
    @pytest.mark.asyncio
    async def test_tier1_happy_path(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = [1]
        db.get_descendants.return_value = [2, 3]

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert set(result["concept_ids"]) == {1, 2, 3}
        assert result["metadata"]["status"] == "SUCCESS"
        assert "Tier 1" in result["metadata"]["strategy_used"]

    @pytest.mark.asyncio
    async def test_tier1_no_descendants(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = [1]
        db.get_descendants.return_value = []

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert result["concept_ids"] == [1]
        assert result["metadata"]["status"] == "SUCCESS"

    @pytest.mark.asyncio
    async def test_tier1_api_concept_not_in_local_db(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = []

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert result["metadata"]["status"] == "FAILURE"

    @pytest.mark.asyncio
    async def test_strict_strategy_failure(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = []

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test", strategy="strict")

        assert result["metadata"]["status"] == "FAILURE"

    @pytest.mark.asyncio
    async def test_include_descendants_false(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = [1]
        db.get_descendants.return_value = [2]

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test", include_descendants=False)

        assert result["concept_ids"] == [1]
        assert result["metadata"]["status"] == "SUCCESS"

    @pytest.mark.asyncio
    async def test_tier2_warning_on_no_descendants(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = [1]
        db.get_descendants.return_value = []

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert result["metadata"]["status"] == "SUCCESS"
        assert "no descendants" in result["metadata"]["warnings"][0]

    @pytest.mark.asyncio
    async def test_tier3_recovery_success(self):
        explorer = Mock()
        concept_a = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        concept_b = Concept(
            id=2,
            name="B",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.NON_STANDARD,
            code="B",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept_a}, {"concept": concept_b}]
        )

        db = Mock()
        db.validate_concepts.side_effect = [[], [3]]
        db.get_standard_mapping.return_value = {2: 3}
        db.get_descendants.return_value = [4]

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert set(result["concept_ids"]) == {3, 4}
        assert (
            result["metadata"]["strategy_used"] == "Tier 3: Recovery via Local Mapping"
        )
        assert "Recovered" in result["metadata"]["warnings"][0]

    @pytest.mark.asyncio
    async def test_tier3_recovery_fails_if_mapped_is_invalid(self):
        explorer = Mock()
        concept_a = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        concept_b = Concept(
            id=2,
            name="B",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.NON_STANDARD,
            code="B",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept_a}, {"concept": concept_b}]
        )

        db = Mock()
        db.validate_concepts.side_effect = [[], []]
        db.get_standard_mapping.return_value = {2: 3}

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test")

        assert result["metadata"]["status"] == "FAILURE"

    @pytest.mark.asyncio
    async def test_strict_mode_skips_tier3_recovery(self):
        explorer = Mock()
        concept = Concept(
            id=1,
            name="A",
            domain="Condition",
            vocabulary="SNOMED",
            className="Clinical",
            standardConcept=ConceptType.STANDARD,
            code="A",
        )
        explorer.map_to_standard_concepts = AsyncMock(
            return_value=[{"concept": concept}]
        )

        db = Mock()
        db.validate_concepts.return_value = []

        generator = ConceptSetGenerator(explorer, db)
        result = await generator.create_from_query("test", strategy="strict")

        assert result["metadata"]["status"] == "FAILURE"
        db.get_standard_mapping.assert_not_called()

```

### File: `athena_client/tests/test_exceptions.py`
<a name="athena_client-tests-test_exceptionspy"></a>
```python
"""
Tests for exception classes and error handling.
"""

from athena_client.exceptions import (
    APIError,
    AthenaError,
    AuthenticationError,
    ClientError,
    NetworkError,
    RateLimitError,
    RetryFailedError,
    ServerError,
    TimeoutError,
    ValidationError,
)


class TestAthenaError:
    """Test base AthenaError class."""

    def test_athena_error_initialization(self):
        """Test AthenaError initialization."""
        error = AthenaError("Test error message")
        assert error.message == "Test error message"
        assert error.error_code is None  # Default value
        assert error.troubleshooting is None  # Default value

    def test_athena_error_string_representation(self):
        """Test AthenaError string representation."""
        error = AthenaError("Test error message")
        error_str = str(error)
        assert "Test error message" in error_str
        # No troubleshooting since it's None

    def test_athena_error_with_custom_values(self):
        """Test AthenaError with custom error_code and troubleshooting."""
        error = AthenaError(
            "Test error message",
            error_code="TEST_ERROR",
            troubleshooting="‚Ä¢ Step 1\n‚Ä¢ Step 2",
        )
        assert error.message == "Test error message"
        assert error.error_code == "TEST_ERROR"
        assert error.troubleshooting == "‚Ä¢ Step 1\n‚Ä¢ Step 2"

    def test_athena_error_string_with_troubleshooting(self):
        """Test AthenaError string representation with troubleshooting."""
        error = AthenaError("Test error message", troubleshooting="‚Ä¢ Step 1\n‚Ä¢ Step 2")
        error_str = str(error)
        assert "Test error message" in error_str
        assert "Step 1" in error_str
        assert "Step 2" in error_str

    def test_athena_error_default_values(self):
        """Test AthenaError default values."""
        error = AthenaError("Simple error")
        assert error.error_code is None  # Default value
        assert error.troubleshooting is None  # Default value


class TestNetworkError:
    """Test NetworkError class."""

    def test_network_error_initialization(self):
        """Test NetworkError initialization."""
        error = NetworkError("Connection failed")
        assert error.message == "Connection failed"
        assert error.error_code == "NETWORK_ERROR"
        assert "internet connection" in error.troubleshooting.lower()

    def test_network_error_with_url(self):
        """Test NetworkError with URL context."""
        error = NetworkError("Connection failed", url="https://api.example.com/test")
        assert "Connection failed" in str(error)

    def test_network_error_message(self):
        err = NetworkError("Connection failed")
        assert "Connection failed" in str(err)


class TestTimeoutError:
    """Test TimeoutError class."""

    def test_timeout_error_initialization(self):
        """Test TimeoutError initialization."""
        error = TimeoutError("Request timeout")
        assert error.message == "Request timeout"
        assert error.error_code == "NETWORK_ERROR"
        assert "timeout" in error.troubleshooting.lower()

    def test_timeout_error_with_timeout_value(self):
        """Test TimeoutError with timeout value."""
        error = TimeoutError("Request timeout")
        assert "Request timeout" in str(error)

    def test_timeout_error_message(self):
        err = TimeoutError("Request timed out")
        assert "Request timed out" in str(err)


class TestValidationError:
    """Test ValidationError class."""

    def test_validation_error_initialization(self):
        """Test ValidationError initialization."""
        error = ValidationError("Invalid JSON response")
        assert error.message == "Invalid JSON response"
        assert error.error_code == "VALIDATION_ERROR"
        assert "api response format" in error.troubleshooting.lower()

    def test_validation_error_string_representation(self):
        """Test ValidationError string representation."""
        error = ValidationError("Invalid JSON response")
        error_str = str(error)
        assert "Invalid JSON response" in error_str

    def test_validation_error_message(self):
        err = ValidationError("Invalid data")
        assert "Invalid data" in str(err)


class TestAuthenticationError:
    """Test AuthenticationError class."""

    def test_authentication_error_initialization(self):
        """Test AuthenticationError initialization."""
        error = AuthenticationError("Unauthorized access", status_code=403)
        assert error.message == "Unauthorized access"
        assert error.error_code == "AUTHENTICATION_ERROR"
        assert error.status_code == 403
        assert "authentication" in error.troubleshooting.lower()

    def test_authentication_error_string_representation(self):
        """Test AuthenticationError string representation."""
        error = AuthenticationError("Unauthorized access", status_code=403)
        error_str = str(error)
        assert "Unauthorized access" in error_str

    def test_authentication_error_message(self):
        err = AuthenticationError("Unauthorized", status_code=401)
        assert "Unauthorized" in str(err)


class TestRateLimitError:
    """Test RateLimitError class."""

    def test_rate_limit_error_initialization(self):
        """Test RateLimitError initialization."""
        error = RateLimitError("Rate limit exceeded", status_code=429)
        assert error.message == "Rate limit exceeded"
        assert error.error_code == "RATE_LIMIT_ERROR"
        assert error.status_code == 429
        assert "rate limit" in error.troubleshooting.lower()

    def test_rate_limit_error_string_representation(self):
        """Test RateLimitError string representation."""
        error = RateLimitError("Rate limit exceeded", status_code=429)
        error_str = str(error)
        assert "Rate limit exceeded" in error_str

    def test_rate_limit_error_message(self):
        err = RateLimitError("Rate limit exceeded", status_code=429)
        assert "Rate limit exceeded" in str(err)


class TestClientError:
    """Test ClientError class."""

    def test_client_error_initialization(self):
        """Test ClientError initialization."""
        error = ClientError("Bad request", status_code=400)
        assert error.message == "Bad request"
        assert error.error_code == "CLIENT_ERROR"
        assert error.status_code == 400
        assert "request parameters" in error.troubleshooting.lower()

    def test_client_error_string_representation(self):
        """Test ClientError string representation."""
        error = ClientError("Invalid parameters", status_code=422)
        error_str = str(error)
        assert "Invalid parameters" in error_str

    def test_client_error_message(self):
        err = ClientError("Bad request", status_code=400)
        assert "Bad request" in str(err)


class TestServerError:
    """Test ServerError class."""

    def test_server_error_initialization(self):
        """Test ServerError initialization."""
        error = ServerError("Service unavailable", status_code=503)
        assert error.message == "Service unavailable"
        assert error.error_code == "SERVER_ERROR"
        assert error.status_code == 503
        assert "server" in error.troubleshooting.lower()

    def test_server_error_string_representation(self):
        """Test ServerError string representation."""
        error = ServerError("Service unavailable", status_code=503)
        error_str = str(error)
        assert "Service unavailable" in error_str

    def test_server_error_message(self):
        err = ServerError("Internal error", status_code=500)
        assert "Internal error" in str(err)


class TestAPIError:
    """Test APIError class."""

    def test_api_error_initialization(self):
        """Test APIError initialization."""
        error = APIError("Search failed", api_error_code="INVALID_QUERY")
        assert error.message == "Search failed"
        assert error.error_code == "API_ERROR"
        assert error.api_error_code == "INVALID_QUERY"

    def test_api_error_string_representation(self):
        """Test APIError string representation."""
        error = APIError("Search failed", api_error_code="INVALID_QUERY")
        error_str = str(error)
        assert "Search failed" in error_str

    def test_api_error_message(self):
        err = APIError("Concept not found", api_error_code="NOT_FOUND")
        assert "Concept not found" in str(err)


class TestRetryFailedError:
    """Test RetryFailedError class."""

    def test_retry_failed_error_initialization(self):
        """Test RetryFailedError initialization."""
        last_error = NetworkError("Connection failed")
        error = RetryFailedError(
            "Retry failed after 3 attempts",
            max_attempts=3,
            last_error=last_error,
            retry_history=[last_error, last_error, last_error],
        )

        assert error.message == "Retry failed after 3 attempts"
        assert error.error_code == "RETRY_FAILED"
        assert error.max_attempts == 3
        assert error.last_error == last_error

    def test_retry_failed_error_message(self):
        err = RetryFailedError(
            "Retry failed after 3 attempts",
            max_attempts=3,
            last_error="Timeout",
            retry_history=["Timeout", "Timeout", "Timeout"],
        )
        assert "Retry failed after 3 attempts" in str(err)
        assert "3" in str(err)
        assert "Timeout" in str(err)


class TestExceptionInheritance:
    """Test exception inheritance hierarchy."""

    def test_exception_inheritance(self):
        """Test that all exceptions inherit from AthenaError."""
        exceptions = [
            NetworkError("test"),
            TimeoutError("test"),
            ValidationError("test"),
            AuthenticationError("test", status_code=401),
            RateLimitError("test", status_code=429),
            ClientError("test", status_code=400),
            ServerError("test", status_code=500),
            APIError("test"),
            RetryFailedError("test", 1, NetworkError("test"), []),
        ]

        for exc in exceptions:
            assert hasattr(exc, "message")
            assert hasattr(exc, "error_code")
            assert hasattr(exc, "troubleshooting")

    def test_exception_types(self):
        """Test that exceptions are of correct types."""
        assert isinstance(NetworkError("test"), NetworkError)
        assert isinstance(TimeoutError("test"), TimeoutError)
        assert isinstance(ValidationError("test"), ValidationError)
        assert isinstance(
            AuthenticationError("test", status_code=401), AuthenticationError
        )
        assert isinstance(RateLimitError("test", status_code=429), RateLimitError)
        assert isinstance(ClientError("test", status_code=400), ClientError)
        assert isinstance(ServerError("test", status_code=500), ServerError)
        assert isinstance(APIError("test"), APIError)
        assert isinstance(
            RetryFailedError("test", 1, NetworkError("test"), []), RetryFailedError
        )


class TestExceptionContext:
    """Test exception context and troubleshooting."""

    def test_network_error_context(self):
        """Test NetworkError provides network-specific troubleshooting."""
        error = NetworkError("Connection failed")
        assert "internet connection" in error.troubleshooting.lower()
        assert "network" in error.troubleshooting.lower()

    def test_authentication_error_context(self):
        """Test AuthenticationError provides auth-specific troubleshooting."""
        error = AuthenticationError("Invalid token")
        assert "token" in error.troubleshooting.lower()
        assert "authentication" in error.troubleshooting.lower()

    def test_rate_limit_error_context(self):
        """Test RateLimitError provides rate limit-specific troubleshooting."""
        error = RateLimitError("Rate limit exceeded", status_code=429)
        assert "rate limit" in error.troubleshooting.lower()
        assert "wait" in error.troubleshooting.lower()

    def test_validation_error_context(self):
        """Test ValidationError provides validation-specific troubleshooting."""
        error = ValidationError("Invalid data")
        assert "api response format" in error.troubleshooting.lower()

    def test_retry_failed_error_context(self):
        """Test RetryFailedError provides retry-specific troubleshooting."""
        error = RetryFailedError("Failed", 3, NetworkError("test"), [])
        assert "retry attempts have been exhausted" in error.troubleshooting
        assert "max_retries" in error.troubleshooting.lower()

```

### File: `athena_client/tests/test_http.py`
<a name="athena_client-tests-test_httppy"></a>
```python
"""Tests for the enhanced HttpClient class."""

import json
from unittest.mock import Mock, patch
from urllib.parse import urljoin

import pytest
import requests
from requests.exceptions import ConnectionError, Timeout

from athena_client.exceptions import (
    AuthenticationError,
    ClientError,
    NetworkError,
    RateLimitError,
    ServerError,
    TimeoutError,
    ValidationError,
)
from athena_client.http import HttpClient


class TestHttpClient:
    """Test cases for the HttpClient class."""

    def test_init_with_defaults(self):
        """Test HttpClient initialization with default values."""
        with patch("athena_client.http.get_settings") as mock_get_settings:
            mock_settings = Mock()
            mock_settings.ATHENA_BASE_URL = "https://api.example.com"
            mock_settings.ATHENA_TIMEOUT_SECONDS = 30
            mock_settings.ATHENA_MAX_RETRIES = 3
            mock_settings.ATHENA_BACKOFF_FACTOR = 0.3
            mock_get_settings.return_value = mock_settings

            client = HttpClient()

            assert client.base_url == "https://api.example.com"
            assert client.timeout == 30
            assert client.max_retries == 3
            assert client.backoff_factor == 0.3
            assert client.enable_throttling is True
            assert client.throttle_delay_range == (0.1, 0.3)

    def test_init_with_custom_values(self):
        """Test HttpClient initialization with custom values."""
        client = HttpClient(
            base_url="https://custom.api.com",
            token="test-token",
            timeout=60,
            max_retries=5,
            backoff_factor=0.5,
            enable_throttling=False,
            throttle_delay_range=(0.5, 1.0),
        )

        assert client.base_url == "https://custom.api.com"
        assert client.timeout == 60
        assert client.max_retries == 5
        assert client.backoff_factor == 0.5
        assert client.enable_throttling is False
        assert client.throttle_delay_range == (0.5, 1.0)

    def test_create_session(self):
        """Test session creation with retry configuration."""
        client = HttpClient(max_retries=5, backoff_factor=0.5)
        session = client.session

        assert session is not None
        # Check that adapters are mounted
        assert "http://" in session.adapters
        assert "https://" in session.adapters

    def test_setup_default_headers(self):
        """Test default headers setup."""
        client = HttpClient()
        headers = client.session.headers

        assert headers["Accept"] == "application/json"
        assert headers["Content-Type"] == "application/json"
        assert headers["User-Agent"] == "AthenaOHDSIAPIClient/1.0"

    def test_throttle_request_enabled(self):
        """Test request throttling when enabled."""
        client = HttpClient(enable_throttling=True)

        with patch("time.sleep") as mock_sleep:
            client._throttle_request()
            mock_sleep.assert_called_once()

    def test_throttle_request_disabled(self):
        """Test request throttling when disabled."""
        client = HttpClient(enable_throttling=False)

        with patch("time.sleep") as mock_sleep:
            client._throttle_request()
            mock_sleep.assert_not_called()

    def test_handle_rate_limit_with_retry_after(self):
        """Test rate limit handling with Retry-After header."""
        client = HttpClient()
        response = Mock()
        response.headers = {"Retry-After": "30"}

        with patch("time.sleep") as mock_sleep:
            client._handle_rate_limit(response)
            mock_sleep.assert_called_once_with(30)

    def test_handle_rate_limit_without_retry_after(self):
        """Test rate limit handling without Retry-After header."""
        client = HttpClient()
        response = Mock()
        response.headers = {}

        with patch("time.sleep") as mock_sleep:
            client._handle_rate_limit(response)
            mock_sleep.assert_called_once_with(60)

    def test_build_url(self):
        """Test URL building."""
        client = HttpClient(base_url="https://api.example.com")
        url = client._build_url("/concepts/search")
        expected = urljoin("https://api.example.com", "/concepts/search")
        assert url == expected

    def test_normalize_params(self):
        """Test parameter normalization."""
        client = HttpClient()

        # Test with None
        assert client._normalize_params(None) is None

        # Test with empty dict
        assert client._normalize_params({}) == {}

        # Test with mixed types
        params = {"string": "value", "int": 123, "float": 1.23, "bool": True}
        normalized = client._normalize_params(params)
        assert normalized == {
            "string": "value",
            "int": "123",
            "float": "1.23",
            "bool": "True",
        }

    def test_handle_response_success(self):
        """Test successful response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 200
        response.json.return_value = {"result": "success"}
        response.text = "success response"

        result = client._handle_response(response, "https://api.example.com/test")
        assert result == {"result": "success"}

    def test_handle_response_400_error(self):
        """Test 400 error response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 400
        response.reason_phrase = "Bad Request"
        response.text = "Invalid request"

        # Create a proper HTTPError with the response object
        http_error = requests.exceptions.HTTPError("400 Bad Request")
        http_error.response = response
        response.raise_for_status.side_effect = http_error

        with pytest.raises(ClientError) as exc_info:
            client._handle_response(response, "https://api.example.com/test")

        assert "400" in str(exc_info.value)

    def test_handle_response_401_error(self):
        """Test 401 error response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 401
        response.reason_phrase = "Unauthorized"
        response.text = "Authentication required"

        # Create a proper HTTPError with the response object
        http_error = requests.exceptions.HTTPError("401 Unauthorized")
        http_error.response = response
        response.raise_for_status.side_effect = http_error

        with pytest.raises(AuthenticationError) as exc_info:
            client._handle_response(response, "https://api.example.com/test")

        assert "401" in str(exc_info.value)

    def test_handle_response_429_error(self):
        """Test 429 error response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 429
        response.reason_phrase = "Too Many Requests"
        response.text = "Rate limit exceeded"

        # Create a proper HTTPError with the response object
        http_error = requests.exceptions.HTTPError("429 Too Many Requests")
        http_error.response = response
        response.raise_for_status.side_effect = http_error

        with pytest.raises(RateLimitError) as exc_info:
            client._handle_response(response, "https://api.example.com/test")

        assert "429" in str(exc_info.value)

    def test_handle_response_500_error(self):
        """Test 500 error response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 500
        response.reason_phrase = "Internal Server Error"
        response.text = "Server error"

        # Create a proper HTTPError with the response object
        http_error = requests.exceptions.HTTPError("500 Internal Server Error")
        http_error.response = response
        response.raise_for_status.side_effect = http_error

        with pytest.raises(ServerError) as exc_info:
            client._handle_response(response, "https://api.example.com/test")

        assert "500" in str(exc_info.value)

    def test_handle_response_invalid_json(self):
        """Test invalid JSON response handling."""
        client = HttpClient()
        response = Mock()
        response.status_code = 200
        response.json.side_effect = json.JSONDecodeError("Invalid JSON", "", 0)
        response.text = "invalid json"

        with pytest.raises(ValidationError) as exc_info:
            client._handle_response(response, "https://api.example.com/test")

        assert "Invalid JSON" in str(exc_info.value)

    @patch("athena_client.http.build_headers")
    def test_request_success(self, mock_build_headers):
        """Test successful request."""
        mock_build_headers.return_value = {"Authorization": "Bearer token"}

        client = HttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}
        mock_response.text = "success response"
        mock_response.reason = "OK"

        with patch.object(client.session, "request", return_value=mock_response):
            result = client.request("GET", "/test")
            assert result == {"result": "success"}

    @patch("athena_client.http.build_headers")
    def test_request_with_params(self, mock_build_headers):
        """Test request with parameters."""
        mock_build_headers.return_value = {}

        client = HttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}
        mock_response.text = "success response"
        mock_response.reason = "OK"

        with patch.object(
            client.session, "request", return_value=mock_response
        ) as mock_request:
            client.request("GET", "/test", params={"key": "value"})
            mock_request.assert_called_once()
            call_args = mock_request.call_args
            assert call_args[1]["params"] == {"key": "value"}

    @patch("athena_client.http.build_headers")
    def test_request_with_data(self, mock_build_headers):
        """Test request with data."""
        mock_build_headers.return_value = {}

        client = HttpClient()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"result": "success"}
        mock_response.text = "success response"
        mock_response.reason = "OK"

        with patch.object(
            client.session, "request", return_value=mock_response
        ) as mock_request:
            client.request("POST", "/test", data={"key": "value"})
            mock_request.assert_called_once()
            call_args = mock_request.call_args
            assert call_args[1]["data"] == b'{"key": "value"}'

    @patch("athena_client.http.build_headers")
    def test_request_raw_response(self, mock_build_headers):
        """Test request with raw response."""
        mock_build_headers.return_value = {}

        client = HttpClient()
        mock_response = Mock()
        mock_response.status_code = 200

        with patch.object(client.session, "request", return_value=mock_response):
            result = client.request("GET", "/test", raw_response=True)
            assert result == mock_response

    @patch("athena_client.http.build_headers")
    def test_request_network_error(self, mock_build_headers):
        """Test request with network error."""
        mock_build_headers.return_value = {}

        client = HttpClient()

        with patch.object(
            client.session, "request", side_effect=ConnectionError("Connection failed")
        ):
            with pytest.raises(NetworkError) as exc_info:
                client.request("GET", "/test")
            assert "Connection error" in str(exc_info.value)

    @patch("athena_client.http.build_headers")
    def test_request_timeout_error(self, mock_build_headers):
        """Test request with timeout error."""
        mock_build_headers.return_value = {}

        client = HttpClient()

        with patch.object(
            client.session, "request", side_effect=Timeout("Request timeout")
        ):
            with pytest.raises(TimeoutError) as exc_info:
                client.request("GET", "/test")
            assert "Timeout" in str(exc_info.value)

    def test_get_method(self):
        """Test GET method."""
        client = HttpClient()

        with patch.object(client, "request") as mock_request:
            mock_request.return_value = {"result": "success"}
            result = client.get("/test", params={"key": "value"})

            mock_request.assert_called_once_with(
                "GET", "/test", params={"key": "value"}, raw_response=False
            )
            assert result == {"result": "success"}

    def test_post_method(self):
        """Test POST method."""
        client = HttpClient()

        with patch.object(client, "request") as mock_request:
            mock_request.return_value = {"result": "success"}
            result = client.post("/test", data={"key": "value"})

            mock_request.assert_called_once_with(
                "POST", "/test", data={"key": "value"}, params=None, raw_response=False
            )
            assert result == {"result": "success"}

    def test_close(self):
        """Test client close method."""
        client = HttpClient()

        with patch.object(client.session, "close") as mock_close:
            client.close()
            mock_close.assert_called_once()

    def test_context_manager(self):
        """Test client as context manager."""
        with HttpClient() as client:
            assert isinstance(client, HttpClient)

        # Session should be closed after context exit
        # Note: requests.Session doesn't have a 'closed' attribute, so we check
        # if close was called

    def test_context_manager_exception(self):
        """Test context manager with exception."""
        with pytest.raises(ValueError):
            with HttpClient():
                raise ValueError("Test exception")

        # Session should still be closed even with exception
        # Note: requests.Session doesn't have a 'closed' attribute

```

### File: `athena_client/tests/test_models.py`
<a name="athena_client-tests-test_modelspy"></a>
```python
"""
Tests for Pydantic models and data validation.
"""

import pytest

from athena_client.models import (
    Concept,
    ConceptDetails,
    ConceptSearchResponse,
    ConceptType,
)


class TestConceptType:
    """Test ConceptType enum."""

    def test_concept_type_values(self):
        """Test ConceptType enum values."""
        assert ConceptType.STANDARD == "Standard"
        assert ConceptType.NON_STANDARD == "Non-standard"
        assert ConceptType.CLASSIFICATION == "Classification"

    def test_concept_type_string_representation(self):
        """Test ConceptType string representation."""
        assert ConceptType.STANDARD == "Standard"
        assert ConceptType.NON_STANDARD == "Non-standard"
        assert ConceptType.CLASSIFICATION == "Classification"


class TestConcept:
    """Test Concept model."""

    def test_concept_initialization(self):
        """Test Concept model initialization."""
        concept = Concept(
            id=1,
            name="Aspirin",
            domain="Drug",
            vocabulary="RxNorm",
            className="Ingredient",
            standardConcept=ConceptType.STANDARD,
            code="1191",
            invalidReason=None,
            score=1.0,
        )

        assert concept.id == 1
        assert concept.name == "Aspirin"
        assert concept.domain == "Drug"
        assert concept.vocabulary == "RxNorm"
        assert concept.className == "Ingredient"
        assert concept.standardConcept == ConceptType.STANDARD
        assert concept.code == "1191"
        assert concept.invalidReason is None
        assert concept.score == 1.0

    def test_concept_from_dict(self):
        """Test Concept model creation from dictionary."""
        data = {
            "id": 1,
            "name": "Aspirin",
            "domain": "Drug",
            "vocabulary": "RxNorm",
            "className": "Ingredient",
            "standardConcept": "Standard",
            "code": "1191",
            "invalidReason": None,
            "score": 1.0,
        }

        concept = Concept.model_validate(data)

        assert concept.name == "Aspirin"
        assert concept.standardConcept == ConceptType.STANDARD

    def test_concept_with_optional_fields(self):
        """Test Concept model with optional fields."""
        concept_data = {
            "id": 1,
            "name": "Aspirin",
            "domain": "Drug",
            "vocabulary": "RxNorm",
            "className": "Ingredient",
            "standardConcept": None,
            "code": "1191",
            "invalidReason": "U",
            "score": 0.8,
        }

        concept = Concept.model_validate(concept_data)

        assert concept.id == 1
        assert concept.name == "Aspirin"
        assert concept.standardConcept is None
        assert concept.invalidReason == "U"
        assert concept.score == 0.8

    def test_concept_string_representation(self):
        """Test Concept string representation."""
        concept = Concept(
            id=1,
            name="Aspirin",
            domain="Drug",
            vocabulary="RxNorm",
            className="Ingredient",
            standardConcept=ConceptType.STANDARD,
            code="1191",
            invalidReason=None,
            score=1.0,
        )

        # Test that string representation includes key fields
        concept_str = str(concept)
        assert "Aspirin" in concept_str
        assert "Drug" in concept_str


class TestConceptDetails:
    """Test ConceptDetails model."""

    def test_concept_details_initialization(self):
        """Test ConceptDetails model initialization."""
        details = ConceptDetails(
            id=1,
            name="Aspirin",
            domainId="Drug",
            vocabularyId="RxNorm",
            conceptClassId="Ingredient",
            standardConcept=ConceptType.STANDARD,
            conceptCode="1191",
            invalidReason=None,
            validStart="2000-01-01",
            validEnd="2099-12-31",
        )

        assert details.id == 1
        assert details.name == "Aspirin"
        assert details.domainId == "Drug"
        assert details.vocabularyId == "RxNorm"
        assert details.conceptClassId == "Ingredient"
        assert details.standardConcept == ConceptType.STANDARD
        assert details.conceptCode == "1191"
        assert details.invalidReason is None
        assert details.validStart == "2000-01-01"
        assert details.validEnd == "2099-12-31"

    def test_concept_details_from_dict(self):
        """Test ConceptDetails model creation from dictionary."""
        data = {
            "id": 1,
            "name": "Aspirin",
            "domainId": "Drug",
            "vocabularyId": "RxNorm",
            "conceptClassId": "Ingredient",
            "standardConcept": "Standard",
            "conceptCode": "1191",
            "invalidReason": None,
            "validStart": "2000-01-01",
            "validEnd": "2099-12-31",
        }

        details = ConceptDetails.model_validate(data)

        assert details.name == "Aspirin"
        assert details.standardConcept == ConceptType.STANDARD

    def test_concept_details_without_optional_fields(self):
        """Test ConceptDetails model without optional fields."""
        details_data = {
            "id": 1,
            "name": "Aspirin",
            "domainId": "Drug",
            "vocabularyId": "RxNorm",
            "conceptClassId": "Ingredient",
            "standardConcept": "Standard",
            "conceptCode": "1191",
            "invalidReason": None,
            "validStart": "2000-01-01",
            "validEnd": "2099-12-31",
        }

        details = ConceptDetails.model_validate(details_data)

        assert details.id == 1
        assert details.name == "Aspirin"
        assert details.standardConcept == ConceptType.STANDARD

    def test_concept_details_string_representation(self):
        """Test ConceptDetails string representation."""
        details = ConceptDetails(
            id=1,
            name="Aspirin",
            domainId="Drug",
            vocabularyId="RxNorm",
            conceptClassId="Ingredient",
            standardConcept=ConceptType.STANDARD,
            conceptCode="1191",
            invalidReason=None,
            validStart="2000-01-01",
            validEnd="2099-12-31",
        )

        # Test that string representation includes key fields
        details_str = str(details)
        assert "Aspirin" in details_str
        assert "Drug" in details_str


class TestConceptSearchResponse:
    """Test ConceptSearchResponse model."""

    def test_concept_search_response_initialization(self):
        """Test ConceptSearchResponse model initialization."""
        response = ConceptSearchResponse(
            content=[
                Concept(
                    id=1,
                    name="Aspirin",
                    domain="Drug",
                    vocabulary="RxNorm",
                    className="Ingredient",
                    standardConcept=ConceptType.STANDARD,
                    code="1191",
                    invalidReason=None,
                    score=1.0,
                )
            ],
            pageable={"pageSize": 1},
            totalElements=1,
            last=True,
            totalPages=1,
            first=True,
            size=1,
            number=0,
            numberOfElements=1,
            empty=False,
        )

        assert len(response.content) == 1
        assert response.content[0].name == "Aspirin"
        assert response.totalElements == 1
        assert response.last is True
        assert response.empty is False

    def test_concept_search_response_from_dict(self):
        """Test ConceptSearchResponse model creation from dictionary."""
        data = {
            "content": [
                {
                    "id": 1,
                    "name": "Aspirin",
                    "domain": "Drug",
                    "vocabulary": "RxNorm",
                    "className": "Ingredient",
                    "standardConcept": "Standard",
                    "code": "1191",
                    "invalidReason": None,
                    "score": 1.0,
                }
            ],
            "pageable": {"pageSize": 1},
            "totalElements": 1,
            "last": True,
            "totalPages": 1,
            "first": True,
            "size": 1,
            "number": 0,
            "numberOfElements": 1,
            "empty": False,
        }

        response = ConceptSearchResponse.model_validate(data)

        assert len(response.content) == 1
        assert response.content[0].name == "Aspirin"
        assert response.totalElements == 1
        assert response.last is True
        assert response.empty is False

    def test_concept_search_response_empty(self):
        """Test ConceptSearchResponse model with empty results."""
        response_data = {
            "content": [],
            "pageable": {"pageSize": 1},
            "totalElements": 0,
            "last": True,
            "totalPages": 1,
            "first": True,
            "size": 1,
            "number": 0,
            "numberOfElements": 0,
            "empty": True,
        }

        response = ConceptSearchResponse.model_validate(response_data)

        assert len(response.content) == 0
        assert response.totalElements == 0
        assert response.empty is True


class TestModelValidation:
    """Test model validation and error handling."""

    def test_invalid_concept_data(self):
        """Test validation error with invalid concept data."""
        invalid_data = {
            "id": "not_an_integer",  # Should be int
            "name": "Aspirin",
            "domain_id": "Drug",
            "vocabulary_id": "RxNorm",
            "concept_class_id": "Ingredient",
            "standard_concept": "S",
            "concept_code": "1191",
            "valid_start_date": "2000-01-01",
            "valid_end_date": "2099-12-31",
            "invalid_reason": None,
            "domain": {"id": 13, "name": "Drug"},
            "vocabulary": {"id": "RxNorm", "name": "RxNorm"},
            "concept_class": {"id": "Ingredient", "name": "Ingredient"},
        }

        with pytest.raises(ValueError):
            Concept.model_validate(invalid_data)

    def test_missing_required_fields(self):
        """Test validation error with missing required fields."""
        incomplete_data = {
            "id": 1127433,
            "name": "Aspirin",
            # Missing required fields
        }

        with pytest.raises(ValueError):
            Concept.model_validate(incomplete_data)

    def test_invalid_concept_type(self):
        """Test validation error with invalid concept type."""
        invalid_data = {
            "id": 1127433,
            "name": "Aspirin",
            "domain_id": "Drug",
            "vocabulary_id": "RxNorm",
            "concept_class_id": "Ingredient",
            "standard_concept": "INVALID",  # Invalid enum value
            "concept_code": "1191",
            "valid_start_date": "2000-01-01",
            "valid_end_date": "2099-12-31",
            "invalid_reason": None,
            "domain": {"id": 13, "name": "Drug"},
            "vocabulary": {"id": "RxNorm", "name": "RxNorm"},
            "concept_class": {"id": "Ingredient", "name": "Ingredient"},
        }

        with pytest.raises(ValueError):
            Concept.model_validate(invalid_data)

```

### File: `athena_client/tests/test_query.py`
<a name="athena_client-tests-test_querypy"></a>
```python
"""
Tests for the Query DSL.
"""

from athena_client.query import Q


def test_term_query():
    """Test basic term query construction."""
    q = Q.term("diabetes")
    boosts = q.to_boosts()

    assert boosts["filter"]["query_string"]["query"] == "diabetes"
    assert "name^10" in boosts["filter"]["query_string"]["fields"]
    assert "synonyms^5" in boosts["filter"]["query_string"]["fields"]


def test_phrase_query():
    """Test phrase query construction."""
    q = Q.phrase("heart attack")
    boosts = q.to_boosts()

    assert boosts["filter"]["query_string"]["query"] == '"heart attack"'


def test_exact_query():
    """Test exact query construction."""
    q = Q.exact('"Myocardial Infarction"')
    boosts = q.to_boosts()

    assert boosts["filter"]["query_string"]["query"] == '"Myocardial Infarction"'
    assert "concept_code^20" in boosts["filter"]["query_string"]["fields"]
    assert "name.exact^15" in boosts["filter"]["query_string"]["fields"]


def test_wildcard_query():
    """Test wildcard query construction."""
    q = Q.wildcard("aspir*")
    boosts = q.to_boosts()

    assert boosts["filter"]["query_string"]["query"] == "aspir*"


def test_fuzzy_modifier():
    """Test fuzzy modifier."""
    q = Q.term("aspirin").fuzzy(0.8)
    boosts = q.to_boosts()

    assert boosts["filter"]["query_string"]["fuzziness"] == 0.8


def test_and_operator():
    """Test AND operator."""
    q = Q.term("diabetes") & Q.term("type 2")
    boosts = q.to_boosts()

    assert "must" in boosts["filter"]["bool"]
    assert len(boosts["filter"]["bool"]["must"]) == 2


def test_or_operator():
    """Test OR operator."""
    q = Q.term("heart") | Q.term("cardiac")
    boosts = q.to_boosts()

    assert "should" in boosts["filter"]["bool"]
    assert len(boosts["filter"]["bool"]["should"]) == 2


def test_not_operator():
    """Test NOT operator."""
    q = -Q.term("chronic")
    boosts = q.to_boosts()

    assert "must_not" in boosts["filter"]["bool"]
    assert len(boosts["filter"]["bool"]["must_not"]) == 1


def test_complex_query():
    """Test complex query with multiple operators."""
    q = (Q.term("diabetes") & Q.term("type 2")) | Q.exact('"diabetic nephropathy"')
    boosts = q.to_boosts()

    assert "should" in boosts["filter"]["bool"]

```

### File: `athena_client/tests/test_search_result.py`
<a name="athena_client-tests-test_search_resultpy"></a>
```python
"""
Tests for SearchResult class and pagination functionality.
"""

from unittest.mock import MagicMock, Mock, patch

import pytest

from athena_client.models import Concept, ConceptSearchResponse, ConceptType
from athena_client.search_result import SearchResult


@pytest.fixture
def mock_client():
    """Create a mock client for SearchResult tests."""
    return Mock()


@pytest.fixture
def mock_search_response():
    """Create a mock search response."""
    return ConceptSearchResponse(
        content=[
            Concept(
                id=1,
                name="Aspirin",
                domain="Drug",
                vocabulary="RxNorm",
                className="Ingredient",
                standardConcept=ConceptType.STANDARD,
                code="1191",
                invalidReason=None,
                score=1.0,
            )
        ],
        pageable={"pageSize": 1},
        totalElements=1,
        last=True,
        totalPages=1,
        first=True,
        size=1,
        number=0,
        numberOfElements=1,
        empty=False,
    )


def test_search_result_init(mock_search_response, mock_client):
    """Test SearchResult initialization."""
    result = SearchResult(mock_search_response, mock_client)
    assert result.total_elements == 1
    assert len(result.all()) == 1
    assert result.all()[0].name == "Aspirin"


def test_search_result_validation_error(mock_client):
    """Test that passing a dict does not raise an error
    (type is not enforced at runtime)."""
    # This should not raise an error, but will not behave as expected
    result = SearchResult({"invalid": "data"}, mock_client)
    assert result is not None


def test_search_result_top(mock_search_response, mock_client):
    """Test top N results."""
    result = SearchResult(mock_search_response, mock_client)
    top_results = result.top(1)
    assert len(top_results) == 1
    assert top_results[0].name == "Aspirin"


def test_search_result_to_list(mock_search_response, mock_client):
    """Test conversion to list of dictionaries."""
    result = SearchResult(mock_search_response, mock_client)
    data_list = result.to_list()
    assert isinstance(data_list, list)
    assert len(data_list) == 1
    assert data_list[0]["name"] == "Aspirin"


def test_search_result_to_json(mock_search_response, mock_client):
    """Test conversion to JSON."""
    result = SearchResult(mock_search_response, mock_client)
    json_str = result.to_json()
    assert isinstance(json_str, str)
    assert "Aspirin" in json_str


def test_search_result_to_df(mock_search_response, mock_client):
    """Test conversion to DataFrame."""
    mock_dataframe = MagicMock()
    mock_pandas = MagicMock()
    mock_pandas.DataFrame.return_value = mock_dataframe

    with patch.dict("sys.modules", {"pandas": mock_pandas}):
        with patch("athena_client.search_result.pd", mock_pandas):
            result = SearchResult(mock_search_response, mock_client)
            df = result.to_df()
            assert df == mock_dataframe


def test_search_result_to_df_missing_pandas(mock_search_response, mock_client):
    """Test error when pandas is missing."""
    result = SearchResult(mock_search_response, mock_client)
    with patch("athena_client.search_result.pd", None):
        with pytest.raises(AttributeError):
            result.to_df()


def test_search_result_pagination_properties(mock_search_response, mock_client):
    """Test pagination properties."""
    result = SearchResult(mock_search_response, mock_client)
    assert result.total_elements == 1
    assert result.total_pages == 1
    assert result.current_page == 0
    assert result.page_size == 1


def test_search_result_length_and_indexing(mock_search_response, mock_client):
    """Test length and indexing."""
    result = SearchResult(mock_search_response, mock_client)
    assert len(result) == 1
    assert result[0].name == "Aspirin"

    # Test iteration
    concepts = list(result)
    assert len(concepts) == 1
    assert concepts[0].name == "Aspirin"


class TestSearchResult:
    """Test cases for the SearchResult class."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = Mock()
        self.mock_response = Mock(spec=ConceptSearchResponse)

        # Set up default response attributes with correct Concept structure
        self.mock_response.content = [
            Concept(
                id=1,
                name="Test Concept 1",
                domain="Test Domain",
                vocabulary="Test Vocab",
                className="Test Class",
                code="TEST001",
            ),
            Concept(
                id=2,
                name="Test Concept 2",
                domain="Test Domain",
                vocabulary="Test Vocab",
                className="Test Class",
                code="TEST002",
            ),
        ]
        self.mock_response.totalElements = 2
        self.mock_response.totalPages = 1
        self.mock_response.number = 0
        self.mock_response.size = 20
        self.mock_response.first = True
        self.mock_response.last = True
        self.mock_response.facets = {"domain": {"Test": 2}}
        self.mock_response.pageable = None

        self.search_result = SearchResult(self.mock_response, self.mock_client)

    def test_init(self):
        """Test SearchResult initialization."""
        assert self.search_result._response == self.mock_response
        assert self.search_result._client == self.mock_client

    def test_all(self):
        """Test getting all concepts."""
        result = self.search_result.all()
        assert result == self.mock_response.content
        assert len(result) == 2

    def test_top(self):
        """Test getting top N concepts."""
        result = self.search_result.top(1)
        assert len(result) == 1
        assert result[0].id == 1
        assert result[0].name == "Test Concept 1"

    def test_top_more_than_available(self):
        """Test getting top N concepts when N > available."""
        result = self.search_result.top(5)
        assert len(result) == 2
        assert result == self.mock_response.content

    def test_to_list(self):
        """Test converting to list of dictionaries."""
        result = self.search_result.to_list()
        assert isinstance(result, list)
        assert len(result) == 2
        assert result[0]["id"] == 1
        assert result[0]["name"] == "Test Concept 1"

    def test_to_json(self):
        """Test converting to JSON string."""
        # Mock the model_dump_json method
        self.mock_response.model_dump_json.return_value = '{"content": []}'

        result = self.search_result.to_json()
        assert result == '{"content": []}'
        self.mock_response.model_dump_json.assert_called_once()

    @patch("athena_client.search_result.pd")
    def test_to_df_success(self, mock_pd):
        """Test converting to pandas DataFrame successfully."""
        mock_df = Mock()
        mock_pd.DataFrame.return_value = mock_df

        result = self.search_result.to_df()

        assert result == mock_df
        mock_pd.DataFrame.assert_called_once()

    @patch("athena_client.search_result.pd")
    def test_to_df_import_error(self, mock_pd):
        """Test converting to DataFrame when pandas is not available."""
        mock_pd.DataFrame.side_effect = ImportError("No module named 'pandas'")

        with pytest.raises(ImportError) as exc_info:
            self.search_result.to_df()

        assert "pandas is required for DataFrame output" in str(exc_info.value)

    def test_next_page_when_last_page(self):
        """Test next_page when on last page."""
        self.mock_response.last = True

        result = self.search_result.next_page()
        assert result is None

    def test_next_page_when_not_last_page(self):
        """Test next_page when not on last page."""
        self.mock_response.last = False
        self.mock_response.number = 0
        self.mock_response.size = 20

        # Mock the client search method
        mock_next_result = Mock()
        self.mock_client.search.return_value = mock_next_result

        result = self.search_result.next_page()

        assert result == mock_next_result
        self.mock_client.search.assert_called_once_with(query="", page=1, size=20)

    def test_next_page_with_none_values(self):
        """Test next_page when number or size is None."""
        self.mock_response.last = False
        self.mock_response.number = None
        self.mock_response.size = None

        result = self.search_result.next_page()
        assert result is None

    def test_previous_page_when_first_page(self):
        """Test previous_page when on first page."""
        self.mock_response.first = True

        result = self.search_result.previous_page()
        assert result is None

    def test_previous_page_when_not_first_page(self):
        """Test previous_page when not on first page."""
        self.mock_response.first = False
        self.mock_response.number = 1
        self.mock_response.size = 20

        # Mock the client search method
        mock_prev_result = Mock()
        self.mock_client.search.return_value = mock_prev_result

        result = self.search_result.previous_page()

        assert result == mock_prev_result
        self.mock_client.search.assert_called_once_with(query="", page=0, size=20)

    def test_previous_page_with_none_values(self):
        """Test previous_page when number or size is None."""
        self.mock_response.first = False
        self.mock_response.number = None
        self.mock_response.size = None

        result = self.search_result.previous_page()
        assert result is None

    def test_total_elements_direct_field(self):
        """Test total_elements with direct field."""
        self.mock_response.totalElements = 100

        result = self.search_result.total_elements
        assert result == 100

    def test_total_elements_from_pageable(self):
        """Test total_elements from pageable field."""
        self.mock_response.totalElements = None
        self.mock_response.pageable = {"totalElements": 150}

        result = self.search_result.total_elements
        assert result == 150

    def test_total_elements_fallback(self):
        """Test total_elements fallback to content length."""
        self.mock_response.totalElements = None
        self.mock_response.pageable = None

        result = self.search_result.total_elements
        assert result == 2  # Length of content

    def test_total_pages_direct_field(self):
        """Test total_pages with direct field."""
        self.mock_response.totalPages = 5

        result = self.search_result.total_pages
        assert result == 5

    def test_total_pages_calculated_from_pageable(self):
        """Test total_pages calculated from pageable."""
        self.mock_response.totalPages = None
        self.mock_response.pageable = {"totalElements": 100, "pageSize": 20}

        result = self.search_result.total_pages
        assert result == 5  # (100 + 20 - 1) // 20 = 5

    def test_total_pages_fallback(self):
        """Test total_pages fallback."""
        self.mock_response.totalPages = None
        self.mock_response.pageable = None

        result = self.search_result.total_pages
        assert result == 1

    def test_current_page_direct_field(self):
        """Test current_page with direct field."""
        self.mock_response.number = 3

        result = self.search_result.current_page
        assert result == 3

    def test_current_page_from_pageable(self):
        """Test current_page from pageable field."""
        self.mock_response.number = None
        self.mock_response.pageable = {"pageNumber": 2}

        result = self.search_result.current_page
        assert result == 2

    def test_current_page_fallback(self):
        """Test current_page fallback."""
        self.mock_response.number = None
        self.mock_response.pageable = None

        result = self.search_result.current_page
        assert result == 0

    def test_page_size_direct_field(self):
        """Test page_size with direct field."""
        self.mock_response.size = 50

        result = self.search_result.page_size
        assert result == 50

    def test_page_size_from_pageable(self):
        """Test page_size from pageable field."""
        self.mock_response.size = None
        self.mock_response.pageable = {"pageSize": 25}

        result = self.search_result.page_size
        assert result == 25

    def test_page_size_fallback(self):
        """Test page_size fallback to content length."""
        self.mock_response.size = None
        self.mock_response.pageable = None

        result = self.search_result.page_size
        assert result == 2  # Length of content

    def test_facets(self):
        """Test getting facets."""
        result = self.search_result.facets
        assert result == {"domain": {"Test": 2}}

    def test_facets_none(self):
        """Test getting facets when None."""
        self.mock_response.facets = None

        result = self.search_result.facets
        assert result is None

    def test_len(self):
        """Test length of search result."""
        result = len(self.search_result)
        assert result == 2

    def test_getitem(self):
        """Test getting item by index."""
        result = self.search_result[0]
        assert result.id == 1
        assert result.name == "Test Concept 1"

    def test_getitem_negative_index(self):
        """Test getting item with negative index."""
        result = self.search_result[-1]
        assert result.id == 2
        assert result.name == "Test Concept 2"

    def test_iter(self):
        """Test iteration over search result."""
        concepts = list(self.search_result)
        assert len(concepts) == 2
        assert concepts[0].id == 1
        assert concepts[1].id == 2

    def test_empty_search_result(self):
        """Test search result with empty content."""
        self.mock_response.content = []
        self.mock_response.totalElements = 0
        self.mock_response.totalPages = 0
        self.mock_response.number = 0
        self.mock_response.size = 20
        self.mock_response.first = True
        self.mock_response.last = True

        empty_result = SearchResult(self.mock_response, self.mock_client)

        assert len(empty_result) == 0
        assert empty_result.all() == []
        assert empty_result.top(5) == []
        assert empty_result.total_elements == 0
        assert empty_result.total_pages == 0
        assert empty_result.current_page == 0
        assert (
            empty_result.page_size == 20
        )  # Should use the size field, not content length

    def test_search_result_with_pageable_only(self):
        """Test search result with only pageable information."""
        self.mock_response.totalElements = None
        self.mock_response.totalPages = None
        self.mock_response.number = None
        self.mock_response.size = None
        self.mock_response.pageable = {
            "totalElements": 200,
            "totalPages": 10,
            "pageNumber": 3,
            "pageSize": 20,
        }

        result = SearchResult(self.mock_response, self.mock_client)

        assert result.total_elements == 200
        assert result.total_pages == 10
        assert result.current_page == 3
        assert result.page_size == 20

    def test_search_result_edge_cases(self):
        """Test search result with edge case values."""
        # Test with None pageable
        self.mock_response.pageable = None

        result = SearchResult(self.mock_response, self.mock_client)

        # Should use the size field, not content length
        assert result.page_size == 20

        # Test with empty pageable
        self.mock_response.pageable = {}

        result = SearchResult(self.mock_response, self.mock_client)

        # Should use the size field, not content length
        assert result.page_size == 20

    def test_search_result_with_missing_pageable_fields(self):
        """Test search result with missing pageable fields."""
        self.mock_response.totalElements = None
        self.mock_response.totalPages = None
        self.mock_response.number = None
        self.mock_response.size = None
        self.mock_response.pageable = {
            "totalElements": 100,
            # Missing pageSize
        }

        result = SearchResult(self.mock_response, self.mock_client)

        # Should fall back to content length for page_size
        assert result.page_size == 2
        # Should calculate total_pages as 1 (fallback)
        assert result.total_pages == 1

    def test_search_result_with_partial_pageable(self):
        """Test search result with partial pageable information."""
        self.mock_response.totalElements = None
        self.mock_response.totalPages = None
        self.mock_response.number = None
        self.mock_response.size = None
        self.mock_response.pageable = {
            "pageSize": 25,
            # Missing totalElements
        }

        result = SearchResult(self.mock_response, self.mock_client)

        # Should use pageable pageSize
        assert result.page_size == 25
        # Should fall back to content length for total_elements
        assert result.total_elements == 2

```

### File: `athena_client/tests/test_utils.py`
<a name="athena_client-tests-test_utilspy"></a>
```python
"""Tests for the utils module."""

import logging
from unittest.mock import Mock, patch

from athena_client.utils import configure_logging


class TestUtils:
    """Test cases for the utils module."""

    def test_configure_logging_default_level(self):
        """Test logging configuration with default level."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            configure_logging()

            mock_logging.getLogger.assert_called_with("athena_client")
            mock_logger.setLevel.assert_called_with(logging.INFO)

    def test_configure_logging_custom_level(self):
        """Test logging configuration with custom level."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.DEBUG = logging.DEBUG

            configure_logging(logging.DEBUG)

            mock_logger.setLevel.assert_called_with(logging.DEBUG)

    def test_configure_logging_with_existing_handlers(self):
        """Test logging configuration when handlers already exist."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logger.handlers = [Mock()]  # Existing handler
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO
            mock_logging.StreamHandler = Mock()
            mock_logging.Formatter = Mock()

            configure_logging()

            # Should not add new handler when handlers already exist
            mock_logging.StreamHandler.assert_not_called()

    def test_configure_logging_without_handlers(self):
        """Test logging configuration when no handlers exist."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logger.handlers = []  # No existing handlers
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            mock_handler = Mock()
            mock_logging.StreamHandler.return_value = mock_handler

            mock_formatter = Mock()
            mock_logging.Formatter.return_value = mock_formatter

            configure_logging()

            # Should create new handler and formatter
            mock_logging.StreamHandler.assert_called_once()
            mock_logging.Formatter.assert_called_once()
            mock_handler.setLevel.assert_called_with(logging.INFO)
            mock_handler.setFormatter.assert_called_with(mock_formatter)
            mock_logger.addHandler.assert_called_with(mock_handler)

    def test_configure_logging_none_level(self):
        """Test logging configuration with None level."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            configure_logging(None)

            # Should use default INFO level
            mock_logger.setLevel.assert_called_with(logging.INFO)

    def test_configure_logging_formatter_format(self):
        """Test that the formatter is created with the correct format."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logger.handlers = []
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            mock_handler = Mock()
            mock_logging.StreamHandler.return_value = mock_handler

            mock_formatter = Mock()
            mock_logging.Formatter.return_value = mock_formatter

            configure_logging()

            # Should create formatter with the correct format string
            expected_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            mock_logging.Formatter.assert_called_with(expected_format)

    def test_configure_logging_handler_level(self):
        """Test that the handler level is set correctly."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logger.handlers = []
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            mock_handler = Mock()
            mock_logging.StreamHandler.return_value = mock_handler

            mock_formatter = Mock()
            mock_logging.Formatter.return_value = mock_formatter

            configure_logging(logging.DEBUG)

            # Handler level should match the configured level
            mock_handler.setLevel.assert_called_with(logging.DEBUG)

    def test_configure_logging_logger_name(self):
        """Test that the correct logger name is used."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO

            configure_logging()

            # Should get logger with the correct name
            mock_logging.getLogger.assert_called_with("athena_client")

    def test_configure_logging_multiple_calls(self):
        """Test that multiple calls to configure_logging work correctly."""
        with patch("athena_client.utils.logging") as mock_logging:
            mock_logger = Mock()
            mock_logger.handlers = []
            mock_logging.getLogger.return_value = mock_logger
            mock_logging.INFO = logging.INFO
            mock_logging.DEBUG = logging.DEBUG

            mock_handler = Mock()
            mock_logging.StreamHandler.return_value = mock_handler

            mock_formatter = Mock()
            mock_logging.Formatter.return_value = mock_formatter

            # First call
            configure_logging(logging.INFO)

            # Second call with different level
            configure_logging(logging.DEBUG)

            # Should set level to DEBUG on second call
            assert mock_logger.setLevel.call_count == 2
            mock_logger.setLevel.assert_called_with(logging.DEBUG)

    def test_configure_logging_integration(self):
        """Test logging configuration integration with real logging."""
        # Test with real logging module
        original_handlers = logging.getLogger("athena_client").handlers[:]

        try:
            # Configure logging
            configure_logging(logging.DEBUG)

            # Get the logger
            logger = logging.getLogger("athena_client")

            # Check that level is set correctly
            assert logger.level == logging.DEBUG

            # Check that handlers were added
            assert len(logger.handlers) > 0

            # Check that handler level is set correctly
            for handler in logger.handlers:
                if isinstance(handler, logging.StreamHandler):
                    assert handler.level == logging.DEBUG
                    assert handler.formatter is not None

        finally:
            # Clean up - remove handlers we added
            logger = logging.getLogger("athena_client")
            for handler in logger.handlers[:]:
                if handler not in original_handlers:
                    logger.removeHandler(handler)

```

## Folder: tests/property

### File: `athena_client/tests/property/test_query_builder.py`
<a name="athena_client-tests-property-test_query_builderpy"></a>
```python
from hypothesis import given
from hypothesis import strategies as st

from athena_client.query import Q


@given(text=st.text(min_size=1, max_size=40))
def test_phrase_builder_roundtrip(text):
    """Generated boosts should always include the raw phrase."""
    boosts = Q.phrase(text).to_boosts()
    assert text in boosts["filter"]["query_string"]["query"]


@given(prefix=st.text(min_size=1, max_size=10))
def test_wildcard_always_star(prefix):
    """Wildcard helper must append '*' if caller forgot."""
    expr = Q.wildcard(prefix)
    assert expr.value.endswith("*")

```

## Folder: tests/benchmarks

### File: `athena_client/tests/benchmarks/test_orjson.py`
<a name="athena_client-tests-benchmarks-test_orjsonpy"></a>
```python
import json

import pytest

from athena_client.models import Concept, ConceptSearchResponse, ConceptType

SAMPLE = ConceptSearchResponse(
    content=[
        Concept(
            id=i,
            name=f"Name {i}",
            domain="Domain",
            vocabulary="Vocab",
            className="Class",
            code=str(i),
            standardConcept=ConceptType.STANDARD,
            invalidReason=None,
            score=1.0,
        )
        for i in range(1000)
    ],
    pageable={
        "sort": {"sorted": True, "unsorted": False, "empty": False},
        "pageSize": 20,
        "pageNumber": 0,
        "offset": 0,
        "paged": True,
        "unpaged": False,
    },
    totalElements=1000,
    last=True,
    totalPages=1,
    first=True,
    sort={"sorted": True, "unsorted": False, "empty": False},
    size=1000,
    number=0,
    numberOfElements=1000,
    empty=False,
)


@pytest.mark.benchmark(group="json")
def test_orjson_dump(benchmark):
    benchmark(SAMPLE.model_dump_json)


@pytest.mark.benchmark(group="json")
def test_stdlib_dump(benchmark):
    benchmark(json.dumps, SAMPLE.model_dump())

```

## Folder: tests/db

### File: `athena_client/tests/db/__init__.py`
<a name="athena_client-tests-db-__init__py"></a>
```python

```

### File: `athena_client/tests/db/test_sqlalchemy_connector.py`
<a name="athena_client-tests-db-test_sqlalchemy_connectorpy"></a>
```python
from unittest.mock import Mock, patch

from athena_client.db.sqlalchemy_connector import SQLAlchemyConnector


class TestSQLAlchemyConnector:
    def test_validate_concepts_empty(self):
        engine = Mock()
        connector = SQLAlchemyConnector(engine)

        assert connector.validate_concepts([]) == []
        engine.connect.assert_not_called()

    def test_validate_concepts_all_match(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(1,), (2,)]

        connector = SQLAlchemyConnector(engine)
        result = connector.validate_concepts([1, 2])

        assert result == [1, 2]
        connection.execute.assert_called_once()

    def test_validate_concepts_partial_match(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(2,)]

        connector = SQLAlchemyConnector(engine)
        result = connector.validate_concepts([1, 2])

        assert result == [2]

    def test_validate_concepts_none_match(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = []

        connector = SQLAlchemyConnector(engine)
        result = connector.validate_concepts([1, 2])

        assert result == []

    def test_from_connection_string(self):
        with patch(
            "athena_client.db.sqlalchemy_connector.create_engine"
        ) as mock_create:
            engine = Mock()
            mock_create.return_value = engine
            connector = SQLAlchemyConnector.from_connection_string("sqlite:///:memory:")
            assert connector._engine is engine
            mock_create.assert_called_once_with("sqlite:///:memory:")

    def test_get_descendants_success(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(1,), (2,), (3,)]

        connector = SQLAlchemyConnector(engine)
        result = connector.get_descendants([1])

        assert set(result) == {2, 3}

    def test_get_descendants_no_descendants(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(1,)]

        connector = SQLAlchemyConnector(engine)
        result = connector.get_descendants([1])

        assert result == []

    def test_get_descendants_empty_input(self):
        engine = Mock()
        connector = SQLAlchemyConnector(engine)

        assert connector.get_descendants([]) == []
        engine.connect.assert_not_called()

    def test_get_descendants_invalid_id(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = []

        connector = SQLAlchemyConnector(engine)
        result = connector.get_descendants([999])

        assert result == []

    def test_get_standard_mapping_success(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(10, 100, "S")]

        connector = SQLAlchemyConnector(engine)
        result = connector.get_standard_mapping([10])

        assert result == {10: 100}

    def test_get_standard_mapping_multiple(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(10, 100, "S"), (11, 101, "S")]

        connector = SQLAlchemyConnector(engine)
        result = connector.get_standard_mapping([10, 11, 12])

        assert result == {10: 100, 11: 101}

    def test_get_standard_mapping_no_mapping(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = []

        connector = SQLAlchemyConnector(engine)
        result = connector.get_standard_mapping([10])

        assert result == {}

    def test_get_standard_mapping_maps_to_non_standard(self):
        engine = Mock()
        connection = Mock()
        engine.connect.return_value.__enter__ = Mock(return_value=connection)
        engine.connect.return_value.__exit__ = Mock(return_value=None)
        connection.execute.return_value = [(10, 100, "C")]

        connector = SQLAlchemyConnector(engine)
        result = connector.get_standard_mapping([10])

        assert result == {}

```

## Folder: .hypothesis

## Folder: .hypothesis/unicode_data

## Folder: .hypothesis/unicode_data/15.1.0

## Folder: .hypothesis/unicode_data/13.0.0

## Folder: .hypothesis/constants

## Folder: .benchmarks

## Folder: .mypy_cache

## Folder: .mypy_cache/3.9

## Folder: .mypy_cache/3.9/orjson

## Folder: .mypy_cache/3.9/backoff

## Folder: .mypy_cache/3.9/mdurl

## Folder: .mypy_cache/3.9/zoneinfo

## Folder: .mypy_cache/3.9/ctypes

## Folder: .mypy_cache/3.9/httpcore

## Folder: .mypy_cache/3.9/httpcore/_backends

## Folder: .mypy_cache/3.9/httpcore/_async

## Folder: .mypy_cache/3.9/httpcore/_sync

## Folder: .mypy_cache/3.9/unittest

## Folder: .mypy_cache/3.9/h11

## Folder: .mypy_cache/3.9/dotenv

## Folder: .mypy_cache/3.9/annotated_types

## Folder: .mypy_cache/3.9/attrs

## Folder: .mypy_cache/3.9/cryptography

## Folder: .mypy_cache/3.9/cryptography/hazmat

## Folder: .mypy_cache/3.9/cryptography/hazmat/decrepit

## Folder: .mypy_cache/3.9/cryptography/hazmat/decrepit/ciphers

## Folder: .mypy_cache/3.9/cryptography/hazmat/backends

## Folder: .mypy_cache/3.9/cryptography/hazmat/backends/openssl

## Folder: .mypy_cache/3.9/cryptography/hazmat/primitives

## Folder: .mypy_cache/3.9/cryptography/hazmat/primitives/serialization

## Folder: .mypy_cache/3.9/cryptography/hazmat/primitives/ciphers

## Folder: .mypy_cache/3.9/cryptography/hazmat/primitives/asymmetric

## Folder: .mypy_cache/3.9/cryptography/hazmat/bindings

## Folder: .mypy_cache/3.9/cryptography/hazmat/bindings/_rust

## Folder: .mypy_cache/3.9/cryptography/hazmat/bindings/_rust/openssl

## Folder: .mypy_cache/3.9/cryptography/hazmat/bindings/openssl

## Folder: .mypy_cache/3.9/athena_client

## Folder: .mypy_cache/3.9/athena_client/utils

## Folder: .mypy_cache/3.9/athena_client/models

## Folder: .mypy_cache/3.9/athena_client/db

## Folder: .mypy_cache/3.9/multiprocessing

## Folder: .mypy_cache/3.9/_typeshed

## Folder: .mypy_cache/3.9/urllib

## Folder: .mypy_cache/3.9/markdown_it

## Folder: .mypy_cache/3.9/markdown_it/rules_block

## Folder: .mypy_cache/3.9/markdown_it/rules_core

## Folder: .mypy_cache/3.9/markdown_it/common

## Folder: .mypy_cache/3.9/markdown_it/rules_inline

## Folder: .mypy_cache/3.9/markdown_it/presets

## Folder: .mypy_cache/3.9/markdown_it/helpers

## Folder: .mypy_cache/3.9/zipfile

## Folder: .mypy_cache/3.9/idna

## Folder: .mypy_cache/3.9/click

## Folder: .mypy_cache/3.9/html

## Folder: .mypy_cache/3.9/sqlalchemy

## Folder: .mypy_cache/3.9/sqlalchemy/connectors

## Folder: .mypy_cache/3.9/sqlalchemy/databases

## Folder: .mypy_cache/3.9/sqlalchemy/util

## Folder: .mypy_cache/3.9/sqlalchemy/ext

## Folder: .mypy_cache/3.9/sqlalchemy/ext/declarative

## Folder: .mypy_cache/3.9/sqlalchemy/dialects

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/sybase

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/postgresql

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/oracle

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/sqlite

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/mysql

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/mssql

## Folder: .mypy_cache/3.9/sqlalchemy/dialects/firebird

## Folder: .mypy_cache/3.9/sqlalchemy/orm

## Folder: .mypy_cache/3.9/sqlalchemy/engine

## Folder: .mypy_cache/3.9/sqlalchemy/event

## Folder: .mypy_cache/3.9/sqlalchemy/sql

## Folder: .mypy_cache/3.9/numpy

## Folder: .mypy_cache/3.9/numpy/strings

## Folder: .mypy_cache/3.9/numpy/char

## Folder: .mypy_cache/3.9/numpy/core

## Folder: .mypy_cache/3.9/numpy/linalg

## Folder: .mypy_cache/3.9/numpy/ctypeslib

## Folder: .mypy_cache/3.9/numpy/ma

## Folder: .mypy_cache/3.9/numpy/_core

## Folder: .mypy_cache/3.9/numpy/_typing

## Folder: .mypy_cache/3.9/numpy/rec

## Folder: .mypy_cache/3.9/numpy/typing

## Folder: .mypy_cache/3.9/numpy/f2py

## Folder: .mypy_cache/3.9/numpy/testing

## Folder: .mypy_cache/3.9/numpy/testing/_private

## Folder: .mypy_cache/3.9/numpy/lib

## Folder: .mypy_cache/3.9/numpy/fft

## Folder: .mypy_cache/3.9/numpy/random

## Folder: .mypy_cache/3.9/numpy/matrixlib

## Folder: .mypy_cache/3.9/numpy/polynomial

## Folder: .mypy_cache/3.9/requests

## Folder: .mypy_cache/3.9/anyio

## Folder: .mypy_cache/3.9/anyio/abc

## Folder: .mypy_cache/3.9/anyio/_core

## Folder: .mypy_cache/3.9/anyio/streams

## Folder: .mypy_cache/3.9/httpx

## Folder: .mypy_cache/3.9/httpx/_transports

## Folder: .mypy_cache/3.9/sys

## Folder: .mypy_cache/3.9/certifi

## Folder: .mypy_cache/3.9/json

## Folder: .mypy_cache/3.9/sniffio

## Folder: .mypy_cache/3.9/attr

## Folder: .mypy_cache/3.9/http

## Folder: .mypy_cache/3.9/sqlite3

## Folder: .mypy_cache/3.9/concurrent

## Folder: .mypy_cache/3.9/concurrent/futures

## Folder: .mypy_cache/3.9/rich

## Folder: .mypy_cache/3.9/yaml

## Folder: .mypy_cache/3.9/os

## Folder: .mypy_cache/3.9/pydantic_settings

## Folder: .mypy_cache/3.9/pydantic_settings/sources

## Folder: .mypy_cache/3.9/pydantic_settings/sources/providers

## Folder: .mypy_cache/3.9/urllib3

## Folder: .mypy_cache/3.9/urllib3/util

## Folder: .mypy_cache/3.9/urllib3/contrib

## Folder: .mypy_cache/3.9/urllib3/http2

## Folder: .mypy_cache/3.9/importlib

## Folder: .mypy_cache/3.9/importlib/resources

## Folder: .mypy_cache/3.9/importlib/metadata

## Folder: .mypy_cache/3.9/pydantic

## Folder: .mypy_cache/3.9/pydantic/v1

## Folder: .mypy_cache/3.9/pydantic/_internal

## Folder: .mypy_cache/3.9/pydantic/plugin

## Folder: .mypy_cache/3.9/pydantic/deprecated

## Folder: .mypy_cache/3.9/collections

## Folder: .mypy_cache/3.9/typing_inspection

## Folder: .mypy_cache/3.9/zstandard

## Folder: .mypy_cache/3.9/asyncio

## Folder: .mypy_cache/3.9/logging

## Folder: .mypy_cache/3.9/email

## Folder: .mypy_cache/3.9/pydantic_core

## Folder: .mypy_cache/3.9/pandas

## Folder: .mypy_cache/3.9/pandas/core

## Folder: .mypy_cache/3.9/pandas/core/reshape

## Folder: .mypy_cache/3.9/pandas/core/tools

## Folder: .mypy_cache/3.9/pandas/core/util

## Folder: .mypy_cache/3.9/pandas/core/interchange

## Folder: .mypy_cache/3.9/pandas/core/dtypes

## Folder: .mypy_cache/3.9/pandas/core/groupby

## Folder: .mypy_cache/3.9/pandas/core/computation

## Folder: .mypy_cache/3.9/pandas/core/window

## Folder: .mypy_cache/3.9/pandas/core/arrays

## Folder: .mypy_cache/3.9/pandas/core/arrays/arrow

## Folder: .mypy_cache/3.9/pandas/core/arrays/sparse

## Folder: .mypy_cache/3.9/pandas/core/indexes

## Folder: .mypy_cache/3.9/pandas/util

## Folder: .mypy_cache/3.9/pandas/io

## Folder: .mypy_cache/3.9/pandas/io/parsers

## Folder: .mypy_cache/3.9/pandas/io/formats

## Folder: .mypy_cache/3.9/pandas/io/excel

## Folder: .mypy_cache/3.9/pandas/io/json

## Folder: .mypy_cache/3.9/pandas/io/sas

## Folder: .mypy_cache/3.9/pandas/tseries

## Folder: .mypy_cache/3.9/pandas/_testing

## Folder: .mypy_cache/3.9/pandas/_libs

## Folder: .mypy_cache/3.9/pandas/_libs/tslibs

## Folder: .mypy_cache/3.9/pandas/plotting

## Folder: .mypy_cache/3.9/pandas/arrays

## Folder: .mypy_cache/3.9/pandas/api

## Folder: .mypy_cache/3.9/pandas/api/indexers

## Folder: .mypy_cache/3.9/pandas/api/types

## Folder: .mypy_cache/3.9/pandas/api/interchange

## Folder: .mypy_cache/3.9/pandas/api/extensions

## Folder: .mypy_cache/3.9/pandas/api/typing

## Folder: .mypy_cache/3.9/pandas/errors

## Folder: .mypy_cache/3.9/pandas/_config

## Folder: .mypy_cache/3.9/dateutil

## Folder: examples

### File: `athena_client/examples/advanced_retry_demo.py`
<a name="athena_client-examples-advanced_retry_demopy"></a>
```python
#!/usr/bin/env python3
"""
Advanced retry configuration and detailed error reporting demo.

This demo showcases:
- Fine-grained retry control
- Detailed retry error reporting
- Developer configuration options
- Request throttling control
"""
import sys
import os
import time

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.exceptions import RetryFailedError, NetworkError, APIError


def demo_retry_configuration():
    """Demonstrate advanced retry configuration options."""
    print("\nüîß ADVANCED RETRY CONFIGURATION")
    print("=" * 50)
    
    print("\n1. Client-Level Configuration:")
    print("-" * 35)
    athena = Athena(
        max_retries=5,
        retry_delay=1.0,
        enable_throttling=True,
        throttle_delay_range=(0.2, 0.5),
        timeout=30
    )
    print(f"‚úÖ Max retries: {athena.max_retries}")
    print(f"‚úÖ Retry delay: {athena.retry_delay} seconds")
    print(f"‚úÖ Throttling: {'enabled' if athena.enable_throttling else 'disabled'}")
    print(f"‚úÖ Throttle range: {athena.throttle_delay_range} seconds")
    print(f"‚úÖ Timeout: {athena.http.timeout} seconds")
    
    print("\n2. Call-Level Override:")
    print("-" * 35)
    try:
        # Override retry settings for this specific call
        results = athena.search(
            "aspirin",
            max_retries=2,      # Override max retries
            retry_delay=0.5     # Override retry delay
        )
        print(f"‚úÖ Search successful with custom retry settings")
    except Exception as e:
        print(f"‚ùå Search failed: {e}")


def demo_detailed_error_reporting():
    """Demonstrate detailed retry error reporting."""
    print("\nüìä DETAILED ERROR REPORTING")
    print("=" * 50)
    
    print("\n1. Normal Error (No Retry):")
    print("-" * 30)
    athena = Athena(max_retries=0)  # No retries
    try:
        results = athena.search("aspirin")
        print("‚úÖ Search successful")
    except Exception as e:
        print(f"‚ùå Error: {type(e).__name__}")
        print(f"   Message: {e}")
    
    print("\n2. Retry Error with Details:")
    print("-" * 30)
    # This would normally show retry behavior, but we'll simulate it
    print("   (In a real scenario with network issues, you would see:)")
    print("   ‚úÖ RetryFailedError with detailed information:")
    print("   ‚úÖ Maximum attempts made")
    print("   ‚úÖ Last error details")
    print("   ‚úÖ Complete retry history")
    print("   ‚úÖ Specific troubleshooting suggestions")


def demo_retry_control_scenarios():
    """Demonstrate different retry control scenarios."""
    print("\nüéõÔ∏è RETRY CONTROL SCENARIOS")
    print("=" * 50)
    
    print("\n1. Aggressive Retry (High Volume):")
    print("-" * 35)
    athena_aggressive = Athena(
        max_retries=10,
        retry_delay=0.1,
        enable_throttling=False
    )
    print(f"‚úÖ Max retries: {athena_aggressive.max_retries}")
    print(f"‚úÖ Retry delay: {athena_aggressive.retry_delay} seconds")
    print(f"‚úÖ Throttling: {'enabled' if athena_aggressive.enable_throttling else 'disabled'}")
    print("   Use case: High-volume processing where speed is critical")
    
    print("\n2. Conservative Retry (Production):")
    print("-" * 35)
    athena_conservative = Athena(
        max_retries=3,
        retry_delay=2.0,
        enable_throttling=True,
        throttle_delay_range=(0.3, 0.8)
    )
    print(f"‚úÖ Max retries: {athena_conservative.max_retries}")
    print(f"‚úÖ Retry delay: {athena_conservative.retry_delay} seconds")
    print(f"‚úÖ Throttling: {'enabled' if athena_conservative.enable_throttling else 'disabled'}")
    print("   Use case: Production systems where reliability is critical")
    
    print("\n3. Development Retry (Fast Feedback):")
    print("-" * 35)
    athena_dev = Athena(
        max_retries=1,
        retry_delay=0.5,
        enable_throttling=False
    )
    print(f"‚úÖ Max retries: {athena_dev.max_retries}")
    print(f"‚úÖ Retry delay: {athena_dev.retry_delay} seconds")
    print(f"‚úÖ Throttling: {'enabled' if athena_dev.enable_throttling else 'disabled'}")
    print("   Use case: Development where fast feedback is important")


def demo_error_analysis():
    """Demonstrate how to analyze retry errors."""
    print("\nüîç ERROR ANALYSIS")
    print("=" * 50)
    
    print("\n1. RetryFailedError Analysis:")
    print("-" * 30)
    print("```python")
    print("try:")
    print("    results = athena.search('aspirin')")
    print("except RetryFailedError as e:")
    print("    print(f'Max attempts: {e.max_attempts}')")
    print("    print(f'Attempts made: {len(e.retry_history) + 1}')")
    print("    print(f'Last error: {e.last_error}')")
    print("    print(f'Retry history: {e.retry_history}')")
    print("    # Error message includes all this information automatically")
    print("```")
    
    print("\n2. Error Type Analysis:")
    print("-" * 30)
    print("```python")
    print("try:")
    print("    results = athena.search('aspirin')")
    print("except RetryFailedError as e:")
    print("    if isinstance(e.last_error, NetworkError):")
    print("        print('Network connectivity issue')")
    print("    elif isinstance(e.last_error, TimeoutError):")
    print("        print('Server response timeout')")
    print("    elif isinstance(e.last_error, APIError):")
    print("        print('API-specific error')")
    print("```")


def demo_best_practices():
    """Demonstrate best practices for retry configuration."""
    print("\nüéØ BEST PRACTICES")
    print("=" * 50)
    
    print("\n1. Production Configuration:")
    print("-" * 30)
    print("‚úÖ Use 3-5 max retries for production")
    print("‚úÖ Enable throttling to be respectful to the server")
    print("‚úÖ Use reasonable retry delays (1-3 seconds)")
    print("‚úÖ Monitor retry patterns and adjust accordingly")
    print("‚úÖ Log retry failures for analysis")
    
    print("\n2. Development Configuration:")
    print("-" * 30)
    print("‚úÖ Use 1-2 max retries for faster feedback")
    print("‚úÖ Disable throttling for testing if needed")
    print("‚úÖ Use shorter retry delays (0.5-1 second)")
    print("‚úÖ Enable debug logging for troubleshooting")
    
    print("\n3. Error Handling:")
    print("-" * 30)
    print("‚úÖ Always catch RetryFailedError for retry failures")
    print("‚úÖ Analyze retry history to understand failure patterns")
    print("‚úÖ Implement circuit breakers for persistent failures")
    print("‚úÖ Provide user-friendly error messages")


def main():
    """Run the advanced retry demo."""
    print("üöÄ ATHENA CLIENT - ADVANCED RETRY DEMO")
    print("=" * 60)
    print("This demo showcases advanced retry configuration and")
    print("detailed error reporting features.")
    print("=" * 60)
    
    demo_retry_configuration()
    demo_detailed_error_reporting()
    demo_retry_control_scenarios()
    demo_error_analysis()
    demo_best_practices()
    
    print("\n" + "=" * 60)
    print("üéâ ADVANCED RETRY DEMO COMPLETE")
    print("=" * 60)
    print("‚úÖ Advanced retry configuration demonstrated")
    print("‚úÖ Detailed error reporting features shown")
    print("‚úÖ Retry control scenarios explained")
    print("‚úÖ Best practices outlined")
    print("\nThe athena-client now provides enterprise-grade retry")
    print("control with detailed error reporting!")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/bigquery_concept_set_demo.py`
<a name="athena_client-examples-bigquery_concept_set_demopy"></a>
```python
#!/usr/bin/env python3
"""
Example: Generating a Validated Concept Set with Google BigQuery

This script demonstrates how to use the athena-client to generate a concept
set by connecting to an OMOP CDM hosted in Google BigQuery.

Prerequisites:
1.  Install the necessary client libraries:
    pip install "athena-client[bigquery]"

2.  Authenticate with Google Cloud. The simplest way for local development
    is to use the gcloud CLI:
    gcloud auth application-default login

    This command will open a browser window for you to log in and will store
    your credentials locally where the client library can find them.

3.  Ensure your Google Cloud user or service account has permissions to read
    the BigQuery dataset containing your OMOP tables (e.g., "BigQuery Data Viewer").

Usage:
    python examples/bigquery_concept_set_demo.py
"""
import asyncio
import os
import sys
import logging

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena

# --- Configuration for Your BigQuery OMOP CDM ---
# Replace these with your actual Google Cloud Project ID and BigQuery dataset name.
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "som-rit-starr-training")
BIGQUERY_DATASET = os.environ.get("BIGQUERY_DATASET", "starr_omop_cdm5_deid_1pcent_lite_20191024")
# -------------------------------------------------

def create_bigquery_connection_string() -> str:
    """
    Creates the SQLAlchemy connection string for Google BigQuery.
    """
    if GCP_PROJECT_ID == "your-gcp-project-id" or BIGQUERY_DATASET == "your_omop_dataset":
        print("‚ö†Ô∏è  WARNING: Please update GCP_PROJECT_ID and BIGQUERY_DATASET variables in this script.")
        print("           You can also set them as environment variables.")
        sys.exit(1)

    # The format for a BigQuery connection string is "bigquery://<project_id>/<dataset>"
    return f"bigquery://{GCP_PROJECT_ID}/{BIGQUERY_DATASET}"


async def main():
    """
    Main function to connect to BigQuery and generate a concept set.
    """
    # Suppress noisy network error logs from BigQuery/Google libraries
    for noisy_logger in [
        "google.auth.transport.requests",
        "google.auth._default",
        "google.resumable_media",
        "google.api_core.retry",
        "urllib3.connectionpool",
        "requests.packages.urllib3.connectionpool",
        "sqlalchemy.engine.Engine",
        "pybigquery.sqlalchemy_bigquery",
        "sqlalchemy_bigquery",
    ]:
        logging.getLogger(noisy_logger).setLevel(logging.ERROR)

    print("üöÄ Athena Client with Google BigQuery Demo")
    print("=" * 50)

    # 1. Create the BigQuery connection string
    db_connection_string = create_bigquery_connection_string()
    print(f"Connecting to BigQuery dataset: {BIGQUERY_DATASET} in project {GCP_PROJECT_ID}")

    # 2. Initialize the Athena client
    athena = Athena()
    
    # 3. Define the search query
    search_query = "Diabetes Mellitus"
    print(f"\nüîç Generating concept set for: '{search_query}'")

    try:
        # 4. Generate the concept set
        # The client uses the connection string to talk to your BigQuery OMOP instance.
        concept_set = await athena.generate_concept_set(
            query=search_query,
            db_connection_string=db_connection_string
        )

        # 5. Print the results
        print("\n" + "="*50)
        print("‚úÖ Concept Set Generation Complete!")
        print("="*50)

        metadata = concept_set.get("metadata", {})
        if metadata.get("status") == "SUCCESS":
            print(f"Status: {metadata['status']} ‚ú®")
            print(f"Strategy Used: {metadata['strategy_used']}")
            warnings = metadata.get('warnings', [])
            if warnings:
                print("\nWarnings:")
                for warning in warnings:
                    print(f"  - {warning}")
            print(f"\nFound {len(concept_set.get('concept_ids', []))} total concepts (including descendants).")
            seed_concepts = metadata.get('seed_concepts', [])
            if seed_concepts:
                print(f"The set was built from {len(seed_concepts)} validated standard concept(s):")
                for concept_id in seed_concepts:
                    print(f"  - Concept ID: {concept_id}")
        else:
            print(f"Status: {metadata.get('status', 'FAILURE')} ‚ùå")
            # Always print the full reason, even if it's not the default
            print(f"Reason: {metadata.get('reason', 'An unknown error occurred.')}")
            suggestions = metadata.get('suggestions', [])
            if suggestions:
                print("\nSuggestions:")
                for suggestion in suggestions:
                    if suggestion:
                        print(f"  - {suggestion}")

    except Exception as e:
        print(f"\n‚ùå An unexpected error occurred during the process: {e}")
        print("   Please check the following:")
        print("   - Have you authenticated with Google Cloud? (run 'gcloud auth application-default login')")
        print("   - Is your GCP_PROJECT_ID and BIGQUERY_DATASET correct?")
        print("   - Does your user account have permissions to read the BigQuery dataset?")

if __name__ == "__main__":
    # Ensure you have the required dependencies installed and supported Python version
    import sys
    if sys.version_info >= (3, 10):
        print("‚ùå BigQuery support requires Python 3.9 or lower due to upstream dependency limitations.")
        print("   Please use a Python 3.9 environment for BigQuery support.")
        sys.exit(1)
    try:
        import sqlalchemy_bigquery
    except ImportError:
        print("‚ùå Missing BigQuery dependencies.")
        print('   Please install them with: pip install "athena-client[bigquery]"')
        sys.exit(1)
    
    asyncio.run(main())

```

### File: `athena_client/examples/concept_exploration_demo.py`
<a name="athena_client-examples-concept_exploration_demopy"></a>
```python
#!/usr/bin/env python3
"""
Concept Exploration Demo

This script demonstrates the ConceptExplorer with:
- Async/await support for improved performance
- BFS-based exploration algorithm
- Batch processing of API calls
- Configurable exploration parameters
- Enhanced error handling

Usage:
    python concept_exploration_demo.py
"""

import asyncio
import logging
import time
from typing import Dict, Any

# Import the athena client
try:
    from athena_client import AthenaClient, create_concept_explorer
    from athena_client.async_client import AthenaAsyncClient
except ImportError:
    print("Please install athena-client: pip install athena-client")
    exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def demo_basic_exploration():
    """Demonstrate basic concept exploration with async client."""
    print("\n" + "="*60)
    print("DEMO 1: Basic Concept Exploration (Async Client)")
    print("="*60)
    
    # Initialize async client
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    query = "migraine"
    print(f"Exploring concepts for: '{query}'")
    
    start_time = time.time()
    
    try:
        # Perform async exploration with limits
        results = await explorer.find_standard_concepts(
            query=query,
            max_exploration_depth=1,  # Reduced depth
            initial_seed_limit=3,     # Reduced seed limit
            include_synonyms=True,
            include_relationships=True,
            max_total_concepts=20,    # Limit total concepts
            max_api_calls=15,         # Limit API calls
            max_time_seconds=20       # Limit time
        )
        
        elapsed_time = time.time() - start_time
        
        # Display results
        print(f"\nExploration completed in {elapsed_time:.2f} seconds")
        print(f"Direct matches: {len(results['direct_matches'])}")
        print(f"Synonym matches: {len(results['synonym_matches'])}")
        print(f"Relationship matches: {len(results['relationship_matches'])}")
        print(f"Cross references: {len(results['cross_references'])}")
        
        # Show exploration statistics
        if 'exploration_stats' in results:
            stats = results['exploration_stats']
            print(f"\nüìä Exploration Statistics:")
            print(f"  Total concepts found: {stats['total_concepts_found']}")
            print(f"  API calls made: {stats['api_calls_made']}")
            print(f"  Time elapsed: {stats['time_elapsed_seconds']:.2f}s")
            print(f"  Limits reached:")
            for limit_type, reached in stats['limits_reached'].items():
                status = "‚úì" if reached else "‚úó"
                print(f"    {status} {limit_type}")
        
        # Show some direct matches
        if results['direct_matches']:
            print("\nTop direct matches:")
            for i, concept in enumerate(results['direct_matches'][:3], 1):
                print(f"  {i}. {concept.name} ({concept.vocabulary}) - {concept.standardConcept}")
        
        # Show some synonym matches
        if results['synonym_matches']:
            print("\nTop synonym matches:")
            for i, concept in enumerate(results['synonym_matches'][:3], 1):
                print(f"  {i}. {concept.name} ({concept.vocabulary}) - {concept.standardConcept}")
        
        return results
        
    except Exception as e:
        logger.error(f"Exploration failed: {e}")
        return None


async def demo_mapping_with_confidence():
    """Demonstrate concept mapping with confidence scores."""
    print("\n" + "="*60)
    print("DEMO 2: Concept Mapping with Confidence Scores")
    print("="*60)
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    query = "diabetes mellitus"
    print(f"Mapping query: '{query}' to standard concepts")
    
    try:
        # Map to standard concepts with confidence scores and limits
        mappings = await explorer.map_to_standard_concepts(
            query=query,
            target_vocabularies=["SNOMED", "RxNorm"],
            confidence_threshold=0.3
        )
        
        print(f"\nFound {len(mappings)} mappings above confidence threshold:")
        
        for i, mapping in enumerate(mappings[:5], 1):
            concept = mapping['concept']
            confidence = mapping['confidence']
            path = mapping['exploration_path']
            category = mapping['source_category']
            
            print(f"\n  {i}. {concept.name}")
            print(f"     Vocabulary: {concept.vocabulary}")
            print(f"     Confidence: {confidence:.3f}")
            print(f"     Path: {path}")
            print(f"     Category: {category}")
        
        return mappings
        
    except Exception as e:
        logger.error(f"Mapping failed: {e}")
        return None


async def demo_performance_comparison():
    """Compare performance between different exploration parameters."""
    print("\n" + "="*60)
    print("DEMO 3: Performance Comparison")
    print("="*60)
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    query = "hypertension"
    
    # Test different initial_seed_limit values with strict limits
    seed_limits = [2, 3, 5]
    
    for seed_limit in seed_limits:
        print(f"\nTesting with initial_seed_limit={seed_limit}")
        
        start_time = time.time()
        
        try:
            results = await explorer.find_standard_concepts(
                query=query,
                max_exploration_depth=1,  # Keep depth low for comparison
                initial_seed_limit=seed_limit,
                include_synonyms=True,
                include_relationships=True,
                max_total_concepts=15,    # Strict limit
                max_api_calls=10,         # Strict limit
                max_time_seconds=15       # Strict limit
            )
            
            elapsed_time = time.time() - start_time
            total_concepts = (
                len(results['direct_matches']) +
                len(results['synonym_matches']) +
                len(results['relationship_matches'])
            )
            
            print(f"  Time: {elapsed_time:.2f}s")
            print(f"  Total concepts found: {total_concepts}")
            print(f"  Direct matches: {len(results['direct_matches'])}")
            print(f"  Synonym matches: {len(results['synonym_matches'])}")
            print(f"  Relationship matches: {len(results['relationship_matches'])}")
            
            # Show exploration stats
            if 'exploration_stats' in results:
                stats = results['exploration_stats']
                print(f"  API calls: {stats['api_calls_made']}")
                print(f"  Limits hit: {sum(stats['limits_reached'].values())}")
            
        except Exception as e:
            logger.error(f"Test failed for seed_limit={seed_limit}: {e}")


async def demo_error_handling():
    """Demonstrate error handling in the new implementation."""
    print("\n" + "="*60)
    print("DEMO 4: Error Handling")
    print("="*60)
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # Test with invalid parameters
    print("Testing parameter validation:")
    
    try:
        await explorer.find_standard_concepts(
            query="test",
            max_exploration_depth=-1  # Invalid: negative depth
        )
    except ValueError as e:
        print(f"  ‚úì Caught invalid max_exploration_depth: {e}")
    
    try:
        await explorer.find_standard_concepts(
            query="test",
            initial_seed_limit=0  # Invalid: zero seed limit
        )
    except ValueError as e:
        print(f"  ‚úì Caught invalid initial_seed_limit: {e}")
    
    try:
        await explorer.find_standard_concepts(
            query="test",
            max_total_concepts=0  # Invalid: zero concepts limit
        )
    except ValueError as e:
        print(f"  ‚úì Caught invalid max_total_concepts: {e}")
    
    # Test with non-existent query
    print("\nTesting with non-existent query:")
    try:
        results = await explorer.find_standard_concepts(
            query="this_query_should_not_exist_12345",
            max_exploration_depth=1,
            initial_seed_limit=3,
            max_total_concepts=10,
            max_api_calls=5,
            max_time_seconds=10
        )
        
        print(f"  ‚úì Handled empty results gracefully")
        print(f"  Direct matches: {len(results['direct_matches'])}")
        
    except Exception as e:
        logger.error(f"Unexpected error: {e}")


async def demo_alternative_queries():
    """Demonstrate alternative query suggestions."""
    print("\n" + "="*60)
    print("DEMO 5: Alternative Query Suggestions")
    print("="*60)
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    queries = ["migraine", "diabetes", "hypertension"]
    
    for query in queries:
        print(f"\nSuggestions for '{query}':")
        try:
            suggestions = await explorer.suggest_alternative_queries(
                query=query,
                max_suggestions=5
            )
            
            for i, suggestion in enumerate(suggestions, 1):
                print(f"  {i}. {suggestion}")
                
        except Exception as e:
            logger.error(f"Failed to get suggestions for '{query}': {e}")


async def demo_concept_hierarchy():
    """Demonstrate concept hierarchy exploration."""
    print("\n" + "="*60)
    print("DEMO 6: Concept Hierarchy")
    print("="*60)
    
    client = AthenaAsyncClient()
    explorer = create_concept_explorer(client)
    
    # First, find a concept to explore
    try:
        results = await explorer.find_standard_concepts(
            query="migraine",
            max_exploration_depth=1,
            initial_seed_limit=1
        )
        
        if results['direct_matches']:
            concept = results['direct_matches'][0]
            print(f"Exploring hierarchy for: {concept.name} (ID: {concept.id})")
            
            hierarchy = await explorer.get_concept_hierarchy(
                concept_id=concept.id,
                max_depth=2
            )
            
            print(f"  Root concept: {hierarchy['root_concept'].name}")
            print(f"  Parents: {len(hierarchy['parents'])}")
            print(f"  Children: {len(hierarchy['children'])}")
            print(f"  Depth: {hierarchy['depth']}")
            
            if hierarchy['parents']:
                print("\n  Parent concepts:")
                for parent in hierarchy['parents'][:3]:
                    print(f"    - {parent.name} ({parent.vocabularyId})")
            
            if hierarchy['children']:
                print("\n  Child concepts:")
                for child in hierarchy['children'][:3]:
                    print(f"    - {child.name} ({child.vocabularyId})")
        
    except Exception as e:
        logger.error(f"Hierarchy exploration failed: {e}")


async def main():
    """Run all demos."""
    print("Concept Exploration Demo")
    print("This demo showcases the ConceptExplorer with:")
    print("- Async/await support for improved performance")
    print("- BFS-based exploration algorithm")
    print("- Batch processing of API calls")
    print("- Configurable exploration parameters")
    print("- Enhanced error handling")
    
    # Run all demos
    await demo_basic_exploration()
    await demo_mapping_with_confidence()
    await demo_performance_comparison()
    await demo_error_handling()
    await demo_alternative_queries()
    await demo_concept_hierarchy()
    
    print("\n" + "="*60)
    print("Demo completed!")
    print("="*60)


if __name__ == "__main__":
    # Run the async main function
    asyncio.run(main()) 
```

### File: `athena_client/examples/concept_set_demo.py`
<a name="athena_client-examples-concept_set_demopy"></a>
```python
#!/usr/bin/env python3
"""Example demonstrating concept set generation."""

import asyncio

from athena_client import Athena


async def main() -> None:
    client = Athena()
    result = await client.generate_concept_set(
        "hypertension",
        db_connection_string="postgresql://user:pass@localhost/omop",
    )
    print(result)


if __name__ == "__main__":
    asyncio.run(main())

```

### File: `athena_client/examples/demo.py`
<a name="athena_client-examples-demopy"></a>
```python
#!/usr/bin/env python3
"""
Comprehensive demo showcasing the robust athena-client library.

This demo demonstrates all the working features with the real Athena API.
"""
import sys
import os

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.query import Q


def main():
    print("üöÄ ROBUST ATHENA-CLIENT DEMO")
    print("=" * 60)
    print("This demo showcases the enhanced robust athena-client")
    print("working perfectly with the real Athena API!")
    print("=" * 60)

    # Create client
    print("\nüîß Creating enhanced Athena client...")
    athena = Athena()
    print("  ‚úÖ Client created successfully")

    print("\n" + "=" * 60)
    print("1. SEARCH FUNCTIONALITY")
    print("=" * 60)

    # Simple text search
    print("\nüîç Searching for 'aspirin'...")
    try:
        results = athena.search("aspirin", page=0, size=5)
        print(f"‚úÖ Search successful! Found {len(results)} results")
        print("üìã Showing first 5 results:")
        
        for i, concept in enumerate(results.top(5), 1):
            print(f"  {i}. [{concept.id}] {concept.name}")
            print(f"     Domain: {concept.domain}")
            print(f"     Vocabulary: {concept.vocabulary}")
            print(f"     Class: {concept.className}")
            print(f"     Standard: {concept.standardConcept}")
            print()

        # Pagination information
        print("üìä Pagination Information:")
        print(f"  - Total Elements: {results.total_elements}")
        print(f"  - Total Pages: {results.total_pages}")
        print(f"  - Current Page: {results.current_page}")
        print(f"  - Page Size: {results.page_size}")

        # Facets
        if results.facets:
            print("\nüîç Available Facets:")
            for facet_name, facet_values in results.facets.items():
                if isinstance(facet_values, dict):
                    top_values = dict(list(facet_values.items())[:3])
                    print(f"  - {facet_name}: {top_values}")

    except Exception as e:
        print(f"‚ùå Search failed: {e}")

    # Query DSL search
    print("\nüîç Using Query DSL to search for 'heart' OR 'cardiac'...")
    try:
        query = Q.term("heart") | Q.term("cardiac")
        complex_results = athena.search(query, page=0, size=3)
        print(f"‚úÖ Complex search successful! Found {len(complex_results)} results")
        
        for i, concept in enumerate(complex_results.top(3), 1):
            print(f"  {i}. [{concept.id}] {concept.name} ({concept.vocabulary})")
    except Exception as e:
        print(f"‚ùå Complex search failed: {e}")

    print("\n" + "=" * 60)
    print("2. CONCEPT DETAILS")
    print("=" * 60)

    # Get concept details
    print("\nüîç Getting concept details...")
    try:
        concept_id = 1112807  # RxNorm Aspirin
        details = athena.details(concept_id)
        print("‚úÖ Concept details retrieved successfully!")
        print(f"  üìã ID: {details.id}")
        print(f"  üìã Name: {details.name}")
        print(f"  üìã Domain: {details.domainId}")
        print(f"  üìã Vocabulary: {details.vocabularyId}")
        print(f"  üìã Class: {details.conceptClassId}")
        print(f"  üìã Standard: {details.standardConcept}")
        print(f"  üìã Code: {details.conceptCode}")
        print(f"  üìã Valid: {details.validStart} to {details.validEnd}")
        
        if details.synonyms:
            print(f"  üìã Synonyms: {', '.join(details.synonyms)}")
        
        if details.vocabularyName:
            print(f"  üìã Vocabulary Name: {details.vocabularyName}")
            print(f"  üìã Vocabulary Version: {details.vocabularyVersion}")
    except Exception as e:
        print(f"‚ùå Could not retrieve concept details: {e}")

    print("\n" + "=" * 60)
    print("3. CONCEPT RELATIONSHIPS")
    print("=" * 60)

    # Get relationships
    print("\nüîó Getting concept relationships...")
    try:
        relationships = athena.relationships(concept_id)
        print(f"‚úÖ Relationships retrieved successfully! Found {relationships.count} total relationships")
        
        if relationships.items:
            print("üìã Relationship Groups:")
            for i, group in enumerate(relationships.items[:3], 1):  # Show first 3 groups
                print(f"  {i}. {group.relationshipName} ({len(group.relationships)} relationships)")
                
                # Show first few relationships in each group
                for j, rel in enumerate(group.relationships[:2], 1):
                    print(f"     {j}. {rel.relationshipName} -> {rel.targetConceptName} ({rel.targetConceptId})")
                print()
    except Exception as e:
        print(f"‚ùå Could not retrieve relationships: {e}")

    print("\n" + "=" * 60)
    print("4. CONCEPT GRAPH")
    print("=" * 60)

    # Get graph
    print("\nüï∏Ô∏è Getting concept graph...")
    try:
        graph = athena.graph(concept_id, depth=2, zoom_level=2)
        print("‚úÖ Graph retrieved successfully!")
        print(f"  üìä Terms: {len(graph.terms)}")
        print(f"  üìä Links: {len(graph.links)}")
        
        if graph.terms:
            current_terms = [t for t in graph.terms if t.isCurrent]
            print(f"  üìä Current terms: {len(current_terms)}")
            for term in current_terms[:3]:  # Show first 3
                print(f"    - {term.name} (weight: {term.weight}, depth: {term.depth})")
        
        if graph.links:
            print(f"  üìä Sample links:")
            for link in graph.links[:3]:  # Show first 3
                print(f"    - {link.source} -> {link.target}")
    except Exception as e:
        print(f"‚ùå Could not retrieve graph: {e}")

    print("\n" + "=" * 60)
    print("5. CONFIGURATION OPTIONS")
    print("=" * 60)

    # Configuration examples
    print("\n‚öôÔ∏è Configuration Examples:")
    
    # Default configuration
    print("\n  Default Configuration:")
    default_client = Athena()
    print("    ‚úÖ Created with default settings (public Athena server)")
    
    # Custom configuration
    print("\n  Custom Configuration:")
    custom_client = Athena(
        timeout=15,
        max_retries=5
    )
    print("    ‚úÖ Created with custom timeout and retry settings")

    print("\nüìã Client Capabilities:")
    print("  - ‚úÖ Real API connectivity")
    print("  - ‚úÖ Enhanced error handling")
    print("  - ‚úÖ Robust retry logic")
    print("  - ‚úÖ Custom User-Agent and headers")
    print("  - ‚úÖ Parameter normalization")
    print("  - ‚úÖ Detailed logging")
    print("  - ‚úÖ Session management")
    print("  - ‚úÖ Pydantic model validation")
    print("  - ‚úÖ Search with pagination")
    print("  - ‚úÖ Query DSL support")
    print("  - ‚úÖ Concept details retrieval")
    print("  - ‚úÖ Relationship exploration")
    print("  - ‚úÖ Graph visualization data")

    print("\n" + "=" * 60)
    print("üéâ DEMO COMPLETED SUCCESSFULLY!")
    print("=" * 60)
    print("\nThe enhanced athena-client is working perfectly!")
    print("\nKey Features Demonstrated:")
    print("  ‚úÖ Real API connectivity")
    print("  ‚úÖ Search functionality with pagination")
    print("  ‚úÖ Query DSL for complex searches")
    print("  ‚úÖ Concept details retrieval")
    print("  ‚úÖ Relationships exploration")
    print("  ‚úÖ Graph visualization data")
    print("  ‚úÖ Configuration options")
    print("\nEnhanced Features:")
    print("  ‚úÖ Custom User-Agent (AthenaOHDSIAPIClient/1.0)")
    print("  ‚úÖ Robust error handling and logging")
    print("  ‚úÖ Enhanced retry logic")
    print("  ‚úÖ Parameter normalization")
    print("  ‚úÖ Proper URL building")
    print("  ‚úÖ Pydantic model validation")
    print("  ‚úÖ Flexible pagination handling")
    print("\nFor more information, visit: https://athena-client.readthedocs.io")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/error_handling_demo.py`
<a name="athena_client-examples-error_handling_demopy"></a>
```python
#!/usr/bin/env python3
"""
Comprehensive demo showcasing the enhanced error handling system.

This demo demonstrates how the athena-client provides clear, actionable error messages
for various failure scenarios, helping users understand and resolve issues quickly.
"""
import sys
import os

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.exceptions import (
    AthenaError, NetworkError, TimeoutError, ClientError, ServerError,
    AuthenticationError, RateLimitError, ValidationError, APIError
)


def demo_network_errors():
    """Demonstrate network error handling."""
    print("\nüåê NETWORK ERROR HANDLING")
    print("=" * 50)
    
    print("\n1. DNS Resolution Failure:")
    print("-" * 30)
    try:
        client = Athena(base_url="https://invalid-domain-that-does-not-exist-12345.com/api/v1")
        client.search("aspirin")
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")
    
    print("\n2. Connection Timeout:")
    print("-" * 30)
    try:
        client = Athena(timeout=0.001)  # Very short timeout
        client.search("aspirin")
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")


def demo_api_errors():
    """Demonstrate API error handling."""
    print("\nüîå API ERROR HANDLING")
    print("=" * 50)
    
    client = Athena()
    
    print("\n1. Invalid Concept ID:")
    print("-" * 30)
    try:
        client.details(999999999)  # Non-existent concept ID
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")
    
    print("\n2. Invalid Search Parameters:")
    print("-" * 30)
    try:
        client.search("", page=0, size=0)  # Invalid page size
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")
    
    print("\n3. Empty Search Query:")
    print("-" * 30)
    try:
        client.search("")  # Empty query
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")


def demo_http_errors():
    """Demonstrate HTTP error handling."""
    print("\nüåç HTTP ERROR HANDLING")
    print("=" * 50)
    
    client = Athena()
    
    print("\n1. 404 Not Found:")
    print("-" * 30)
    try:
        client.http.get("/nonexistent-endpoint")
    except Exception as e:
        print(f"‚úÖ Error Type: {type(e).__name__}")
        print(f"‚úÖ Error Message: {e}")


def demo_error_recovery():
    """Demonstrate error recovery and retry behavior."""
    print("\nüîÑ ERROR RECOVERY & RETRY")
    print("=" * 50)
    
    print("\n1. Retry Configuration:")
    print("-" * 30)
    client = Athena(max_retries=3, timeout=10)
    print(f"‚úÖ Max retries: {client.http.max_retries}")
    print(f"‚úÖ Timeout: {client.http.timeout} seconds")
    print(f"‚úÖ Backoff factor: {client.http.backoff_factor}")
    
    print("\n2. Successful Recovery Example:")
    print("-" * 30)
    try:
        # This should work and demonstrate successful API calls
        results = client.search("aspirin", size=5)
        print(f"‚úÖ Successfully found {len(results.all())} concepts")
        print(f"‚úÖ First concept: {results.all()[0].name if results.all() else 'None'}")
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")


def demo_error_types():
    """Demonstrate the different error types and their characteristics."""
    print("\nüìã ERROR TYPE HIERARCHY")
    print("=" * 50)
    
    print("\nError Types and Their Purposes:")
    print("-" * 40)
    
    error_types = [
        ("AthenaError", "Base class for all client exceptions"),
        ("NetworkError", "DNS, connection, socket issues"),
        ("TimeoutError", "Request timeout issues"),
        ("ClientError", "4xx HTTP status codes"),
        ("ServerError", "5xx HTTP status codes"),
        ("AuthenticationError", "401/403 authentication issues"),
        ("RateLimitError", "429 rate limiting issues"),
        ("ValidationError", "Data validation failures"),
        ("APIError", "API-specific error responses"),
    ]
    
    for error_type, description in error_types:
        print(f"‚úÖ {error_type:<20} - {description}")


def demo_troubleshooting():
    """Demonstrate troubleshooting suggestions."""
    print("\nüí° TROUBLESHOOTING FEATURES")
    print("=" * 50)
    
    print("\n1. Error Messages Include:")
    print("-" * 30)
    print("‚úÖ Clear explanation of what went wrong")
    print("‚úÖ Context about where the error occurred")
    print("‚úÖ Specific troubleshooting suggestions")
    print("‚úÖ Error codes for programmatic handling")
    print("‚úÖ User-friendly language (not technical jargon)")
    
    print("\n2. Example Troubleshooting Flow:")
    print("-" * 30)
    print("1. User encounters an error")
    print("2. Error message explains the problem")
    print("3. Troubleshooting section provides specific steps")
    print("4. User can take action to resolve the issue")
    print("5. If needed, error code allows for programmatic handling")


def demo_best_practices():
    """Demonstrate best practices for error handling."""
    print("\nüéØ ERROR HANDLING BEST PRACTICES")
    print("=" * 50)
    
    print("\n1. Always Use Try-Catch:")
    print("-" * 30)
    print("```python")
    print("try:")
    print("    results = athena.search('aspirin')")
    print("    print(f'Found {len(results.all())} concepts')")
    print("except NetworkError as e:")
    print("    print(f'Network issue: {e}')")
    print("except APIError as e:")
    print("    print(f'API issue: {e}')")
    print("except Exception as e:")
    print("    print(f'Unexpected error: {e}')")
    print("```")
    
    print("\n2. Check Error Types:")
    print("-" * 30)
    print("‚úÖ NetworkError - Retry after network issues")
    print("‚úÖ TimeoutError - Increase timeout or retry")
    print("‚úÖ ClientError - Check request parameters")
    print("‚úÖ ServerError - Wait and retry later")
    print("‚úÖ AuthenticationError - Check credentials")
    print("‚úÖ RateLimitError - Implement backoff strategy")
    
    print("\n3. Use Error Codes for Logic:")
    print("-" * 30)
    print("```python")
    print("try:")
    print("    concept = athena.details(concept_id)")
    print("except APIError as e:")
    print("    if e.error_code == 'CONCEPT_NOT_FOUND':")
    print("        # Handle missing concept")
    print("    elif e.error_code == 'INVALID_ID':")
    print("        # Handle invalid ID format")
    print("```")


def main():
    """Run the comprehensive error handling demo."""
    print("üöÄ ATHENA CLIENT - ENHANCED ERROR HANDLING DEMO")
    print("=" * 60)
    print("This demo showcases how the athena-client provides clear,")
    print("actionable error messages for various failure scenarios.")
    print("=" * 60)
    
    demo_error_types()
    demo_network_errors()
    demo_api_errors()
    demo_http_errors()
    demo_error_recovery()
    demo_troubleshooting()
    demo_best_practices()
    
    print("\n" + "=" * 60)
    print("üéâ ERROR HANDLING DEMO COMPLETE")
    print("=" * 60)
    print("‚úÖ All error scenarios demonstrated")
    print("‚úÖ Clear, actionable error messages shown")
    print("‚úÖ Troubleshooting suggestions provided")
    print("‚úÖ Best practices outlined")
    print("\nThe athena-client now provides comprehensive error handling")
    print("that helps users understand and resolve issues quickly!")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/graph_demo.py`
<a name="athena_client-examples-graph_demopy"></a>
```python
#!/usr/bin/env python3
"""
Graph Demo - Showcase Concept Relationship Graphs

This script demonstrates the graph functionality with concepts that have
actual relationship data in the Athena API.

Usage:
    python examples/graph_demo.py
"""

import sys
import os
import json
from typing import List, Dict, Any

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.models import ConceptRelationsGraph, GraphTerm, GraphLink


def print_separator(title: str):
    """Print a formatted separator with title."""
    print("\n" + "="*60)
    print(f"üìä {title}")
    print("="*60)


def print_concept_info(concept_id: int, name: str, vocabulary: str):
    """Print basic concept information."""
    print(f"\nüîç Concept: {name}")
    print(f"   ID: {concept_id}")
    print(f"   Vocabulary: {vocabulary}")


def analyze_graph_structure(graph: ConceptRelationsGraph) -> Dict[str, Any]:
    """Analyze the graph structure and return statistics."""
    stats = {
        "total_terms": len(graph.terms),
        "total_links": len(graph.links),
        "connections_count": graph.connectionsCount or 0,
        "depth_distribution": {},
        "weight_distribution": {},
        "current_concept": None,
        "related_concepts": []
    }
    
    # Analyze terms
    for term in graph.terms:
        # Track depth distribution
        depth = term.depth
        stats["depth_distribution"][depth] = stats["depth_distribution"].get(depth, 0) + 1
        
        # Track weight distribution
        weight_range = f"{term.weight//100*100}-{(term.weight//100+1)*100}"
        stats["weight_distribution"][weight_range] = stats["weight_distribution"].get(weight_range, 0) + 1
        
        # Identify current concept (depth 0)
        if term.depth == 0:
            stats["current_concept"] = {
                "id": term.id,
                "name": term.name,
                "weight": term.weight,
                "count": term.count
            }
        else:
            stats["related_concepts"].append({
                "id": term.id,
                "name": term.name,
                "depth": term.depth,
                "weight": term.weight,
                "count": term.count
            })
    
    return stats


def print_graph_statistics(stats: Dict[str, Any]):
    """Print detailed graph statistics."""
    print(f"\nüìà Graph Statistics:")
    print(f"   Total Terms: {stats['total_terms']}")
    print(f"   Total Links: {stats['total_links']}")
    print(f"   Total Connections: {stats['connections_count']:,}")
    
    if stats['current_concept']:
        current = stats['current_concept']
        print(f"\nüéØ Current Concept:")
        print(f"   Name: {current['name']}")
        print(f"   Weight: {current['weight']:,}")
        print(f"   Count: {current['count']:,}")
    
    if stats['related_concepts']:
        print(f"\nüîó Related Concepts ({len(stats['related_concepts'])}):")
        for i, concept in enumerate(stats['related_concepts'][:5], 1):  # Show first 5
            print(f"   {i}. {concept['name']}")
            print(f"      Depth: {concept['depth']}, Weight: {concept['weight']:,}")
        
        if len(stats['related_concepts']) > 5:
            print(f"   ... and {len(stats['related_concepts']) - 5} more")
    
    if stats['depth_distribution']:
        print(f"\nüìä Depth Distribution:")
        for depth, count in sorted(stats['depth_distribution'].items()):
            depth_name = "Current" if depth == 0 else f"Level {depth}"
            print(f"   {depth_name}: {count} concepts")


def print_graph_links(graph: ConceptRelationsGraph, max_links: int = 10):
    """Print graph links/relationships."""
    if not graph.links:
        print("\n‚ùå No relationship links found in the graph.")
        return
    
    print(f"\nüîó Graph Links (showing first {min(max_links, len(graph.links))}):")
    
    # Create a mapping of term IDs to names for easier lookup
    term_map = {term.id: term.name for term in graph.terms}
    
    for i, link in enumerate(graph.links[:max_links], 1):
        source_name = term_map.get(link.source, f"Unknown ({link.source})")
        target_name = term_map.get(link.target, f"Unknown ({link.target})")
        
        print(f"   {i}. {source_name} ‚Üí {target_name}")
        if link.relationshipName:
            print(f"      Relationship: {link.relationshipName}")


def demo_basic_graph():
    """Demonstrate basic graph functionality with aspirin."""
    print_separator("BASIC GRAPH DEMO - ASPIRIN (RxNorm)")
    
    athena = Athena()
    
    # Use RxNorm aspirin which has graph data
    concept_id = 1112807  # RxNorm aspirin
    concept_name = "aspirin"
    vocabulary = "RxNorm"
    
    print_concept_info(concept_id, concept_name, vocabulary)
    
    try:
        # Get graph with depth 1 and zoom level 1
        print(f"\nüîÑ Fetching graph data (depth=1, zoom=1)...")
        graph = athena.graph(concept_id, depth=1, zoom_level=1)
        
        if not graph.terms:
            print("‚ùå No graph data found for this concept.")
            return
        
        # Analyze and display graph structure
        stats = analyze_graph_structure(graph)
        print_graph_statistics(stats)
        print_graph_links(graph)
        
        return graph
        
    except Exception as e:
        print(f"‚ùå Error fetching graph: {e}")
        return None


def demo_deep_graph():
    """Demonstrate deeper graph exploration."""
    print_separator("DEEP GRAPH DEMO - ASPIRIN (RxNorm)")
    
    athena = Athena()
    concept_id = 1112807  # RxNorm aspirin
    
    print_concept_info(concept_id, "aspirin", "RxNorm")
    
    # Test different depth and zoom levels
    configurations = [
        (1, 1, "Shallow exploration"),
        (2, 1, "Medium depth"),
        (1, 2, "Higher zoom level"),
        (2, 2, "Deep exploration")
    ]
    
    for depth, zoom, description in configurations:
        print(f"\nüîÑ {description} (depth={depth}, zoom={zoom})...")
        
        try:
            graph = athena.graph(concept_id, depth=depth, zoom_level=zoom)
            
            if graph.terms:
                stats = analyze_graph_structure(graph)
                print(f"   ‚úÖ Found {stats['total_terms']} terms, {stats['total_links']} links")
                print(f"   üìä Connections: {stats['connections_count']:,}")
            else:
                print("   ‚ùå No graph data")
                
        except Exception as e:
            print(f"   ‚ùå Error: {e}")


def demo_multiple_concepts():
    """Demonstrate graphs for multiple concepts."""
    print_separator("MULTIPLE CONCEPTS GRAPH DEMO")
    
    athena = Athena()
    
    # Test concepts that might have graph data
    test_concepts = [
        (1112807, "aspirin", "RxNorm"),
        (43013024, "acetaminophen", "RxNorm"),
        (40163718, "ibuprofen", "RxNorm"),
        (46275062, "diabetes mellitus", "SNOMED"),
        (316139, "hypertension", "SNOMED")
    ]
    
    for concept_id, name, vocabulary in test_concepts:
        print_concept_info(concept_id, name, vocabulary)
        try:
            graph = athena.graph(concept_id, depth=1, zoom_level=1)
            if graph.terms:
                stats = analyze_graph_structure(graph)
                print(f"   ‚úÖ Graph data: {stats['total_terms']} terms, {stats['total_links']} links")
                # Show a sample of related concepts with standard status
                if stats['related_concepts']:
                    print("   üîó Sample related concepts (standard status):")
                    for sample in stats['related_concepts'][:3]:
                        # Find the term in graph.terms to get the 'standard' attribute
                        term = next((t for t in graph.terms if t.id == sample['id']), None)
                        if term is not None:
                            std_attr = getattr(term, 'standard', None)
                            # Normalize the standard attribute (could be 'S', 's', 'standard', True, etc.)
                            if std_attr is None:
                                std_str = "unknown"
                            elif isinstance(std_attr, bool):
                                std_str = "standard" if std_attr else "non-standard"
                            elif isinstance(std_attr, str):
                                std_str = "standard" if std_attr.strip().lower() in ["s", "standard", "true", "yes", "y"] else ("non-standard" if std_attr.strip().lower() in ["n", "non-standard", "false", "no"] else std_attr)
                            else:
                                std_str = str(std_attr)
                        else:
                            std_str = "unknown"
                        print(f"      - {sample['name']} (depth {sample['depth']}): {std_str}")
            else:
                print("   ‚ùå No graph data available")
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
        print()  # Empty line between concepts


def demo_graph_export():
    """Demonstrate exporting graph data to different formats."""
    print_separator("GRAPH EXPORT DEMO")
    
    athena = Athena()
    concept_id = 1112807  # RxNorm aspirin
    
    print_concept_info(concept_id, "aspirin", "RxNorm")
    
    try:
        graph = athena.graph(concept_id, depth=1, zoom_level=1)
        
        if not graph.terms:
            print("‚ùå No graph data to export.")
            return
        
        # Export to JSON
        print(f"\nüíæ Exporting graph data...")
        
        # Create a structured export
        export_data = {
            "concept_id": concept_id,
            "concept_name": "aspirin",
            "vocabulary": "RxNorm",
            "graph_metadata": {
                "total_terms": len(graph.terms),
                "total_links": len(graph.links),
                "connections_count": graph.connectionsCount
            },
            "terms": [term.model_dump() for term in graph.terms],
            "links": [link.model_dump() for link in graph.links]
        }
        
        # Save to file
        output_file = "output/aspirin_graph.json"
        os.makedirs("output", exist_ok=True)
        
        with open(output_file, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        print(f"‚úÖ Graph data exported to: {output_file}")
        print(f"üìä Export contains:")
        print(f"   - {len(graph.terms)} terms")
        print(f"   - {len(graph.links)} links")
        print(f"   - {graph.connectionsCount:,} total connections")
        
        # Show a sample of the export
        print(f"\nüìÑ Sample export structure:")
        print(json.dumps(export_data["graph_metadata"], indent=2))
        
    except Exception as e:
        print(f"‚ùå Error exporting graph: {e}")


def demo_graph_analysis():
    """Demonstrate advanced graph analysis."""
    print_separator("GRAPH ANALYSIS DEMO")
    
    athena = Athena()
    concept_id = 1112807  # RxNorm aspirin
    
    print_concept_info(concept_id, "aspirin", "RxNorm")
    
    try:
        graph = athena.graph(concept_id, depth=2, zoom_level=1)
        
        if not graph.terms:
            print("‚ùå No graph data for analysis.")
            return
        
        stats = analyze_graph_structure(graph)
        
        print(f"\nüî¨ Advanced Graph Analysis:")
        
        # Find the most connected terms
        term_connections = {}
        for link in graph.links:
            term_connections[link.source] = term_connections.get(link.source, 0) + 1
            term_connections[link.target] = term_connections.get(link.target, 0) + 1
        
        if term_connections:
            most_connected = max(term_connections.items(), key=lambda x: x[1])
            term_name = next((term.name for term in graph.terms if term.id == most_connected[0]), "Unknown")
            print(f"   üéØ Most connected term: {term_name} ({most_connected[1]} connections)")
        
        # Analyze depth distribution
        if stats['depth_distribution']:
            print(f"   üìä Depth analysis:")
            for depth, count in sorted(stats['depth_distribution'].items()):
                percentage = (count / stats['total_terms']) * 100
                depth_name = "Current" if depth == 0 else f"Level {depth}"
                print(f"      {depth_name}: {count} terms ({percentage:.1f}%)")
        
        # Find high-weight terms
        high_weight_terms = [term for term in graph.terms if term.weight > 1000]
        if high_weight_terms:
            print(f"   ‚ö° High-weight terms ({len(high_weight_terms)}):")
            for term in high_weight_terms[:3]:  # Show top 3
                print(f"      - {term.name} (weight: {term.weight:,})")
        
    except Exception as e:
        print(f"‚ùå Error analyzing graph: {e}")


def main():
    """Run all graph demos."""
    print("üöÄ ATHENA-CLIENT GRAPH DEMO")
    print("=" * 60)
    print("This demo showcases concept relationship graphs with actual data")
    print("from the Athena API, demonstrating the rich relationship")
    print("information available for medical concepts.")
    print("=" * 60)
    
    # Run all demos
    demo_basic_graph()
    demo_deep_graph()
    demo_multiple_concepts()
    demo_graph_export()
    demo_graph_analysis()
    
    print("\n" + "="*60)
    print("üéâ GRAPH DEMO COMPLETED!")
    print("="*60)
    print("\nKey Features Demonstrated:")
    print("  ‚úÖ Basic graph retrieval and visualization")
    print("  ‚úÖ Deep graph exploration with different parameters")
    print("  ‚úÖ Multiple concept comparison")
    print("  ‚úÖ Graph data export and analysis")
    print("  ‚úÖ Advanced graph statistics and insights")
    print("\nThe graph functionality provides rich relationship data")
    print("for understanding medical concept connections!")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/large_query_demo.py`
<a name="athena_client-examples-large_query_demopy"></a>
```python
#!/usr/bin/env python3
"""
Demo showcasing enhanced timeout handling, pagination, and user-friendly error messages.

This demo demonstrates how the athena-client handles:
- Large queries with intelligent timeout adjustment
- Progress tracking for long-running operations
- User-friendly warnings and error messages
- Smart pagination for large result sets
- Enhanced error handling for complex operations
"""
import sys
import os
import time

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.utils import estimate_query_size, format_large_query_warning


def demo_timeout_configuration():
    """Demonstrate enhanced timeout configuration."""
    print("\n‚è±Ô∏è  ENHANCED TIMEOUT CONFIGURATION")
    print("=" * 50)
    
    print("\n1. Default Timeout Settings:")
    print("-" * 35)
    athena = Athena()
    print(f"‚úÖ Default timeout: {athena.http.timeout} seconds")
    print(f"‚úÖ Search timeout: 45 seconds (configurable)")
    print(f"‚úÖ Graph timeout: 60 seconds (configurable)")
    print(f"‚úÖ Relationships timeout: 45 seconds (configurable)")
    
    print("\n2. Query Size Estimation:")
    print("-" * 35)
    test_queries = [
        "pain",
        "diabetes mellitus",
        "aspirin 325mg tablet",
        "acute myocardial infarction",
        "c"
    ]
    
    for query in test_queries:
        estimated_size = estimate_query_size(query)
        print(f"Query: '{query}' -> Estimated {estimated_size:,} results")
    
    print("\n3. Large Query Warnings:")
    print("-" * 35)
    for query in ["pain", "cancer", "diabetes"]:
        warning = format_large_query_warning(query, estimate_query_size(query))
        if warning:
            print(warning)
            print()


def demo_progress_tracking():
    """Demonstrate progress tracking for large operations."""
    print("\nüìä PROGRESS TRACKING")
    print("=" * 50)
    
    print("\n1. Progress Features:")
    print("-" * 25)
    print("‚úÖ Real-time progress bars")
    print("‚úÖ ETA calculations")
    print("‚úÖ Time elapsed tracking")
    print("‚úÖ Configurable update intervals")
    print("‚úÖ Thread-safe progress updates")
    
    print("\n2. Progress Configuration:")
    print("-" * 35)
    from athena_client.settings import get_settings
    settings = get_settings()
    print(f"‚úÖ Show progress: {settings.ATHENA_SHOW_PROGRESS}")
    print(f"‚úÖ Update interval: {settings.ATHENA_PROGRESS_UPDATE_INTERVAL} seconds")
    print(f"‚úÖ Large query threshold: {settings.ATHENA_LARGE_QUERY_THRESHOLD} results")
    
    print("\n3. Progress Examples:")
    print("-" * 25)
    print("‚Ä¢ Search operations with >100 results")
    print("‚Ä¢ Graph operations with depth >2")
    print("‚Ä¢ Relationship queries for complex concepts")
    print("‚Ä¢ Large pagination requests")


def demo_enhanced_error_messages():
    """Demonstrate enhanced error messages for large queries."""
    print("\nüí¨ ENHANCED ERROR MESSAGES")
    print("=" * 50)
    
    print("\n1. Timeout Error Examples:")
    print("-" * 35)
    print("‚ùå Search timeout: The query 'pain' is taking too long to process.")
    print("   Try:")
    print("   ‚Ä¢ Using more specific search terms")
    print("   ‚Ä¢ Adding domain or vocabulary filters")
    print("   ‚Ä¢ Reducing the page size")
    print("   ‚Ä¢ Breaking the query into smaller parts")
    
    print("\n2. Graph Timeout Error Examples:")
    print("-" * 40)
    print("‚ùå Graph timeout: The graph for concept 12345 is too complex.")
    print("   Try:")
    print("   ‚Ä¢ Reducing the depth (currently 3)")
    print("   ‚Ä¢ Reducing the zoom level (currently 3)")
    print("   ‚Ä¢ Using a simpler concept as the starting point")
    print("   ‚Ä¢ Breaking the request into smaller parts")
    
    print("\n3. Pagination Error Examples:")
    print("-" * 35)
    print("‚ùå Page size too large: Page size must not be greater than 1000")
    print("   Please reduce the page size to 1000 or less.")


def demo_smart_pagination():
    """Demonstrate smart pagination features."""
    print("\nüìÑ SMART PAGINATION")
    print("=" * 50)
    
    print("\n1. Pagination Configuration:")
    print("-" * 35)
    from athena_client.settings import get_settings
    settings = get_settings()
    print(f"‚úÖ Default page size: {settings.ATHENA_DEFAULT_PAGE_SIZE}")
    print(f"‚úÖ Maximum page size: {settings.ATHENA_MAX_PAGE_SIZE}")
    print(f"‚úÖ Auto-chunk large queries: {settings.ATHENA_AUTO_CHUNK_LARGE_QUERIES}")
    print(f"‚úÖ Chunk size: {settings.ATHENA_CHUNK_SIZE}")
    
    print("\n2. Pagination Features:")
    print("-" * 25)
    print("‚úÖ Automatic page size validation")
    print("‚úÖ Smart defaults based on query size")
    print("‚úÖ Large query chunking")
    print("‚úÖ Progress tracking for pagination")
    print("‚úÖ Memory-efficient result handling")
    
    print("\n3. Pagination Best Practices:")
    print("-" * 35)
    print("‚Ä¢ Use smaller page sizes for large queries")
    print("‚Ä¢ Enable progress tracking for pagination")
    print("‚Ä¢ Consider chunking very large result sets")
    print("‚Ä¢ Monitor memory usage for large datasets")


def demo_large_query_handling():
    """Demonstrate handling of large queries."""
    print("\nüîç LARGE QUERY HANDLING")
    print("=" * 50)
    
    athena = Athena()
    
    print("\n1. Large Query Detection:")
    print("-" * 30)
    large_queries = [
        "pain",
        "diabetes",
        "cancer",
        "heart disease"
    ]
    
    for query in large_queries:
        estimated_size = estimate_query_size(query)
        print(f"Query: '{query}'")
        print(f"  Estimated size: {estimated_size:,} results")
        print(f"  Timeout: {athena.http.timeout * (2.5 if estimated_size > 10000 else 2.0 if estimated_size > 5000 else 1.5):.0f} seconds")
        print()
    
    print("\n2. Large Query Strategies:")
    print("-" * 30)
    print("‚úÖ Automatic timeout adjustment")
    print("‚úÖ Progress tracking for long operations")
    print("‚úÖ User-friendly warnings")
    print("‚úÖ Smart pagination defaults")
    print("‚úÖ Memory-efficient processing")
    
    print("\n3. Large Query Optimization:")
    print("-" * 35)
    print("‚Ä¢ Add specific filters (domain, vocabulary)")
    print("‚Ä¢ Use smaller page sizes")
    print("‚Ä¢ Enable progress tracking")
    print("‚Ä¢ Consider breaking into smaller queries")
    print("‚Ä¢ Monitor resource usage")


def demo_complex_graph_operations():
    """Demonstrate complex graph operations with enhanced handling."""
    print("\nüï∏Ô∏è  COMPLEX GRAPH OPERATIONS")
    print("=" * 50)
    
    print("\n1. Graph Complexity Estimation:")
    print("-" * 35)
    graph_configs = [
        (2, 2, "Simple graph"),
        (3, 3, "Complex graph"),
        (4, 4, "Very complex graph"),
        (5, 5, "Extremely complex graph")
    ]
    
    for depth, zoom, description in graph_configs:
        complexity = depth * zoom * 100
        timeout = 60 * (2.5 if complexity > 1000 else 2.0 if complexity > 500 else 1.5)
        print(f"{description}: depth={depth}, zoom={zoom}")
        print(f"  Estimated complexity: {complexity}")
        print(f"  Estimated timeout: {timeout:.0f} seconds")
        print()
    
    print("\n2. Graph Operation Features:")
    print("-" * 35)
    print("‚úÖ Complexity-based timeout adjustment")
    print("‚úÖ Progress tracking for complex graphs")
    print("‚úÖ User warnings for complex operations")
    print("‚úÖ Enhanced error messages")
    print("‚úÖ Automatic retry with backoff")
    
    print("\n3. Graph Optimization Tips:")
    print("-" * 30)
    print("‚Ä¢ Start with smaller depth/zoom values")
    print("‚Ä¢ Monitor progress for complex graphs")
    print("‚Ä¢ Use simpler concepts as starting points")
    print("‚Ä¢ Consider breaking into multiple requests")
    print("‚Ä¢ Enable progress tracking for visibility")


def demo_best_practices():
    """Demonstrate best practices for large queries."""
    print("\nüéØ BEST PRACTICES")
    print("=" * 50)
    
    print("\n1. Query Optimization:")
    print("-" * 25)
    print("‚úÖ Use specific search terms")
    print("‚úÖ Add domain/vocabulary filters")
    print("‚úÖ Start with smaller page sizes")
    print("‚úÖ Enable progress tracking")
    print("‚úÖ Monitor timeout settings")
    
    print("\n2. Error Handling:")
    print("-" * 25)
    print("‚úÖ Read error messages carefully")
    print("‚úÖ Follow troubleshooting suggestions")
    print("‚úÖ Adjust query parameters as needed")
    print("‚úÖ Use appropriate timeout values")
    print("‚úÖ Implement proper retry logic")
    
    print("\n3. Performance Monitoring:")
    print("-" * 30)
    print("‚úÖ Monitor query execution time")
    print("‚úÖ Track memory usage")
    print("‚úÖ Watch for timeout patterns")
    print("‚úÖ Log large query operations")
    print("‚úÖ Optimize based on usage patterns")
    
    print("\n4. Configuration Recommendations:")
    print("-" * 40)
    print("‚úÖ Set appropriate timeout values")
    print("‚úÖ Enable progress tracking")
    print("‚úÖ Configure reasonable page sizes")
    print("‚úÖ Use smart retry strategies")
    print("‚úÖ Monitor and adjust settings")


def main():
    """Run the comprehensive large query demo."""
    print("üöÄ ATHENA CLIENT - ENHANCED LARGE QUERY HANDLING DEMO")
    print("=" * 70)
    print("This demo showcases the enhanced features for handling large queries,")
    print("including intelligent timeouts, progress tracking, and user-friendly")
    print("error messages.")
    print("=" * 70)
    
    demo_timeout_configuration()
    demo_progress_tracking()
    demo_enhanced_error_messages()
    demo_smart_pagination()
    demo_large_query_handling()
    demo_complex_graph_operations()
    demo_best_practices()
    
    print("\n" + "=" * 70)
    print("üéâ LARGE QUERY HANDLING DEMO COMPLETE")
    print("=" * 70)
    print("‚úÖ Enhanced timeout configuration demonstrated")
    print("‚úÖ Progress tracking features shown")
    print("‚úÖ User-friendly error messages displayed")
    print("‚úÖ Smart pagination features explained")
    print("‚úÖ Large query handling strategies outlined")
    print("‚úÖ Best practices for optimization provided")
    print("\nThe athena-client now provides comprehensive support for")
    print("large queries with intelligent timeout handling, progress")
    print("tracking, and user-friendly error messages!")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/retry_throttling_demo.py`
<a name="athena_client-examples-retry_throttling_demopy"></a>
```python
#!/usr/bin/env python3
"""
Demo showcasing the enhanced retry mechanism and request throttling.

This demo demonstrates how the athena-client handles:
- Rate limiting (429 errors)
- Server overload (5xx errors)
- Network timeouts
- Request throttling to prevent overwhelming the server
"""
import sys
import os
import time

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena


def demo_retry_configuration():
    """Demonstrate retry configuration options."""
    print("\nüîß RETRY CONFIGURATION")
    print("=" * 50)
    
    # Default configuration
    print("\n1. Default Configuration:")
    print("-" * 30)
    athena_default = Athena()
    print(f"‚úÖ Max retries: {athena_default.http.max_retries}")
    print(f"‚úÖ Timeout: {athena_default.http.timeout} seconds")
    print(f"‚úÖ Backoff factor: {athena_default.http.backoff_factor}")
    print(f"‚úÖ Throttling: {'enabled' if athena_default.http.enable_throttling else 'disabled'}")
    print(f"‚úÖ Throttle delay range: {athena_default.http.throttle_delay_range} seconds")
    
    # Custom configuration
    print("\n2. Custom Configuration:")
    print("-" * 30)
    athena_custom = Athena(
        max_retries=5,
        timeout=30,
        enable_throttling=True,
        throttle_delay_range=(0.2, 0.5)
    )
    print(f"‚úÖ Max retries: {athena_custom.http.max_retries}")
    print(f"‚úÖ Timeout: {athena_custom.http.timeout} seconds")
    print(f"‚úÖ Backoff factor: {athena_custom.http.backoff_factor}")
    print(f"‚úÖ Throttling: {'enabled' if athena_custom.http.enable_throttling else 'disabled'}")
    print(f"‚úÖ Throttle delay range: {athena_custom.http.throttle_delay_range} seconds")
    
    # No throttling configuration
    print("\n3. No Throttling Configuration:")
    print("-" * 30)
    athena_no_throttle = Athena(enable_throttling=False)
    print(f"‚úÖ Throttling: {'enabled' if athena_no_throttle.http.enable_throttling else 'disabled'}")


def demo_retry_mechanism():
    """Demonstrate the retry mechanism in action."""
    print("\nüîÑ RETRY MECHANISM")
    print("=" * 50)
    
    athena = Athena(max_retries=2)  # Use fewer retries for demo
    
    print("\n1. Successful Request (No Retry Needed):")
    print("-" * 40)
    start_time = time.time()
    try:
        results = athena.search("aspirin", size=5)
        end_time = time.time()
        print(f"‚úÖ Success: Found {len(results.all())} concepts")
        print(f"‚úÖ Time taken: {end_time - start_time:.2f} seconds")
        print(f"‚úÖ No retries needed")
    except Exception as e:
        print(f"‚ùå Error: {e}")
    
    print("\n2. Retry on Network Issues:")
    print("-" * 40)
    print("   (This would normally show retry behavior for network issues)")
    print("   ‚úÖ Automatic retry on connection errors")
    print("   ‚úÖ Exponential backoff between attempts")
    print("   ‚úÖ Respects Retry-After headers")
    print("   ‚úÖ Logs retry attempts for debugging")


def demo_rate_limiting():
    """Demonstrate rate limiting handling."""
    print("\n‚è±Ô∏è RATE LIMITING HANDLING")
    print("=" * 50)
    
    print("\n1. Rate Limit Detection:")
    print("-" * 30)
    print("‚úÖ Detects 429 status codes automatically")
    print("‚úÖ Respects Retry-After headers from server")
    print("‚úÖ Uses exponential backoff if no Retry-After header")
    print("‚úÖ Logs rate limiting events")
    
    print("\n2. Rate Limit Response:")
    print("-" * 30)
    print("‚úÖ Waits for server-specified time")
    print("‚úÖ Retries request after waiting")
    print("‚úÖ Provides clear error messages")
    print("‚úÖ Includes troubleshooting suggestions")


def demo_request_throttling():
    """Demonstrate request throttling."""
    print("\nüêå REQUEST THROTTLING")
    print("=" * 50)
    
    print("\n1. Throttling Benefits:")
    print("-" * 30)
    print("‚úÖ Prevents overwhelming the server")
    print("‚úÖ Reduces likelihood of rate limiting")
    print("‚úÖ Random delays prevent thundering herd")
    print("‚úÖ Configurable delay ranges")
    
    print("\n2. Throttling in Action:")
    print("-" * 30)
    athena = Athena(enable_throttling=True, throttle_delay_range=(0.1, 0.2))
    
    start_time = time.time()
    for i in range(3):
        print(f"   Making request {i+1}/3...")
        try:
            results = athena.search("aspirin", size=1)
            print(f"   ‚úÖ Request {i+1} successful")
        except Exception as e:
            print(f"   ‚ùå Request {i+1} failed: {e}")
    
    end_time = time.time()
    total_time = end_time - start_time
    print(f"\n‚úÖ Total time for 3 requests: {total_time:.2f} seconds")
    print(f"‚úÖ Average time per request: {total_time/3:.2f} seconds")
    print(f"‚úÖ Includes throttling delays")


def demo_error_recovery():
    """Demonstrate error recovery scenarios."""
    print("\nüõ†Ô∏è ERROR RECOVERY SCENARIOS")
    print("=" * 50)
    
    print("\n1. Server Overload (5xx Errors):")
    print("-" * 35)
    print("‚úÖ Retries on 500, 502, 503, 504 errors")
    print("‚úÖ Also retries on 520, 521, 522, 523, 524")
    print("‚úÖ Exponential backoff between attempts")
    print("‚úÖ Clear error messages after max retries")
    
    print("\n2. Network Issues:")
    print("-" * 35)
    print("‚úÖ Retries on connection errors")
    print("‚úÖ Retries on DNS resolution failures")
    print("‚úÖ Retries on timeout errors")
    print("‚úÖ Handles temporary network instability")
    
    print("\n3. API Errors:")
    print("-" * 35)
    print("‚úÖ No retry on 4xx client errors")
    print("‚úÖ Clear, actionable error messages")
    print("‚úÖ Specific handling for common errors")
    print("‚úÖ Helpful troubleshooting suggestions")


def demo_best_practices():
    """Demonstrate best practices for retry and throttling."""
    print("\nüéØ BEST PRACTICES")
    print("=" * 50)
    
    print("\n1. Production Configuration:")
    print("-" * 35)
    print("‚úÖ Use 3-5 max retries for production")
    print("‚úÖ Enable throttling to be respectful")
    print("‚úÖ Use reasonable timeout values (15-30s)")
    print("‚úÖ Monitor retry patterns in logs")
    
    print("\n2. Development Configuration:")
    print("-" * 35)
    print("‚úÖ Use fewer retries for faster feedback")
    print("‚úÖ Disable throttling for testing if needed")
    print("‚úÖ Use shorter timeouts for quick iteration")
    print("‚úÖ Enable debug logging for troubleshooting")
    
    print("\n3. Rate Limit Handling:")
    print("-" * 35)
    print("‚úÖ Always respect Retry-After headers")
    print("‚úÖ Implement exponential backoff")
    print("‚úÖ Log rate limiting events")
    print("‚úÖ Consider implementing circuit breakers")


def main():
    """Run the retry and throttling demo."""
    print("üöÄ ATHENA CLIENT - RETRY & THROTTLING DEMO")
    print("=" * 60)
    print("This demo showcases the enhanced retry mechanism and")
    print("request throttling features of the athena-client.")
    print("=" * 60)
    
    demo_retry_configuration()
    demo_retry_mechanism()
    demo_rate_limiting()
    demo_request_throttling()
    demo_error_recovery()
    demo_best_practices()
    
    print("\n" + "=" * 60)
    print("üéâ RETRY & THROTTLING DEMO COMPLETE")
    print("=" * 60)
    print("‚úÖ Enhanced retry mechanism demonstrated")
    print("‚úÖ Request throttling features shown")
    print("‚úÖ Rate limiting handling explained")
    print("‚úÖ Best practices outlined")
    print("\nThe athena-client now provides robust handling of")
    print("rate limiting, server overload, and network issues!")


if __name__ == "__main__":
    main() 
```

### File: `athena_client/examples/simple_usage_demo.py`
<a name="athena_client-examples-simple_usage_demopy"></a>
```python
#!/usr/bin/env python3
"""
Simple demo showcasing the athena-client library working with the real Athena API.
"""
import sys
import os

# Add parent directory to Python path for local execution
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from athena_client import Athena
from athena_client.query import Q


def main():
    print("üöÄ ATHENA-CLIENT SIMPLE DEMO")
    print("=" * 50)
    print("Testing the athena-client with the real Athena API")
    print("=" * 50)

    # Create client
    print("\nüîß Creating Athena client...")
    athena = Athena()
    print("‚úÖ Client created successfully")

    print("\n" + "=" * 50)
    print("1. BASIC SEARCH")
    print("=" * 50)

    # Simple text search
    print("\nüîç Searching for 'aspirin'...")
    try:
        results = athena.search("aspirin", page=0, size=3)
        print(f"‚úÖ Search successful! Found {len(results)} results")
        print("üìã Results:")
        
        for i, concept in enumerate(results.top(3), 1):
            print(f"  {i}. [{concept.id}] {concept.name}")
            print(f"     Domain: {concept.domain}")
            print(f"     Vocabulary: {concept.vocabulary}")
            print(f"     Class: {concept.className}")
            print()

        print(f"üìä Total results available: {results.total_elements}")

    except Exception as e:
        print(f"‚ùå Search failed: {e}")

    print("\n" + "=" * 50)
    print("2. QUERY DSL SEARCH")
    print("=" * 50)

    # Query DSL search
    print("\nüîç Using Query DSL to search for 'heart' OR 'cardiac'...")
    try:
        query = Q.term("heart") | Q.term("cardiac")
        complex_results = athena.search(query, page=0, size=3)
        print(f"‚úÖ Complex search successful! Found {len(complex_results)} results")
        
        for i, concept in enumerate(complex_results.top(3), 1):
            print(f"  {i}. [{concept.id}] {concept.name} ({concept.vocabulary})")
    except Exception as e:
        print(f"‚ùå Complex search failed: {e}")

    print("\n" + "=" * 50)
    print("3. CONCEPT DETAILS")
    print("=" * 50)

    # Get concept details for the first aspirin result
    print("\nüîç Getting concept details for aspirin...")
    try:
        # Get the first aspirin concept ID from the search
        aspirin_results = athena.search("aspirin", page=0, size=1)
        if aspirin_results:
            concept_id = aspirin_results[0].id
            details = athena.details(concept_id)
            print("‚úÖ Concept details retrieved successfully!")
            print(f"  üìã ID: {details.id}")
            print(f"  üìã Name: {details.name}")
            print(f"  üìã Domain: {details.domainId}")
            print(f"  üìã Vocabulary: {details.vocabularyId}")
            print(f"  üìã Class: {details.conceptClassId}")
            print(f"  üìã Code: {details.conceptCode}")
        else:
            print("‚ùå No aspirin concepts found")
    except Exception as e:
        print(f"‚ùå Could not retrieve concept details: {e}")

    print("\n" + "=" * 50)
    print("4. CONCEPT RELATIONSHIPS")
    print("=" * 50)

    # Get relationships for the same concept
    print("\nüîó Getting concept relationships...")
    try:
        if aspirin_results:
            concept_id = aspirin_results[0].id
            relationships = athena.relationships(concept_id)
            print(f"‚úÖ Relationships retrieved successfully! Found {relationships.count} total relationships")
            
            if relationships.items:
                print("üìã Relationship Groups:")
                for i, group in enumerate(relationships.items[:2], 1):  # Show first 2 groups
                    print(f"  {i}. {group.relationshipName} ({len(group.relationships)} relationships)")
        else:
            print("‚ùå No concept available for relationships")
    except Exception as e:
        print(f"‚ùå Could not retrieve relationships: {e}")

    print("\n" + "=" * 50)
    print("5. CONCEPT GRAPH")
    print("=" * 50)

    # Get graph for the same concept
    print("\nüï∏Ô∏è Getting concept graph...")
    try:
        if aspirin_results:
            concept_id = aspirin_results[0].id
            graph = athena.graph(concept_id, depth=1, zoom_level=1)
            print("‚úÖ Graph retrieved successfully!")
            print(f"  üìä Terms: {len(graph.terms)}")
            print(f"  üìä Links: {len(graph.links)}")
        else:
            print("‚ùå No concept available for graph")
    except Exception as e:
        print(f"‚ùå Could not retrieve graph: {e}")

    print("\n" + "=" * 50)
    print("üéâ DEMO COMPLETED!")
    print("=" * 50)
    print("\nThe athena-client is working correctly with the Athena API!")
    print("\nKey Features Demonstrated:")
    print("  ‚úÖ Basic text search")
    print("  ‚úÖ Query DSL for complex searches")
    print("  ‚úÖ Concept details retrieval")
    print("  ‚úÖ Relationships exploration")
    print("  ‚úÖ Graph visualization data")
    print("\nAll API calls are working as expected!")


if __name__ == "__main__":
    main() 
```

## Folder: .venv

## Folder: .venv/include

## Folder: .venv/lib

## Folder: .venv/lib/python3.9

## Folder: .venv/share

## Folder: .venv/share/man

## Folder: .venv/share/man/man1

## Folder: .github

## Folder: .github/workflows

### File: `athena_client/.github/workflows/ci.yml`
<a name="athena_client-github-workflows-ciyml"></a>
```yaml
name: CI

on: [push, pull_request]

jobs:
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      - name: Install Hatch
        run: pip install hatch
      - name: Install Bandit
        run: pip install bandit
      - name: Install dev deps
        run: hatch env create
      - name: Bandit
        run: make bandit

  test:
    name: Tests & SBOM
    needs: security
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      - name: Install Hatch
        run: pip install hatch
      - name: Install dev deps
        run: hatch env create
      - name: List installed packages
        run: hatch run pip list
      - name: Test suite
        run: hatch run cov
      - name: Generate SBOM
        if: github.ref == 'refs/heads/main'
        run: make cyclonedx
      - name: Upload SBOM
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.json

```

### File: `athena_client/.github/workflows/publish.yml`
<a name="athena_client-github-workflows-publishyml"></a>
```yaml
name: Publish Python Package

on:
  push:
    tags:
      - 'v*.*.*'

jobs:
  build-and-publish:
    name: Build and Publish to PyPI
    runs-on: ubuntu-latest
    environment: pypi
    permissions:
      id-token: write
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install build tools
        run: pip install build twine hatch
      - name: Build package
        run: python -m build
      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1

```

## Folder: build

## Folder: build/bdist.macosx-15-arm64

## Folder: build/bdist.macosx-15.0-arm64

## Folder: build/lib

## Folder: build/lib/athena_client

### File: `athena_client/build/lib/athena_client/__init__.py`
<a name="athena_client-build-lib-athena_client-__init__py"></a>
```python
"""
athena-client: Production-ready Python SDK for the OHDSI Athena Concepts API
"""

from .client import AthenaClient
from .concept_explorer import ConceptExplorer, create_concept_explorer
from .db.base import DatabaseConnector
from .db.sqlalchemy_connector import SQLAlchemyConnector
from .models import ConceptDetails, ConceptRelationsGraph, ConceptRelationship

Athena = AthenaClient

__version__ = "1.0.5"

__all__ = [
    "Athena",
    "AthenaClient",
    "ConceptDetails",
    "ConceptRelationsGraph",
    "ConceptRelationship",
    "ConceptExplorer",
    "create_concept_explorer",
    "SQLAlchemyConnector",
    "DatabaseConnector",
]

```

### File: `athena_client/build/lib/athena_client/async_client.py`
<a name="athena_client-build-lib-athena_client-async_clientpy"></a>
```python
"""
Async HTTP client for the Athena API.

This module provides an asynchronous HTTP client for interacting with the Athena API.
It uses httpx for HTTP requests and provides automatic retry logic, rate limiting,
and error handling.
"""

import json
import logging
from typing import Any, Dict, Optional, Union, cast

try:
    import httpx
except ImportError as err:
    raise AttributeError(
        "httpx is required for the async client. Install with 'pip install httpx'"
    ) from err

try:
    import backoff
except ImportError as err:
    raise ImportError(
        "backoff is required for the async client. Install with 'pip install backoff'"
    ) from err

from .auth import build_headers
from .concept_explorer import create_concept_explorer
from .concept_set import ConceptSetGenerator
from .db.base import DatabaseConnector
from .exceptions import AthenaError, ClientError, NetworkError, ServerError
from .models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
    ConceptSearchResponse,
)
from .search_result import SearchResult
from .settings import get_settings

logger = logging.getLogger(__name__)


class AsyncHttpClient:
    """
    Asynchronous HTTP client for making requests to the Athena API.

    Features:
    - Automatic retry with exponential backoff
    - Custom timeout handling
    - Authentication header generation
    - Error handling and mapping to typed exceptions
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        db_connector: Optional[DatabaseConnector] = None,
    ) -> None:
        """
        Initialize the async HTTP client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
        """
        settings = get_settings()

        # Use provided values or fall back to settings
        self.base_url = base_url or settings.ATHENA_BASE_URL

        # Set up token and HMAC if provided
        if token is not None:
            settings.ATHENA_TOKEN = token
        if client_id is not None:
            settings.ATHENA_CLIENT_ID = client_id
        if private_key is not None:
            settings.ATHENA_PRIVATE_KEY = private_key

        self.timeout = timeout or settings.ATHENA_TIMEOUT_SECONDS
        self.max_retries = max_retries or settings.ATHENA_MAX_RETRIES
        self.backoff_factor = backoff_factor or settings.ATHENA_BACKOFF_FACTOR

        # Create httpx client
        self.client = httpx.AsyncClient(timeout=self.timeout)

        # Set up default headers
        self._setup_default_headers()

    def _setup_default_headers(self) -> None:
        """Set up default headers for all requests."""
        # Set default headers similar to the working client
        default_headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "AthenaOHDSIAPIClient/1.0",
        }

        # Update client headers
        self.client.headers.update(default_headers)

        logger.debug("Default headers set: %s", default_headers)

    def _build_url(self, path: str) -> str:
        """
        Build full URL by joining base URL and path.

        Args:
            path: API endpoint path

        Returns:
            Full URL
        """
        # Handle paths that start with / to ensure they're appended correctly
        if path.startswith("/"):
            # Remove the leading / and join with base_url
            path = path[1:]

        # Ensure base_url doesn't end with / and path doesn't start with /
        if self.base_url.endswith("/"):
            base = self.base_url[:-1]
        else:
            base = self.base_url

        if path.startswith("/"):
            path = path[1:]

        full_url = f"{base}/{path}"

        logger.debug(
            f"Building URL: base_url='{self.base_url}', path='{path}' "
            f"-> full_url='{full_url}'"
        )
        return full_url

    async def _handle_response(self, response: httpx.Response) -> Dict[str, Any]:
        """
        Handle API response and raise appropriate exceptions.

        Args:
            response: HTTP response from httpx

        Returns:
            Parsed JSON response

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
        """
        try:
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            if 400 <= response.status_code < 500:
                raise ClientError(
                    f"Client error: {response.status_code} {response.reason_phrase}",
                    status_code=response.status_code,
                    response=response.text,
                ) from e
            elif response.status_code >= 500:
                raise ServerError(
                    f"Server error: {response.status_code} {response.reason_phrase}",
                    status_code=response.status_code,
                    response=response.text,
                ) from e
            else:
                raise
        except httpx.DecodingError as e:
            raise AthenaError(f"Invalid JSON response: {e}") from e

    @backoff.on_exception(
        backoff.expo,
        (httpx.TimeoutException, httpx.ConnectError),
        max_tries=3,
        factor=0.3,
    )
    async def request(
        self,
        method: str,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        data: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make an HTTP request to the Athena API.

        Args:
            method: HTTP method (GET, POST, etc.)
            path: API endpoint path
            params: Query parameters
            data: Request body data
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
        """
        url = self._build_url(path)
        body_bytes = b""

        # Convert data to JSON bytes if provided
        if data is not None:
            body_bytes = json.dumps(data).encode("utf-8")

        # Build authentication headers
        headers = build_headers(method, url, body_bytes)

        # Add Content-Type header if sending data
        if data is not None:
            headers["Content-Type"] = "application/json"

        # Generate a correlation ID for logging
        correlation_id = f"req-{id(self)}-{id(path)}"
        logger.debug(f"[{correlation_id}] {method} {url}")

        try:
            response = await self.client.request(
                method=method,
                url=url,
                params=params,
                content=body_bytes if data is not None else None,
                headers=headers,
                timeout=self.timeout,
            )

            logger.debug(
                f"[{correlation_id}] {response.status_code} {response.reason_phrase}"
            )

            if raw_response:
                return response

            return await self._handle_response(response)

        except (httpx.TimeoutException, httpx.ConnectError) as e:
            logger.warning(f"[{correlation_id}] Network error: {e}")
            raise NetworkError(f"Network error: {e}") from e

    async def get(
        self,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make a GET request to the Athena API.

        Args:
            path: API endpoint path
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return await self.request("GET", path, params=params, raw_response=raw_response)

    async def post(
        self,
        path: str,
        data: Any = None,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], httpx.Response]:
        """
        Make a POST request to the Athena API.

        Args:
            path: API endpoint path
            data: Request body data
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return await self.request(
            "POST", path, data=data, params=params, raw_response=raw_response
        )


class AthenaAsyncClient:
    """
    Asynchronous client for the Athena API.

    This class provides asynchronous access to all Athena API endpoints
    with minimal abstraction, returning parsed Pydantic models.
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        db_connector: Optional[DatabaseConnector] = None,
    ) -> None:
        """
        Initialize the async Athena client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
            db_connector: Optional database connector for local OMOP validation
        """
        self.http = AsyncHttpClient(
            base_url=base_url,
            token=token,
            client_id=client_id,
            private_key=private_key,
            timeout=timeout,
            max_retries=max_retries,
            backoff_factor=backoff_factor,
        )
        self.db_connector = db_connector

    def set_database_connector(self, connector: DatabaseConnector) -> None:
        """Set the database connector for this client."""

        self.db_connector = connector

    async def search_concepts(
        self,
        query: str = "",
        exact: Optional[str] = None,
        fuzzy: bool = False,
        wildcard: Optional[str] = None,
        boosts: Optional[Dict[str, Any]] = None,
        debug: bool = False,
        page_size: int = 20,
        page: int = 0,
        domain: Optional[str] = None,
        vocabulary: Optional[str] = None,
        standard_concept: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Search for concepts in the Athena vocabulary.

        Args:
            query: The search query string
            exact: Exact match phrase
            fuzzy: Whether to enable fuzzy matching
            wildcard: Wildcard pattern
            boosts: Dictionary of field boosts
            debug: Enable debug mode
            page_size: Number of results per page
            page: Page number (0-indexed)
            domain: Filter by domain
            vocabulary: Filter by vocabulary
            standard_concept: Filter by standard concept status

        Returns:
            Raw API response data
        """
        # Convert page to start parameter that the API expects
        start = page * page_size

        params: Dict[str, Any] = {"pageSize": page_size, "start": start}

        # Add query if provided
        if query:
            params["query"] = query

        # Add filters if provided
        if exact:
            params["exact"] = exact
        if fuzzy:
            params["fuzzy"] = str(fuzzy).lower()
        if wildcard:
            params["wildcard"] = wildcard
        if domain:
            params["domain"] = domain
        if vocabulary:
            params["vocabulary"] = vocabulary
        if standard_concept:
            params["standardConcept"] = standard_concept

        # If boosts provided, use debug endpoint and include boosts in request
        if boosts or debug:
            response = await self.http.post(
                "/concepts",
                data={"boosts": boosts} if boosts else {},
                params=params,
            )
            return cast(Dict[str, Any], response)

        # Otherwise use standard GET endpoint
        response = await self.http.get("/concepts", params=params)
        return cast(Dict[str, Any], response)

    async def search(
        self,
        query: str = "",
        size: int = 20,
        page: int = 0,
        **kwargs: Any,
    ) -> SearchResult:
        """
        Search for concepts with a SearchResult wrapper.

        Args:
            query: The search query string
            size: Number of results per page
            page: Page number (0-indexed)
            **kwargs: Additional search parameters

        Returns:
            SearchResult object with convenient access methods
        """
        # Convert size to pageSize for the API
        search_kwargs: Dict[str, Any] = dict(kwargs)
        search_kwargs["page_size"] = size
        search_kwargs["page"] = page

        response_data = await self.search_concepts(query=query, **search_kwargs)
        response = ConceptSearchResponse.model_validate(response_data)
        return SearchResult(response, self)

    async def details(self, concept_id: int) -> ConceptDetails:
        """
        Get detailed information for a specific concept.

        This is an alias for get_concept_details for compatibility.

        Args:
            concept_id: The concept ID to get details for

        Returns:
            ConceptDetails object
        """
        return await self.get_concept_details(concept_id)

    async def relationships(
        self,
        concept_id: int,
        only_standard: bool = False,
        relationship_id: Optional[str] = None,
    ) -> ConceptRelationship:
        """
        Get relationships for a specific concept.

        This is an alias for get_concept_relationships for compatibility.

        Args:
            concept_id: The concept ID to get relationships for
            only_standard: Only include standard concepts
            relationship_id: Filter by relationship type

        Returns:
            ConceptRelationship object
        """
        return await self.get_concept_relationships(
            concept_id, relationship_id=relationship_id, only_standard=only_standard
        )

    async def get_concept_details(self, concept_id: int) -> ConceptDetails:
        """
        Get detailed information for a specific concept.

        Args:
            concept_id: The concept ID to get details for

        Returns:
            ConceptDetails object
        """
        response = await self.http.get(f"/concepts/{concept_id}")
        data = cast(Dict[str, Any], response)
        return ConceptDetails.model_validate(data)

    async def get_concept_relationships(
        self,
        concept_id: int,
        relationship_id: Optional[str] = None,
        only_standard: bool = False,
    ) -> ConceptRelationship:
        """
        Get relationships for a specific concept.

        Args:
            concept_id: The concept ID to get relationships for
            relationship_id: Filter by relationship type
            only_standard: Only include standard concepts

        Returns:
            ConceptRelationship object
        """
        params: Dict[str, Any] = {}

        if relationship_id:
            params["relationshipId"] = relationship_id
        if only_standard:
            params["standardConcepts"] = "true"

        response = await self.http.get(
            f"/concepts/{concept_id}/relationships", params=params
        )
        data = cast(Dict[str, Any], response)
        return ConceptRelationship.model_validate(data)

    async def get_concept_graph(
        self,
        concept_id: int,
        depth: int = 10,
        zoom_level: int = 4,
    ) -> ConceptRelationsGraph:
        """
        Get relationship graph for a specific concept.

        Args:
            concept_id: The concept ID to get graph for
            depth: Maximum depth of relationships to traverse
            zoom_level: Zoom level for the graph

        Returns:
            ConceptRelationsGraph object
        """
        params = {"depth": depth, "zoomLevel": zoom_level}
        response = await self.http.get(
            f"/concepts/{concept_id}/relations", params=params
        )
        data = cast(Dict[str, Any], response)
        return ConceptRelationsGraph.model_validate(data)

    async def generate_concept_set(self, query: str, **kwargs: Any) -> Dict[str, Any]:
        """Generate a validated concept set from a search query."""

        if not self.db_connector:
            raise RuntimeError("A database connector has not been configured.")

        explorer = create_concept_explorer(self)
        generator = ConceptSetGenerator(explorer=explorer, db=self.db_connector)

        return await generator.create_from_query(query, **kwargs)

```

### File: `athena_client/build/lib/athena_client/auth.py`
<a name="athena_client-build-lib-athena_client-authpy"></a>
```python
"""
Authentication module for the Athena client.

This module handles Bearer token and HMAC authentication for the Athena API.
"""

import logging
from base64 import b64encode
from datetime import datetime
from typing import Any, Dict

from cryptography.hazmat.primitives import hashes, serialization

from .settings import get_settings

logger = logging.getLogger(__name__)


def build_headers(method: str, url: str, body: bytes) -> Dict[str, str]:
    """
    Build authentication headers for Athena API requests.

    If a token is supplied, adds Bearer authentication.
    If a private key is supplied, adds HMAC signature.

    Args:
        method: HTTP method (GET, POST, etc.)
        url: Full request URL
        body: Request body as bytes

    Returns:
        Dictionary of headers to add to the request
    """
    s = get_settings()

    # Start with empty headers - authentication is optional
    hdrs = {}

    # Add Bearer token if available
    if s.ATHENA_TOKEN:
        hdrs["X-Athena-Auth"] = f"Bearer {s.ATHENA_TOKEN}"
        hdrs["X-Athena-Client-Id"] = s.ATHENA_CLIENT_ID or "athena-client"
        logger.debug("Bearer token authentication headers added")
    else:
        logger.debug("No API token provided; proceeding without Authorization header")

    # Add HMAC signature if private key is available
    if s.ATHENA_PRIVATE_KEY:
        try:
            nonce = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
            to_sign = f"{method}\n{url}\n\n{nonce}\n{body.decode()}"
            key = serialization.load_pem_private_key(
                s.ATHENA_PRIVATE_KEY.encode(), password=None
            )
            signing_key: Any = key
            sig = signing_key.sign(to_sign.encode(), hashes.SHA256())
            hdrs.update(
                {"X-Athena-Nonce": nonce, "X-Athena-Hmac": b64encode(sig).decode()}
            )
            logger.debug("HMAC signature headers added")
        except ImportError:
            logger.warning(
                "cryptography package is required for HMAC signing. "
                "Install with 'pip install \"athena-client[crypto]\"'"
            )
        except Exception as e:
            logger.error(f"Error generating HMAC signature: {e}")

    return hdrs

```

### File: `athena_client/build/lib/athena_client/cli.py`
<a name="athena_client-build-lib-athena_client-clipy"></a>
```python
"""
Command-line interface for the Athena client.

This module provides a CLI for interacting with the Athena API.
"""

import asyncio
import json
import sys
from typing import Any, Optional

try:
    import click
except ImportError:
    click = None  # type: ignore
    print(
        "The 'click' package is required for the CLI. "
        "Install with 'pip install \"athena-client[cli]\"'"
    )
    sys.exit(1)

try:
    import rich
    from rich.console import Console
    from rich.syntax import Syntax
    from rich.table import Table
except ImportError:
    rich = None  # type: ignore
    Console = None  # type: ignore
    Syntax = None  # type: ignore
    Table = None  # type: ignore

from . import Athena, __version__


def _create_client(
    base_url: Optional[str],
    token: Optional[str],
    timeout: Optional[int],
    retries: Optional[int],
) -> Athena:
    """
    Create an Athena client with the given parameters.

    Args:
        base_url: Base URL for the Athena API
        token: Bearer token for authentication
        timeout: HTTP timeout in seconds
        retries: Maximum number of retry attempts

    Returns:
        Athena client
    """
    return Athena(
        base_url=base_url,
        token=token,
        timeout=timeout,
        max_retries=retries,
    )


def _format_output(data: object, output: str, console: Any = None) -> None:
    """
    Format and print data based on the requested output format.

    Args:
        data: Data to format and print
        output: Output format (json, yaml, table, pretty)
        console: Rich console for pretty printing
    """
    if output == "json":
        if isinstance(data, str):
            print(data)
        else:
            print(json.dumps(data, indent=2))
    elif output == "yaml":
        try:
            import yaml

            print(yaml.dump(data))
        except ImportError:
            print(
                "The 'pyyaml' package is required for YAML output. "
                "Install with 'pip install \"athena-client[yaml]\"'"
            )
            sys.exit(1)
    elif output == "table" and console is not None and rich is not None:
        if hasattr(data, "to_list"):
            # Handle SearchResult
            results = data.to_list()
            if not results:
                console.print("[yellow]No results found[/yellow]")
                return

            table = Table(title="Athena Concepts")

            # Add columns
            table.add_column("ID", style="cyan")
            table.add_column("Name", style="green")
            table.add_column("Code", style="magenta")
            table.add_column("Vocabulary", style="blue")
            table.add_column("Domain", style="yellow")
            table.add_column("Class", style="red")

            # Add rows
            for item in results:
                table.add_row(
                    str(item["id"]),
                    item["name"],
                    item["code"],
                    item["vocabulary"],
                    item["domain"],
                    item["className"],
                )

            console.print(table)
        else:
            # Just pretty-print JSON for other data types
            syntax = Syntax(
                json.dumps(data, indent=2, default=str),
                "json",
                theme="monokai",
                word_wrap=True,
            )
            console.print(syntax)
    elif output == "pretty" and console is not None and rich is not None:
        # Use rich's pretty printing
        console.print(data)
    else:
        # Fall back to regular JSON
        if isinstance(data, str):
            print(data)
        else:
            print(json.dumps(data, indent=2))


@click.group()
@click.version_option(__version__)
@click.option(
    "--base-url",
    envvar="ATHENA_BASE_URL",
    help="Base URL for the Athena API",
)
@click.option(
    "--token",
    envvar="ATHENA_TOKEN",
    help="Bearer token for authentication",
)
@click.option(
    "--timeout",
    type=int,
    envvar="ATHENA_TIMEOUT_SECONDS",
    help="HTTP timeout in seconds",
)
@click.option(
    "--retries",
    type=int,
    envvar="ATHENA_MAX_RETRIES",
    help="Maximum number of retry attempts",
)
@click.option(
    "--output",
    "-o",
    type=click.Choice(["json", "yaml", "table", "pretty"]),
    default="table",
    help="Output format",
)
@click.pass_context
def cli(
    ctx: Any,
    base_url: Optional[str],
    token: Optional[str],
    timeout: Optional[int],
    retries: Optional[int],
    output: str,
) -> None:
    """Athena Client CLI - Interact with the OHDSI Athena API."""
    ctx.ensure_object(dict)
    ctx.obj["base_url"] = base_url
    ctx.obj["token"] = token
    ctx.obj["timeout"] = timeout
    ctx.obj["retries"] = retries
    ctx.obj["output"] = output

    # Set up rich console if available
    if rich is not None:
        ctx.obj["console"] = Console()
    else:
        ctx.obj["console"] = None


@cli.command()
@click.argument("query")
@click.option("--fuzzy/--no-fuzzy", default=False, help="Enable fuzzy matching")
@click.option("--page-size", type=int, default=20, help="Number of results per page")
@click.option("--page", type=int, default=0, help="Page number (0-indexed)")
@click.option("--domain", help="Filter by domain")
@click.option("--vocabulary", help="Filter by vocabulary")
@click.pass_context
def search(
    ctx: Any,
    query: str,
    fuzzy: bool,
    page_size: int,
    page: int,
    domain: Optional[str],
    vocabulary: Optional[str],
) -> None:
    """Search for concepts in the Athena vocabulary."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    results = client.search(
        query,
        fuzzy=fuzzy,
        page_size=page_size,
        page=page,
        domain=domain,
        vocabulary=vocabulary,
    )

    # Get the appropriate output based on the format
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = results.to_json()
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(results.to_list())
    else:
        output_data = results

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command(name="generate-set")
@click.argument("query")
@click.option(
    "--db-connection",
    required=True,
    envvar="OMOP_DB_CONNECTION",
    help="SQLAlchemy connection string for the OMOP database.",
)
@click.option(
    "--strategy",
    type=click.Choice(["fallback", "strict"]),
    default="fallback",
    help="Generation strategy.",
)
@click.option(
    "--no-descendants",
    is_flag=True,
    help="Do not include descendant concepts in the set.",
)
@click.pass_context
def generate_set(
    ctx: Any,
    query: str,
    db_connection: str,
    strategy: str,
    no_descendants: bool,
) -> None:
    """Generate a validated concept set for a given query."""

    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    click.echo(f"Generating concept set for '{query}'...")

    try:
        concept_set = asyncio.run(
            client.generate_concept_set(
                query=query,
                db_connection_string=db_connection,
                strategy=strategy,
                include_descendants=not no_descendants,
            )
        )

        _format_output(concept_set, ctx.obj["output"], ctx.obj.get("console"))

        metadata = concept_set.get("metadata", {})
        if metadata.get("status") == "SUCCESS":
            click.secho(
                f"\nSuccess! Found {len(concept_set.get('concept_ids', []))} concepts.",
                fg="green",
                err=True,
            )
            click.secho(f"Strategy used: {metadata.get('strategy_used')}", err=True)
            for warning in metadata.get("warnings", []):
                click.secho(f"Warning: {warning}", fg="yellow", err=True)
        else:
            click.secho(f"\nFailure: {metadata.get('reason')}", fg="red", err=True)

    except Exception as e:  # pragma: no cover - defensive
        click.secho(f"An unexpected error occurred: {e}", fg="red", err=True)
        sys.exit(1)


@cli.command()
@click.argument("concept_id", type=int)
@click.pass_context
def details(ctx: Any, concept_id: int) -> None:
    """Get detailed information for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.details(concept_id)
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.option("--relationship-id", help="Filter by relationship type")
@click.option(
    "--only-standard/--all", default=False, help="Only include standard concepts"
)
@click.pass_context
def relationships(
    ctx: Any,
    concept_id: int,
    relationship_id: Optional[str],
    only_standard: bool,
) -> None:
    """Get relationships for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.relationships(concept_id)
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.option("--depth", type=int, default=10, help="Maximum depth of relationships")
@click.option("--zoom-level", type=int, default=4, help="Zoom level for the graph")
@click.pass_context
def graph(ctx: Any, concept_id: int, depth: int, zoom_level: int) -> None:
    """Get relationship graph for a specific concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.graph(
        concept_id,
        depth=depth,
        zoom_level=zoom_level,
    )
    output_data: Any
    if ctx.obj["output"] == "json":
        output_data = result.model_dump_json(indent=2)
    elif ctx.obj["output"] == "yaml":
        import yaml

        output_data = yaml.dump(result.model_dump())
    else:
        output_data = result.model_dump()

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


@cli.command()
@click.argument("concept_id", type=int)
@click.pass_context
def summary(ctx: Any, concept_id: int) -> None:
    """Get a comprehensive summary for a concept."""
    client = _create_client(
        ctx.obj["base_url"], ctx.obj["token"], ctx.obj["timeout"], ctx.obj["retries"]
    )

    result = client.summary(concept_id)
    output_data: dict[str, Any] = {}
    for key in ["details", "relationships", "graph"]:
        val = result.get(key)
        if val is None:
            output_data[key] = {}
        elif isinstance(val, dict):
            output_data[key] = val
        elif hasattr(val, "model_dump"):
            output_data[key] = val.model_dump()
        else:
            output_data[key] = val

    _format_output(output_data, ctx.obj["output"], ctx.obj.get("console"))


def main() -> None:
    """Entry point for the CLI."""
    cli(obj={})  # pylint: disable=unexpected-keyword-arg


if __name__ == "__main__":
    main()

```

### File: `athena_client/build/lib/athena_client/client.py`
<a name="athena_client-build-lib-athena_client-clientpy"></a>
```python
"""
Main client for the Athena API.

This module provides the main client class for interacting with the Athena API.
"""

import logging
import time
from typing import Any, Dict, List, Literal, Optional, Tuple, Union

from .async_client import AthenaAsyncClient
from .db.base import DatabaseConnector
from .db.sqlalchemy_connector import SQLAlchemyConnector
from .exceptions import APIError, AthenaError
from .http import HttpClient
from .models import (
    ConceptDetails,
    ConceptRelationsGraph,
    ConceptRelationship,
    ConceptSearchResponse,
)
from .query import Q
from .search_result import SearchResult
from .settings import get_settings

logger = logging.getLogger(__name__)


class AthenaClient:
    """Main client for interacting with the Athena API."""

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        retry_delay: Optional[float] = None,
        enable_throttling: bool = True,
        throttle_delay_range: Tuple[float, float] = (0.1, 0.3),
        db_connector: Optional[DatabaseConnector] = None,
        **kwargs: Any,
    ) -> None:
        """Initialize the Athena client.

        Args:
            base_url: Base URL for the Athena API
            token: Authentication token
            timeout: Request timeout in seconds
            max_retries: Maximum number of retries for network errors
            retry_delay: Delay between retry attempts in seconds
                (overrides backoff_factor)
            enable_throttling: Whether to throttle requests to be respectful
                to the server
            throttle_delay_range: Range of delays for throttling (min, max)
                in seconds
            db_connector: Optional database connector for local OMOP validation
            **kwargs: Additional settings
        """
        s = get_settings()

        # Configure retry settings
        self.max_retries = max_retries or s.ATHENA_MAX_RETRIES
        self.retry_delay = retry_delay
        self.enable_throttling = enable_throttling
        self.throttle_delay_range = throttle_delay_range
        self._db_connector = db_connector

        # Create HTTP client with enhanced configuration
        self.http = HttpClient(
            base_url=base_url or s.ATHENA_BASE_URL,
            token=token or s.ATHENA_TOKEN,
            timeout=timeout or s.ATHENA_TIMEOUT_SECONDS,
            max_retries=self.max_retries,
            enable_throttling=self.enable_throttling,
            throttle_delay_range=self.throttle_delay_range,
            **kwargs,
        )

        logger.info(
            f"Athena client initialized: "
            f"max_retries={self.max_retries}, "
            f"retry_delay={self.retry_delay}, "
            f"throttling={'enabled' if self.enable_throttling else 'disabled'}"
        )

    def set_database_connector(self, connector: DatabaseConnector) -> None:
        """Set the database connector for this client."""

        self._db_connector = connector

    def validate_local_concepts(self, concept_ids: List[int]) -> List[int]:
        """Validate concept IDs against the configured local database."""

        if not self._db_connector:
            raise RuntimeError(
                "A database connector has not been configured. Use "
                "`set_database_connector()` to provide one."
            )

        return self._db_connector.validate_concepts(concept_ids)

    def search(
        self,
        query: Union[str, Q],
        page: int = 0,
        size: int = 20,
        auto_retry: bool = True,
        max_retries: Optional[int] = None,
        retry_delay: Optional[float] = None,
        show_progress: Optional[bool] = None,
        **kwargs: Any,
    ) -> SearchResult:
        """
        Search for concepts with automatic error handling and recovery.

        Args:
            query: Search query string or Query DSL object
            page: Page number (0-based)
            size: Page size
            auto_retry: Whether to automatically retry on recoverable errors
            max_retries: Override max retries for this call
            retry_delay: Override retry delay for this call
            show_progress: Whether to show progress for large queries
            **kwargs: Additional search parameters

        Returns:
            SearchResult object with concepts

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """

        from .exceptions import RetryFailedError
        from .settings import get_settings
        from .utils import (
            estimate_query_size,
            format_large_query_warning,
            get_operation_timeout,
            progress_context,
        )

        settings = get_settings()

        if isinstance(query, Q):
            query_str = str(query)
        else:
            query_str = query

        # Estimate query size and provide warnings for large queries
        estimated_size = estimate_query_size(query_str)
        warning = format_large_query_warning(query_str, estimated_size)
        if warning:
            print(warning)

        # Use settings default page size if not specified
        if size == 20 and "pageSize" not in kwargs:
            size = settings.ATHENA_DEFAULT_PAGE_SIZE

        # Validate page size
        if size > settings.ATHENA_MAX_PAGE_SIZE:
            raise ValueError(
                f"Page size {size} exceeds maximum allowed size of "
                f"{settings.ATHENA_MAX_PAGE_SIZE}. Please use a smaller page size."
            )

        # Convert page/size to pageSize/start parameters that the API expects
        page_size = size
        start = page * size  # Calculate start offset

        params = {
            "query": query_str,
            "pageSize": page_size,
            "start": start,
            **kwargs,
        }

        # Configure retry settings for this call
        max_attempts = max(
            1,
            max_retries
            if max_retries is not None
            else (self.max_retries if auto_retry else 1),
        )

        # Get appropriate timeout for this operation
        operation_timeout = get_operation_timeout("search", estimated_size)

        # Set up progress tracking if enabled
        progress_kwargs: Optional[Dict[str, Any]] = None
        if show_progress:
            progress_kwargs = {
                "total": estimated_size,
                "description": f"Searching for '{query_str}'",
                "show_progress": show_progress,
                "update_interval": settings.ATHENA_PROGRESS_UPDATE_INTERVAL,
            }

        retry_history: list[Exception] = []
        with progress_context(**progress_kwargs) if progress_kwargs else nullcontext():
            for attempt in range(max_attempts):
                try:
                    # Create a temporary HTTP client with the appropriate timeout
                    temp_http = HttpClient(
                        base_url=self.http.base_url,
                        token=str(self.http.session.headers.get("Authorization", "")),
                        timeout=operation_timeout,
                        max_retries=1,  # We handle retries manually
                        enable_throttling=self.http.enable_throttling,
                        throttle_delay_range=self.http.throttle_delay_range,
                    )

                    response = temp_http.get("/concepts", params=params)

                    # Raise APIError for any error response with errorMessage
                    # and errorCode
                    if (
                        isinstance(response, dict)
                        and response.get("result") is None
                        and "errorMessage" in response
                        and "errorCode" in response
                    ):
                        error_msg = response.get("errorMessage", "Unknown API error")
                        error_code = response.get("errorCode")

                        # Enhanced error messages for large queries
                        if "timeout" in error_msg.lower():
                            raise APIError(
                                f"Search timeout: The query '{query_str}' "
                                f"is taking too long to process. "
                                f"Try:\n"
                                f"‚Ä¢ Using more specific search terms\n"
                                f"‚Ä¢ Adding domain or vocabulary filters\n"
                                f"‚Ä¢ Reducing the page size\n"
                                f"‚Ä¢ Breaking the query into smaller parts",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Page size must not be less than one" in error_msg:
                            raise APIError(
                                f"Invalid page size: {error_msg}. "
                                f"Please use a page size of 1 or greater.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Page size must not be greater than" in error_msg:
                            raise APIError(
                                f"Page size too large: {error_msg}. "
                                f"Please reduce the page size to "
                                f"{settings.ATHENA_MAX_PAGE_SIZE} or less.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Query must not be blank" in error_msg:
                            raise APIError(
                                f"Empty search query: {error_msg}. "
                                f"Please provide a search term.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        else:
                            raise APIError(
                                f"Search failed: {error_msg}",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )

                    search_response = ConceptSearchResponse.model_validate(response)
                    return SearchResult(search_response, self)

                except Exception as e:
                    if isinstance(e, APIError):
                        # API errors are not retryable, raise immediately
                        raise

                    # For network errors, retry if we have attempts left
                    if attempt < max_attempts - 1:
                        logger.info(
                            f"Retrying search due to {type(e).__name__} "
                            f"(attempt {attempt + 1}/{max_attempts}): {e}"
                        )
                        if retry_delay is not None:
                            time.sleep(retry_delay)
                        elif self.retry_delay is not None:
                            time.sleep(self.retry_delay)
                        retry_history.append(e)
                        continue
                    else:
                        # Final attempt failed, raise with retry history
                        raise RetryFailedError(
                            f"Search failed after {max_attempts} attempts",
                            retry_history=retry_history,
                            max_attempts=max_attempts,
                            last_error=e,
                        ) from e
            raise RuntimeError("Unreachable code in search")

    def details(self, concept_id: int, auto_retry: bool = True) -> ConceptDetails:
        """
        Get detailed information about a concept with automatic error handling.

        Args:
            concept_id: Concept ID
            auto_retry: Whether to automatically retry on recoverable errors

        Returns:
            ConceptDetails object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        max_attempts = 3 if auto_retry else 1

        for attempt in range(max_attempts):
            try:
                response = self.http.get(f"/concepts/{concept_id}")

                # Check if the response is an error response
                if (
                    isinstance(response, dict)
                    and response.get("result") is None
                    and "errorMessage" in response
                ):
                    error_msg = response.get("errorMessage", "Unknown API error")
                    error_code = response.get("errorCode")

                    # Provide more specific error messages for concept details
                    if "Unable to find" in error_msg and "ConceptV5" in error_msg:
                        raise APIError(
                            f"Concept not found: Concept ID {concept_id} "
                            f"does not exist in the database. "
                            f"Please verify the concept ID is correct.",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )
                    else:
                        raise APIError(
                            f"Failed to get concept details: {error_msg}",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )

                return ConceptDetails.model_validate(response)

            except Exception as e:
                if isinstance(e, APIError):
                    # API errors are not retryable, raise immediately
                    raise
                elif attempt < max_attempts - 1:
                    # For other errors, retry if we have attempts left
                    logger.info(
                        f"Retrying concept details due to error "
                        f"(attempt {attempt + 1}/{max_attempts}): {e}"
                    )
                    continue
                else:
                    # Final attempt failed, raise with enhanced message
                    raise AthenaError(
                        f"Failed to get concept details after {max_attempts} attempts. "
                        f"Last error: {e}",
                        error_code="RETRY_FAILED",
                        troubleshooting=(
                            "‚Ä¢ Check your internet connection\n"
                            "‚Ä¢ Try again in a few moments\n"
                            "‚Ä¢ Contact support if the problem persists"
                        ),
                    ) from e
        raise RuntimeError("Unreachable code in details")

    def relationships(
        self, concept_id: int, auto_retry: bool = True
    ) -> ConceptRelationship:
        """
        Get relationships for a concept with automatic error handling.

        Args:
            concept_id: Concept ID
            auto_retry: Whether to automatically retry on recoverable errors

        Returns:
            ConceptRelationship object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        max_attempts = 3 if auto_retry else 1

        for attempt in range(max_attempts):
            try:
                response = self.http.get(f"/concepts/{concept_id}/relationships")

                # Check if the response is an error response
                if (
                    isinstance(response, dict)
                    and response.get("result") is None
                    and "errorMessage" in response
                ):
                    error_msg = response.get("errorMessage", "Unknown API error")
                    error_code = response.get("errorCode")

                    # Provide more specific error messages for relationships
                    if "Unable to find" in error_msg and "ConceptV5" in error_msg:
                        raise APIError(
                            f"Concept not found: Concept ID {concept_id} "
                            f"does not exist in the database. "
                            f"Please verify the concept ID is correct.",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )
                    else:
                        raise APIError(
                            f"Failed to get relationships: {error_msg}",
                            api_error_code=error_code,
                            api_message=error_msg,
                        )

                return ConceptRelationship.model_validate(response)

            except Exception as e:
                if isinstance(e, APIError):
                    # API errors are not retryable, raise immediately
                    raise
                elif attempt < max_attempts - 1:
                    # For other errors, retry if we have attempts left
                    logger.info(
                        f"Retrying relationships due to error "
                        f"(attempt {attempt + 1}/{max_attempts}): {e}"
                    )
                    continue
                else:
                    # Final attempt failed, raise with enhanced message
                    raise AthenaError(
                        f"Failed to get relationships after {max_attempts} attempts. "
                        f"Last error: {e}",
                        error_code="RETRY_FAILED",
                        troubleshooting=(
                            "‚Ä¢ Check your internet connection\n"
                            "‚Ä¢ Try again in a few moments\n"
                            "‚Ä¢ Contact support if the problem persists"
                        ),
                    ) from e
        raise RuntimeError("Unreachable code in relationships")

    def graph(
        self,
        concept_id: int,
        depth: int = 2,
        zoom_level: int = 2,
        auto_retry: bool = True,
        show_progress: Optional[bool] = None,
        **kwargs: Any,
    ) -> ConceptRelationsGraph:
        """
        Get concept relationship graph with automatic error handling.

        Args:
            concept_id: Concept ID
            depth: Graph depth
            zoom_level: Zoom level
            auto_retry: Whether to automatically retry on recoverable errors
            show_progress: Whether to show progress for large graph operations
            **kwargs: Additional parameters

        Returns:
            ConceptRelationsGraph object

        Note:
            This method includes automatic error handling and recovery.
            Network errors are automatically retried, and API errors provide
            clear, actionable messages without requiring try-catch blocks.
        """
        from .settings import get_settings
        from .utils import get_operation_timeout, progress_context

        settings = get_settings()

        # Estimate graph complexity based on depth and zoom level
        estimated_complexity = depth * zoom_level * 100  # Rough estimate

        # Provide warning for complex graphs
        if depth > 3 or zoom_level > 3:
            print(f"‚ö†Ô∏è  Complex graph request: depth={depth}, zoom_level={zoom_level}")
            print(
                "üí° This may take several minutes to complete. "
                "Consider reducing depth or zoom level."
            )

        params = {
            "depth": depth,
            "zoomLevel": zoom_level,
            **kwargs,
        }

        max_attempts = 3 if auto_retry else 1

        # Get appropriate timeout for graph operations
        operation_timeout = get_operation_timeout("graph", estimated_complexity)

        # Set up progress tracking if enabled
        progress_kwargs: Optional[Dict[str, Any]] = None
        if show_progress:
            progress_kwargs = {
                "total": estimated_complexity,
                "description": (
                    f"Building graph for concept {concept_id} "
                    f"(depth={depth}, zoom={zoom_level})"
                ),
                "show_progress": show_progress,
                "update_interval": settings.ATHENA_PROGRESS_UPDATE_INTERVAL,
            }

        with progress_context(**progress_kwargs) if progress_kwargs else nullcontext():
            for attempt in range(max_attempts):
                try:
                    # Create a temporary HTTP client with the appropriate timeout
                    temp_http = HttpClient(
                        base_url=self.http.base_url,
                        token=str(self.http.session.headers.get("Authorization", "")),
                        timeout=operation_timeout,
                        max_retries=1,  # We handle retries manually
                        enable_throttling=self.http.enable_throttling,
                        throttle_delay_range=self.http.throttle_delay_range,
                    )

                    response = temp_http.get(
                        f"/concepts/{concept_id}/relations", params=params
                    )

                    # Check if the response is an error response
                    if (
                        isinstance(response, dict)
                        and response.get("result") is None
                        and "errorMessage" in response
                    ):
                        error_msg = response.get("errorMessage", "Unknown API error")
                        error_code = response.get("errorCode")

                        # Enhanced error messages for graph operations
                        if "timeout" in error_msg.lower():
                            raise APIError(
                                f"Graph timeout: The graph for concept {concept_id} "
                                f"is too complex. "
                                f"Try:\n"
                                f"‚Ä¢ Reducing the depth (currently {depth})\n"
                                f"‚Ä¢ Reducing the zoom level (currently {zoom_level})\n"
                                f"‚Ä¢ Using a simpler concept as the starting point\n"
                                f"‚Ä¢ Breaking the request into smaller parts",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        elif "Unable to find" in error_msg and "ConceptV5" in error_msg:
                            raise APIError(
                                f"Concept not found: Concept ID {concept_id} "
                                f"does not exist in the database. "
                                f"Please verify the concept ID is correct.",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )
                        else:
                            raise APIError(
                                f"Failed to get concept graph: {error_msg}",
                                api_error_code=error_code,
                                api_message=error_msg,
                            )

                    return ConceptRelationsGraph.model_validate(response)

                except Exception as e:
                    if isinstance(e, APIError):
                        # API errors are not retryable, raise immediately
                        raise
                    elif attempt < max_attempts - 1:
                        # For other errors, retry if we have attempts left
                        logger.info(
                            f"Retrying graph due to error "
                            f"(attempt {attempt + 1}/{max_attempts}): {e}"
                        )
                        continue
                    else:
                        # Final attempt failed, raise with enhanced message
                        raise AthenaError(
                            f"Failed to get concept graph after {max_attempts} "
                            f"attempts. "
                            f"Last error: {e}",
                            error_code="RETRY_FAILED",
                            troubleshooting=(
                                "‚Ä¢ Check your internet connection\n"
                                "‚Ä¢ Try again in a few moments\n"
                                "‚Ä¢ Consider reducing graph depth or zoom level\n"
                                "‚Ä¢ Contact support if the problem persists"
                            ),
                        ) from e
            raise RuntimeError("Unreachable code in graph")

    def summary(
        self,
        concept_id: int,
        include_relationships: bool = True,
        include_graph: bool = True,
    ) -> Dict[str, Any]:
        """Get a comprehensive summary of a concept.

        Args:
            concept_id: Concept ID
            include_relationships: Whether to include relationships
            include_graph: Whether to include graph data

        Returns:
            Dictionary containing concept summary

        Raises:
            AthenaError: If any request fails
        """
        summary = {}

        # Get basic details
        try:
            details = self.details(concept_id)
            summary["details"] = details.model_dump()
        except Exception as e:
            summary["details"] = {"error": str(e)}

        # Get relationships if requested
        if include_relationships:
            try:
                relationships = self.relationships(concept_id)
                summary["relationships"] = relationships.model_dump()
            except Exception as e:
                summary["relationships"] = {"error": str(e)}

        # Get graph if requested
        if include_graph:
            try:
                graph = self.graph(concept_id)
                summary["graph"] = graph.model_dump()
            except Exception as e:
                summary["graph"] = {"error": str(e)}

        return summary

    async def generate_concept_set(
        self,
        query: str,
        db_connection_string: str,
        strategy: str = "fallback",
        include_descendants: bool = True,
        confidence_threshold: float = 0.7,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Generate a validated concept set using the async client."""

        async_client = AthenaAsyncClient(
            base_url=self.http.base_url,
            token=str(self.http.session.headers.get("Authorization", "")),
        )

        db_connector = SQLAlchemyConnector.from_connection_string(db_connection_string)
        async_client.set_database_connector(db_connector)

        return await async_client.generate_concept_set(
            query,
            strategy=strategy,
            include_descendants=include_descendants,
            confidence_threshold=confidence_threshold,
            **kwargs,
        )


class Athena(AthenaClient):
    """Alias for AthenaClient for backward compatibility."""

    pass


class nullcontext:
    """Context manager that does nothing."""

    def __enter__(self) -> None:
        return None

    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> Literal[False]:
        return False

```

### File: `athena_client/build/lib/athena_client/concept_explorer.py`
<a name="athena_client-build-lib-athena_client-concept_explorerpy"></a>
```python
"""
Advanced concept exploration and mapping utilities.

This module provides tools to help find standard concepts that might not appear
directly in search results, including:
- Concept relationship exploration
- Synonym-based concept discovery
- Vocabulary mapping and cross-references
- Standard concept identification
- Concept hierarchy exploration
"""

import asyncio
import logging
from collections import deque
from dataclasses import dataclass, field
from typing import Any, Deque, Dict, List, Optional, Set, Union

from .models import Concept, ConceptDetails

logger = logging.getLogger(__name__)


@dataclass
class ExplorationState:
    """
    Internal state management for concept exploration runs.

    This dataclass manages the state of a single exploration run to avoid
    passing multiple state variables through method calls.
    """

    queue: Deque[Any] = field(
        default_factory=deque
    )  # BFS queue: (concept, depth, path)
    visited_ids: Set[int] = field(default_factory=set)  # Set of processed concept IDs
    cache: Dict[int, ConceptDetails] = field(
        default_factory=dict
    )  # In-memory cache for concept details
    results: Dict[str, Any] = field(
        default_factory=lambda: {
            "direct_matches": [],
            "synonym_matches": [],
            "relationship_matches": [],
            "cross_references": [],
            "exploration_paths": [],
        }
    )  # Final results structure
    api_call_count: int = 0  # Count of API calls made
    start_time: float = 0  # Start time of exploration
    max_total_concepts: int = 0  # Maximum total concepts to discover
    max_api_calls: int = 0  # Maximum API calls to make
    max_time_seconds: int = 0  # Maximum time to run exploration

    def __post_init__(self) -> None:
        """Initialize default values for dataclass fields."""
        pass  # All defaults handled by field()


class ConceptExplorer:
    """
    Advanced concept exploration and mapping utilities.

    This class provides methods to help discover standard concepts that might
    not appear directly in search results by exploring relationships, synonyms,
    and cross-references using an optimized BFS algorithm with concurrent processing.
    """

    def __init__(self, client: Any) -> None:
        """Initialize the concept explorer with an Athena client.

        Args:
            client: Athena client instance (can be sync or async)
        """
        self.client = client

    async def find_standard_concepts(
        self,
        query: str,
        max_exploration_depth: int = 2,
        initial_seed_limit: int = 10,  # New parameter per FSD
        include_synonyms: bool = True,
        include_relationships: bool = True,
        vocabulary_priority: Optional[List[str]] = None,
        max_total_concepts: int = 100,  # Limit total concepts found
        max_api_calls: int = 50,  # Limit total API calls
        max_time_seconds: int = 30,  # Limit total execution time
    ) -> Dict[str, Any]:
        """
        Find standard concepts related to a query through exploration.

        This method implements a BFS-based exploration algorithm with concurrent
        batch processing for optimal performance.

        Args:
            query: The search query
            max_exploration_depth: Maximum depth to explore relationships
            initial_seed_limit: Maximum number of top search results to use as seeds
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
            vocabulary_priority: Preferred vocabularies (e.g., ['SNOMED', 'RxNorm'])
            max_total_concepts: Maximum total concepts to discover
            max_api_calls: Maximum API calls to make
            max_time_seconds: Maximum time to run exploration

        Returns:
            Dictionary containing standard concepts found through exploration
        """
        # Validate parameters
        if max_exploration_depth < 0:
            raise ValueError("max_exploration_depth must be non-negative")
        if initial_seed_limit < 1:
            raise ValueError("initial_seed_limit must be at least 1")
        if max_total_concepts < 1:
            raise ValueError("max_total_concepts must be at least 1")
        if max_api_calls < 1:
            raise ValueError("max_api_calls must be at least 1")
        if max_time_seconds < 1:
            raise ValueError("max_time_seconds must be at least 1")

        # Initialize exploration state with limits
        state = ExplorationState()
        state.api_call_count = 0
        state.start_time = asyncio.get_event_loop().time()
        state.max_total_concepts = max_total_concepts
        state.max_api_calls = max_api_calls
        state.max_time_seconds = max_time_seconds

        # Step 1: Initial search and seeding
        logger.info(f"Performing direct search for: {query}")
        direct_results = await self.client.search(query, size=50)
        state.api_call_count += 1
        all_direct_matches = direct_results.all()
        state.results["direct_matches"] = all_direct_matches

        # Take top initial_seed_limit results as seeds
        seed_concepts = all_direct_matches[:initial_seed_limit]
        logger.info(f"Using {len(seed_concepts)} concepts as exploration seeds")

        # Add seed concepts to queue and mark as visited
        for concept in seed_concepts:
            state.queue.append((concept, 0, [concept.id]))
            state.visited_ids.add(concept.id)

        # Step 2: Main BFS traversal loop
        await self._bfs_exploration_loop(
            state,
            max_exploration_depth,
            include_synonyms,
            include_relationships,
            vocabulary_priority,
        )

        # Step 3: Find cross-references (with limits)
        if state.api_call_count < state.max_api_calls:
            logger.info("Finding cross-references")
            cross_refs = await self._find_cross_references(
                all_direct_matches, vocabulary_priority, state
            )
            state.results["cross_references"] = cross_refs

        # Add exploration statistics
        elapsed_time = asyncio.get_event_loop().time() - state.start_time
        state.results["exploration_stats"] = {
            "total_concepts_found": len(state.visited_ids),
            "api_calls_made": state.api_call_count,
            "time_elapsed_seconds": elapsed_time,
            "limits_reached": {
                "max_concepts": len(state.visited_ids) >= max_total_concepts,
                "max_api_calls": state.api_call_count >= max_api_calls,
                "max_time": elapsed_time >= max_time_seconds,
            },
        }

        return state.results

    async def _bfs_exploration_loop(
        self,
        state: ExplorationState,
        max_exploration_depth: int,
        include_synonyms: bool,
        include_relationships: bool,
        vocabulary_priority: Optional[List[str]] = None,
    ) -> None:
        """
        Main BFS exploration loop with concurrent batch processing.

        Args:
            state: Exploration state object
            max_exploration_depth: Maximum exploration depth
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
            vocabulary_priority: Preferred vocabularies
        """
        while state.queue:
            # Check limits before processing
            current_time = asyncio.get_event_loop().time()
            elapsed_time = current_time - state.start_time

            # Check if we've hit any limits
            if (
                len(state.visited_ids) >= state.max_total_concepts
                or state.api_call_count >= state.max_api_calls
                or elapsed_time >= state.max_time_seconds
            ):
                logger.info("Exploration stopped due to limits:")
                logger.info(
                    f"  - Concepts found: {len(state.visited_ids)}/"
                    f"{state.max_total_concepts}"
                )
                logger.info(
                    f"  - API calls made: {state.api_call_count}/{state.max_api_calls}"
                )
                logger.info(
                    f"  - Time elapsed: {elapsed_time:.1f}s/{state.max_time_seconds}s"
                )
                break

            # Process all nodes at current depth level
            level_size = len(state.queue)
            ids_to_fetch_details: Set[int] = set()

            logger.info(f"Processing {level_size} concepts at current depth level")

            # Process all nodes at current depth
            for _ in range(level_size):
                # Check limits again in case we've hit them during processing
                if (
                    len(state.visited_ids) >= state.max_total_concepts
                    or state.api_call_count >= state.max_api_calls
                    or asyncio.get_event_loop().time() - state.start_time
                    >= state.max_time_seconds
                ):
                    break

                concept, depth, path = state.queue.popleft()

                # Skip if we've reached max depth
                if depth >= max_exploration_depth:
                    continue

                # Discover neighbors (synonyms and relationships)
                await self._discover_neighbors(
                    concept,
                    depth,
                    path,
                    state,
                    ids_to_fetch_details,
                    include_synonyms,
                    include_relationships,
                )

            # Batch fetch details for all discovered concepts
            if ids_to_fetch_details and state.api_call_count < state.max_api_calls:
                await self._process_batch_results(
                    ids_to_fetch_details, state, depth + 1, vocabulary_priority
                )

    async def _discover_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
        include_synonyms: bool,
        include_relationships: bool,
    ) -> None:
        """
        Discover neighboring concepts through synonyms and relationships.

        Args:
            concept: Current concept being explored
            depth: Current exploration depth
            path: Path taken to reach this concept
            state: Exploration state
            ids_to_fetch_details: Set to collect IDs for batch fetching
            include_synonyms: Whether to explore synonyms
            include_relationships: Whether to explore relationships
        """
        # Explore synonyms if enabled
        if include_synonyms:
            await self._discover_synonym_neighbors(
                concept, depth, path, state, ids_to_fetch_details
            )

        # Explore relationships if enabled
        if include_relationships:
            await self._discover_relationship_neighbors(
                concept, depth, path, state, ids_to_fetch_details
            )

    async def _discover_synonym_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
    ) -> None:
        """Discover neighboring concepts through synonyms."""
        if concept.standardConcept == "Standard":
            # For standard concepts, search for synonyms
            try:
                # Check API call limit
                if state.api_call_count >= state.max_api_calls:
                    return

                synonym_results = await self.client.search(concept.name, size=10)
                state.api_call_count += 1

                for synonym_concept in synonym_results.all():
                    if (
                        synonym_concept.id not in state.visited_ids
                        and len(state.visited_ids) < state.max_total_concepts
                    ):
                        ids_to_fetch_details.add(synonym_concept.id)

            except Exception as e:
                logger.warning(
                    f"Could not generate suggestions for query '{concept.name}': {e}"
                )

    async def _discover_relationship_neighbors(
        self,
        concept: Concept,
        depth: int,
        path: List[int],
        state: ExplorationState,
        ids_to_fetch_details: Set[int],
    ) -> None:
        """Discover neighboring concepts through relationships."""
        try:
            # Check API call limit
            if state.api_call_count >= state.max_api_calls:
                return

            relationships = await self.client.relationships(
                concept.id, only_standard=True
            )
            state.api_call_count += 1

            for group in relationships.items:
                for rel in group.relationships:
                    if (
                        rel.targetConceptId not in state.visited_ids
                        and len(state.visited_ids) < state.max_total_concepts
                    ):
                        ids_to_fetch_details.add(rel.targetConceptId)

        except Exception as e:
            logger.warning(f"Could not get relationships for concept {concept.id}: {e}")

    async def _process_batch_results(
        self,
        ids_to_fetch_details: Set[int],
        state: ExplorationState,
        next_depth: int,
        vocabulary_priority: Optional[List[str]] = None,
    ) -> None:
        """Process batch results and add to queue."""
        if not ids_to_fetch_details:
            return

        # Check API call limit
        if state.api_call_count >= state.max_api_calls:
            return

        try:
            # Batch fetch concept details
            concept_details_list = await self._get_details_batch_async(
                ids_to_fetch_details
            )
            state.api_call_count += 1

            # Process each concept detail
            for concept_details in concept_details_list:
                if isinstance(concept_details, BaseException):
                    continue

                # Now we know it's a ConceptDetails object
                concept_details_obj = concept_details  # type: ConceptDetails

                # Convert to Concept object
                concept = Concept(
                    id=concept_details_obj.id,
                    name=concept_details_obj.name,
                    domain=concept_details_obj.domainId,
                    vocabulary=concept_details_obj.vocabularyId,
                    className=concept_details_obj.conceptClassId,
                    standardConcept=concept_details_obj.standardConcept,
                    code=concept_details_obj.conceptCode,
                    invalidReason=concept_details_obj.invalidReason,
                    score=None,  # No score available from concept details
                )

                # Add to appropriate result category
                if concept.standardConcept == "Standard":
                    if concept not in state.results["synonym_matches"]:
                        state.results["synonym_matches"].append(concept)
                else:
                    if concept not in state.results["relationship_matches"]:
                        state.results["relationship_matches"].append(concept)

                # Add to queue for further exploration if within limits
                if (
                    len(state.visited_ids) < state.max_total_concepts
                    and concept.id not in state.visited_ids
                ):
                    # Create a simple path for this concept
                    new_path = [concept.id]
                    state.queue.append((concept, next_depth, new_path))
                    state.visited_ids.add(concept.id)

        except Exception as e:
            logger.warning(f"Error processing batch results: {e}")

    async def _get_details_batch_async(
        self, concept_ids: Set[int]
    ) -> List[Union[ConceptDetails, BaseException]]:
        """
        Fetch concept details for multiple IDs concurrently.

        Args:
            concept_ids: Set of concept IDs to fetch details for

        Returns:
            List of ConceptDetails objects or Exception objects for failed requests
        """
        if not (
            hasattr(self.client, "get_concept_details")
            and asyncio.iscoroutinefunction(self.client.get_concept_details)
        ):
            raise NotImplementedError("Async client not available")

        # Create tasks for concurrent execution
        tasks = [
            self.client.get_concept_details(concept_id) for concept_id in concept_ids
        ]

        # Execute all tasks concurrently with exception handling
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results

    def _extract_standard_concepts(
        self, concepts: List[Concept], vocabulary_priority: Optional[List[str]] = None
    ) -> List[Concept]:
        """Extract standard concepts from a list of concepts."""
        standard_concepts = []

        for concept in concepts:
            if concept.standardConcept == "Standard":
                standard_concepts.append(concept)

        # Sort by vocabulary priority if specified
        if vocabulary_priority:

            def sort_key(concept: Concept) -> int:
                try:
                    return vocabulary_priority.index(concept.vocabulary)
                except ValueError:
                    return len(vocabulary_priority)

            standard_concepts.sort(key=sort_key)

        return standard_concepts

    async def _find_cross_references(
        self,
        concepts: List[Concept],
        vocabulary_priority: Optional[List[str]] = None,
        state: Optional[ExplorationState] = None,
    ) -> List[Dict[str, Any]]:
        """Find cross-references between concepts."""
        cross_refs = []

        for concept in concepts:
            if concept.standardConcept == "Standard":
                # Look for related concepts in other vocabularies
                try:
                    # Check API call limit
                    if state and state.api_call_count >= state.max_api_calls:
                        break

                    relationships = await self.client.relationships(
                        concept.id, only_standard=True
                    )
                    if state:
                        state.api_call_count += 1

                    for group in relationships.items:
                        for rel in group.relationships:
                            cross_ref = {
                                "source_concept": concept,
                                "target_concept_id": rel.targetConceptId,
                                "target_concept_name": rel.targetConceptName,
                                "relationship_type": rel.relationshipName,
                                "vocabulary": rel.targetVocabularyId,
                            }
                            cross_refs.append(cross_ref)

                except Exception as e:
                    logger.warning(
                        f"Could not get relationships for concept {concept.id}: {e}"
                    )

        return cross_refs

    async def map_to_standard_concepts(
        self,
        query: str,
        target_vocabularies: Optional[List[str]] = None,
        confidence_threshold: float = 0.5,
    ) -> List[Dict[str, Any]]:
        """
        Map a query to standard concepts with confidence scores.

        This method is now async to support the new async find_standard_concepts.

        Args:
            query: The search query
            target_vocabularies: Preferred target vocabularies
            confidence_threshold: Minimum confidence score for inclusion

        Returns:
            List of mapping results with confidence scores
        """
        # Get exploration results
        exploration_results = await self.find_standard_concepts(query)

        # Collect all standard concepts
        all_standard_concepts = []
        all_standard_concepts.extend(exploration_results["direct_matches"])
        all_standard_concepts.extend(exploration_results["synonym_matches"])
        all_standard_concepts.extend(exploration_results["relationship_matches"])

        # Filter by target vocabularies if specified
        if target_vocabularies:
            all_standard_concepts = [
                concept
                for concept in all_standard_concepts
                if concept.vocabulary in target_vocabularies
            ]

        # Calculate confidence scores and create mappings
        mappings = []
        for concept in all_standard_concepts:
            confidence = self._calculate_mapping_confidence(
                query, concept, exploration_results
            )

            if confidence >= confidence_threshold:
                mapping = {
                    "concept": concept,
                    "confidence": confidence,
                    "exploration_path": self._get_exploration_path(
                        concept, exploration_results
                    ),
                    "source_category": self._get_source_category(
                        concept, exploration_results
                    ),
                }
                mappings.append(mapping)

        # Sort by confidence score (descending)
        mappings.sort(key=lambda x: x["confidence"], reverse=True)

        return mappings

    def _calculate_mapping_confidence(
        self, query: str, concept: Concept, exploration_results: Dict[str, Any]
    ) -> float:
        """Calculate confidence score for a concept mapping."""
        confidence = 0.0

        # Base confidence from search score if available
        if concept.score is not None:
            confidence += concept.score * 0.4

        # Boost for direct matches
        if concept in exploration_results["direct_matches"]:
            confidence += 0.3

        # Boost for synonym matches
        if concept in exploration_results["synonym_matches"]:
            confidence += 0.2

        # Boost for relationship matches
        if concept in exploration_results["relationship_matches"]:
            confidence += 0.1

        # Vocabulary preference boost
        if concept.vocabulary in ["SNOMED", "RxNorm"]:
            confidence += 0.1

        return min(confidence, 1.0)

    def _get_exploration_path(
        self, concept: Concept, exploration_results: Dict[str, Any]
    ) -> str:
        """Get the exploration path that led to this concept."""
        if concept in exploration_results["direct_matches"]:
            return "direct_search"
        elif concept in exploration_results["synonym_matches"]:
            return "synonym_exploration"
        elif concept in exploration_results["relationship_matches"]:
            return "relationship_exploration"
        else:
            return "unknown"

    def _get_source_category(
        self, concept: Concept, exploration_results: Dict[str, Any]
    ) -> str:
        """Get the source category for a concept."""
        if concept in exploration_results["direct_matches"]:
            return "direct_match"
        elif concept in exploration_results["synonym_matches"]:
            return "synonym_match"
        elif concept in exploration_results["relationship_matches"]:
            return "relationship_match"
        else:
            return "unknown"

    async def suggest_alternative_queries(
        self, query: str, max_suggestions: int = 5
    ) -> List[str]:
        """
        Suggest alternative queries based on the original query.

        Args:
            query: The original query
            max_suggestions: Maximum number of suggestions to return

        Returns:
            List of alternative query suggestions
        """
        suggestions = []

        # Basic query variations
        base_suggestions = [
            query.lower(),
            query.title(),
            query.upper(),
            f"{query}*",  # Wildcard
            f"*{query}*",  # Contains
        ]

        # Add base suggestions
        suggestions.extend(base_suggestions)

        # Try to find related concepts for more suggestions
        try:
            results = await self.client.search(query, size=10)
            for concept in results.all():
                if concept.name.lower() != query.lower():
                    suggestions.append(concept.name)
        except Exception as e:
            logger.warning(f"Could not generate suggestions for query '{query}': {e}")

        # Remove duplicates and limit results
        unique_suggestions = list(dict.fromkeys(suggestions))
        return unique_suggestions[:max_suggestions]

    async def get_concept_hierarchy(
        self, concept_id: int, max_depth: int = 3
    ) -> Dict[str, Any]:
        """
        Get the concept hierarchy for a given concept.

        Args:
            concept_id: The concept ID
            max_depth: Maximum depth to explore

        Returns:
            Dictionary containing hierarchy information
        """
        hierarchy: Dict[str, Any] = {
            "root_concept": None,
            "parents": [],
            "children": [],
            "siblings": [],
            "depth": 0,
        }

        try:
            # Get root concept details
            root_details = await self.client.details(concept_id)
            hierarchy["root_concept"] = root_details

            # Initialize typed lists
            parents: List[ConceptDetails] = []
            children: List[ConceptDetails] = []

            # Get relationships
            relationships = await self.client.relationships(
                concept_id, only_standard=True
            )

            for group in relationships.items:
                if group.relationshipName.lower() in ["is a", "isa", "subclass of"]:
                    # Parent relationships
                    for rel in group.relationships:
                        try:
                            parent_details = await self.client.details(
                                rel.targetConceptId
                            )
                            parents.append(parent_details)
                        except Exception as e:
                            logger.warning(
                                f"Could not fetch parent concept "
                                f"{rel.targetConceptId}: {e}"
                            )

                elif group.relationshipName.lower() in ["has subclass", "has subtype"]:
                    # Child relationships
                    for rel in group.relationships:
                        try:
                            child_details = await self.client.details(
                                rel.targetConceptId
                            )
                            children.append(child_details)
                        except Exception as e:
                            logger.warning(
                                f"Could not fetch child concept "
                                f"{rel.targetConceptId}: {e}"
                            )

            # Update hierarchy with typed lists
            hierarchy["parents"] = parents
            hierarchy["children"] = children
            hierarchy["depth"] = len(parents)

        except Exception as e:
            logger.error(f"Could not get hierarchy for concept {concept_id}: {e}")

        return hierarchy


def create_concept_explorer(client: Any) -> ConceptExplorer:
    """
    Create a ConceptExplorer instance with the given client.

    Args:
        client: Athena client instance

    Returns:
        ConceptExplorer instance
    """
    return ConceptExplorer(client)

```

### File: `athena_client/build/lib/athena_client/concept_set.py`
<a name="athena_client-build-lib-athena_client-concept_setpy"></a>
```python
import logging
from typing import Any, Dict, List, Optional

from .concept_explorer import ConceptExplorer
from .db.base import DatabaseConnector

logger = logging.getLogger(__name__)


class ConceptSetGenerator:
    """Orchestrate concept set generation from a search query."""

    def __init__(self, explorer: ConceptExplorer, db: DatabaseConnector) -> None:
        self.explorer = explorer
        self.db = db

    async def create_from_query(
        self,
        query: str,
        strategy: str = "fallback",
        include_descendants: bool = True,
        confidence_threshold: float = 0.7,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Generate a concept set using a tiered standard-first strategy."""
        logger.info(
            "Attempting to find and validate standard concepts for query: '%s'",
            query,
        )
        mappings = await self.explorer.map_to_standard_concepts(
            query, confidence_threshold=confidence_threshold, **kwargs
        )

        from .models import ConceptType

        standard_concepts = [
            m["concept"]
            for m in mappings
            if m["concept"].standardConcept == ConceptType.STANDARD
        ]

        if standard_concepts:
            candidate_ids = [c.id for c in standard_concepts]
            validated_ids = self.db.validate_concepts(candidate_ids)

            if validated_ids:
                warnings: List[str] = []
                final_ids = set(validated_ids)
                if include_descendants:
                    desc_ids = self.db.get_descendants(validated_ids)
                    if not desc_ids:
                        warnings.append(
                            (
                                f"Standard concepts {validated_ids} found but "
                                "have no descendants in the local vocabulary."
                            )
                        )
                    else:
                        final_ids.update(desc_ids)

                return self._build_success_response(
                    query=query,
                    strategy_used="Tier 1: Direct Standard Concept",
                    concept_ids=list(final_ids),
                    seed_concepts=validated_ids,
                    warnings=warnings,
                )

        if strategy == "strict":
            return self._build_failure_response(
                query,
                (
                    "No standard concepts from the API could be validated in "
                    "'strict' mode."
                ),
            )

        non_standard_concepts = [
            m["concept"]
            for m in mappings
            if m["concept"].standardConcept != ConceptType.STANDARD
        ]

        if non_standard_concepts:
            local_mappings = self.db.get_standard_mapping(
                [c.id for c in non_standard_concepts]
            )
            if local_mappings:
                mapped_standard_id = list(local_mappings.values())[0]
                validated_ids = self.db.validate_concepts([mapped_standard_id])
                if validated_ids:
                    final_ids = set(validated_ids)
                    if include_descendants:
                        final_ids.update(self.db.get_descendants(validated_ids))
                    original_non_standard = list(local_mappings.keys())[0]
                    warning = (
                        "Initial standard concepts not found locally. "
                        "Recovered by mapping non-standard concept "
                        f"{original_non_standard} "
                        f"to standard concept {mapped_standard_id}."
                    )
                    return self._build_success_response(
                        query=query,
                        strategy_used="Tier 3: Recovery via Local Mapping",
                        concept_ids=list(final_ids),
                        seed_concepts=validated_ids,
                        warnings=[warning],
                    )

        return self._build_failure_response(
            query,
            (
                "No standard concepts from the API could be validated against "
                "the local database, and no recovery paths were found."
            ),
        )

    def _build_success_response(
        self,
        query: str,
        strategy_used: str,
        concept_ids: List[int],
        seed_concepts: List[int],
        warnings: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        return {
            "name": f"Concept Set for '{query}'",
            "concept_ids": concept_ids,
            "metadata": {
                "status": "SUCCESS",
                "strategy_used": strategy_used,
                "source_query": query,
                "seed_concepts": seed_concepts,
                "warnings": warnings or [],
            },
        }

    def _build_failure_response(self, query: str, reason: str) -> Dict[str, Any]:
        return {
            "name": f"Failed Concept Set for '{query}'",
            "concept_ids": [],
            "metadata": {
                "status": "FAILURE",
                "source_query": query,
                "reason": reason,
                "suggestions": [
                    "Try a different search term.",
                    "Lower the `confidence_threshold`.",
                    "Check if your local vocabulary version is up to date.",
                ],
            },
        }

```

### File: `athena_client/build/lib/athena_client/exceptions.py`
<a name="athena_client-build-lib-athena_client-exceptionspy"></a>
```python
"""
Exception classes for the Athena client.

This module defines a hierarchy of exceptions that can be raised by the Athena client.
"""

from typing import List, Optional


class AthenaError(Exception):
    """Base class for all Athena client exceptions."""

    def __init__(
        self,
        message: str,
        error_code: Optional[str] = None,
        troubleshooting: Optional[str] = None,
    ) -> None:
        """
        Initialize the exception.

        Args:
            message: Error message
            error_code: Optional error code for programmatic handling
            troubleshooting: Optional troubleshooting suggestions
        """
        super().__init__(message)
        self.message = message
        self.error_code = error_code
        self.troubleshooting = troubleshooting

    def __str__(self) -> str:
        """Return a user-friendly error message."""
        msg = self.message
        if self.troubleshooting:
            msg += f"\n\nüí° Troubleshooting: {self.troubleshooting}"
        return msg


class NetworkError(AthenaError):
    """
    Raised for network-related errors (DNS, TLS, socket, or timeout).
    """

    def __init__(self, message: str, url: Optional[str] = None) -> None:
        """
        Initialize the network error.

        Args:
            message: Error message
            url: URL that failed to connect
        """
        troubleshooting = (
            "‚Ä¢ Check your internet connection\n"
            "‚Ä¢ Verify the API endpoint URL is correct\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Contact your network administrator if the problem persists"
        )
        super().__init__(
            message, error_code="NETWORK_ERROR", troubleshooting=troubleshooting
        )
        self.url = url


class TimeoutError(NetworkError):
    """
    Raised when a request times out.
    """

    def __init__(
        self, message: str, url: Optional[str] = None, timeout: Optional[float] = None
    ) -> None:
        """
        Initialize the timeout error.

        Args:
            message: Error message
            url: URL that timed out
            timeout: Timeout value that was exceeded
        """
        troubleshooting = (
            "‚Ä¢ The server is taking too long to respond\n"
            "‚Ä¢ Try increasing the timeout value\n"
            "‚Ä¢ Check if the API server is experiencing high load\n"
            "‚Ä¢ Try again in a few moments"
        )
        super().__init__(message, url)
        self.timeout = timeout
        self.troubleshooting = troubleshooting


class ServerError(AthenaError):
    """
    Raised when the server returns a 5xx status code.
    """

    def __init__(
        self,
        message: str,
        status_code: int,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the server error.

        Args:
            message: Error message
            status_code: HTTP status code
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ The API server is experiencing issues\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Check the API status page for known issues\n"
            "‚Ä¢ Contact the API administrators if the problem persists"
        )
        super().__init__(
            message, error_code="SERVER_ERROR", troubleshooting=troubleshooting
        )
        self.status_code = status_code
        self.response = response
        self.url = url


class ClientError(AthenaError):
    """
    Raised when the server returns a 4xx status code.
    """

    def __init__(
        self,
        message: str,
        status_code: int,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the client error.

        Args:
            message: Error message
            status_code: HTTP status code
            response: Raw response body
            url: URL that caused the error
        """
        # Customize troubleshooting based on status code
        if status_code == 400:
            troubleshooting = (
                "‚Ä¢ Check your request parameters\n"
                "‚Ä¢ Verify the data format is correct\n"
                "‚Ä¢ Review the API documentation for the correct format"
            )
        elif status_code == 401:
            troubleshooting = (
                "‚Ä¢ Check your authentication credentials\n"
                "‚Ä¢ Verify your API token is valid and not expired\n"
                "‚Ä¢ Ensure you have the necessary permissions"
            )
        elif status_code == 403:
            troubleshooting = (
                "‚Ä¢ You don't have permission to access this resource\n"
                "‚Ä¢ Check your API token permissions\n"
                "‚Ä¢ Contact the API administrators for access"
            )
        elif status_code == 404:
            troubleshooting = (
                "‚Ä¢ The requested resource was not found\n"
                "‚Ä¢ Check the URL path is correct\n"
                "‚Ä¢ Verify the resource ID exists\n"
                "‚Ä¢ Review the API documentation for available endpoints"
            )
        elif status_code == 429:
            troubleshooting = (
                "‚Ä¢ You've exceeded the rate limit\n"
                "‚Ä¢ Wait before making more requests\n"
                "‚Ä¢ Consider implementing request throttling\n"
                "‚Ä¢ Check the API documentation for rate limits"
            )
        else:
            troubleshooting = (
                "‚Ä¢ Check your request parameters\n"
                "‚Ä¢ Review the API documentation\n"
                "‚Ä¢ Verify your authentication credentials"
            )

        super().__init__(
            message, error_code="CLIENT_ERROR", troubleshooting=troubleshooting
        )
        self.status_code = status_code
        self.response = response
        self.url = url


class ValidationError(AthenaError):
    """
    Raised when response validation fails.
    """

    def __init__(self, message: str, validation_details: Optional[str] = None) -> None:
        """
        Initialize the validation error.

        Args:
            message: Error message
            validation_details: Detailed validation error information
        """
        troubleshooting = (
            "‚Ä¢ The API response format has changed\n"
            "‚Ä¢ This might be a temporary API issue\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Contact the API administrators if the problem persists"
        )
        super().__init__(
            message, error_code="VALIDATION_ERROR", troubleshooting=troubleshooting
        )
        self.validation_details = validation_details


class AuthenticationError(ClientError):
    """
    Raised for authentication-related errors.
    """

    def __init__(
        self,
        message: str,
        status_code: int = 401,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the authentication error.

        Args:
            message: Error message
            status_code: HTTP status code (default 401)
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ Check your API token is valid and not expired\n"
            "‚Ä¢ Verify your authentication credentials\n"
            "‚Ä¢ Ensure you have the necessary permissions\n"
            "‚Ä¢ Contact the API administrators for access"
        )
        super().__init__(message, status_code, response, url)
        self.error_code = "AUTHENTICATION_ERROR"
        self.troubleshooting = troubleshooting


class RateLimitError(ClientError):
    """
    Raised when rate limits are exceeded.
    """

    def __init__(
        self,
        message: str,
        status_code: int = 429,
        response: Optional[str] = None,
        url: Optional[str] = None,
    ) -> None:
        """
        Initialize the rate limit error.

        Args:
            message: Error message
            status_code: HTTP status code (default 429)
            response: Raw response body
            url: URL that caused the error
        """
        troubleshooting = (
            "‚Ä¢ You've exceeded the API rate limit\n"
            "‚Ä¢ Wait before making more requests\n"
            "‚Ä¢ Consider implementing request throttling\n"
            "‚Ä¢ Check the API documentation for rate limits"
        )
        super().__init__(message, status_code, response, url)
        self.error_code = "RATE_LIMIT_ERROR"
        self.troubleshooting = troubleshooting


class APIError(AthenaError):
    """
    Raised when the API returns an error response.
    """

    def __init__(
        self,
        message: str,
        api_error_code: Optional[str] = None,
        api_message: Optional[str] = None,
    ) -> None:
        """
        Initialize the API error.

        Args:
            message: Error message
            api_error_code: Error code from the API
            api_message: Error message from the API
        """
        troubleshooting = (
            "‚Ä¢ The API returned an error response\n"
            "‚Ä¢ Check the API error details above\n"
            "‚Ä¢ Verify your request parameters\n"
            "‚Ä¢ Try again with different parameters if applicable"
        )
        super().__init__(
            message, error_code="API_ERROR", troubleshooting=troubleshooting
        )
        self.api_error_code = api_error_code
        self.api_message = api_message


class RetryFailedError(AthenaError):
    """
    Raised when all retry attempts have been exhausted.
    """

    def __init__(
        self,
        message: str,
        max_attempts: int,
        last_error: Exception,
        retry_history: List[Exception],
        error_code: Optional[str] = None,
    ) -> None:
        """
        Initialize the retry failed error.

        Args:
            message: Error message
            max_attempts: Maximum number of retry attempts
            last_error: The last error that caused the final failure
            retry_history: List of errors from each retry attempt
            error_code: Optional error code
        """
        troubleshooting = (
            "‚Ä¢ All retry attempts have been exhausted\n"
            "‚Ä¢ Check your internet connection\n"
            "‚Ä¢ Verify the API server is accessible\n"
            "‚Ä¢ Try again in a few moments\n"
            "‚Ä¢ Consider increasing max_retries if this is a temporary issue"
        )
        super().__init__(
            message,
            error_code=error_code or "RETRY_FAILED",
            troubleshooting=troubleshooting,
        )
        self.max_attempts = max_attempts
        self.last_error = last_error
        self.retry_history = retry_history

    def __str__(self) -> str:
        """Return a detailed error message with retry information."""
        msg = self.message
        msg += "\n\nüìä Retry Information:"
        msg += f"\n‚Ä¢ Maximum attempts: {self.max_attempts}"
        msg += f"\n‚Ä¢ Attempts made: {len(self.retry_history) + 1}"
        msg += f"\n‚Ä¢ Last error: {type(self.last_error).__name__}: {self.last_error}"

        if self.retry_history:
            msg += "\n\nüîÑ Retry History:"
            for i, error in enumerate(self.retry_history, 1):
                msg += f"\n‚Ä¢ Attempt {i}: {type(error).__name__}: {error}"

        if self.troubleshooting:
            msg += f"\n\nüí° Troubleshooting: {self.troubleshooting}"

        return msg

```

### File: `athena_client/build/lib/athena_client/http.py`
<a name="athena_client-build-lib-athena_client-httppy"></a>
```python
"""
HTTP client implementation for Athena API.

This module provides HTTP clients for making requests to the Athena API,
with features like retry, backoff, and timeout handling.
"""

import json
import logging
import random
import time
from typing import Any, Dict, Optional, Tuple, TypeVar, Union

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from .auth import build_headers
from .exceptions import (
    AthenaError,
    AuthenticationError,
    ClientError,
    NetworkError,
    RateLimitError,
    ServerError,
    TimeoutError,
    ValidationError,
)
from .settings import get_settings

# Type variable for generic response
T = TypeVar("T")

logger = logging.getLogger(__name__)


class HttpClient:
    """
    Synchronous HTTP client for making requests to the Athena API.

    Features:
    - Automatic retry with exponential backoff
    - Custom timeout handling
    - Authentication header generation
    - Error handling and mapping to typed exceptions
    - Robust logging and debugging
    - Custom User-Agent and headers
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        token: Optional[str] = None,
        client_id: Optional[str] = None,
        private_key: Optional[str] = None,
        timeout: Optional[int] = None,
        max_retries: Optional[int] = None,
        backoff_factor: Optional[float] = None,
        enable_throttling: bool = True,
        throttle_delay_range: Tuple[float, float] = (0.1, 0.3),
    ) -> None:
        """
        Initialize the HTTP client with configuration.

        Args:
            base_url: Base URL for the Athena API
            token: Bearer token for authentication
            client_id: Client ID for HMAC authentication
            private_key: Private key for HMAC signing
            timeout: HTTP timeout in seconds
            max_retries: Maximum number of retry attempts
            backoff_factor: Exponential backoff factor for retries
            enable_throttling: Whether to throttle requests to be respectful
                to the server
            throttle_delay_range: Range of delays for throttling (min, max)
                in seconds
        """
        settings = get_settings()

        # Use provided values or fall back to settings
        self.base_url = base_url or settings.ATHENA_BASE_URL

        # Set up token and HMAC if provided
        if token is not None:
            settings.ATHENA_TOKEN = token
        if client_id is not None:
            settings.ATHENA_CLIENT_ID = client_id
        if private_key is not None:
            settings.ATHENA_PRIVATE_KEY = private_key

        self.timeout = timeout or settings.ATHENA_TIMEOUT_SECONDS
        self.max_retries = max_retries or settings.ATHENA_MAX_RETRIES
        self.backoff_factor = backoff_factor or settings.ATHENA_BACKOFF_FACTOR
        self.enable_throttling = enable_throttling
        self.throttle_delay_range = throttle_delay_range

        # Create session with retry configuration
        self.session = self._create_session()

        # Set up default headers
        self._setup_default_headers()

        logger.debug("HttpClient initialized with base URL: %s", self.base_url)

    def _create_session(self) -> requests.Session:
        """
        Create and configure a requests Session with enhanced retry logic.

        Returns:
            Configured requests.Session object
        """
        session = requests.Session()

        # Enhanced retry strategy for better handling of rate limiting
        # and server overload
        retry_strategy = Retry(
            total=self.max_retries,
            backoff_factor=self.backoff_factor,
            # Retry on rate limiting (429), server errors (5xx), and temporary failures
            status_forcelist=[429, 500, 502, 503, 504, 520, 521, 522, 523, 524],
            # Also retry on connection errors and timeouts
            allowed_methods=["HEAD", "GET", "OPTIONS", "POST"],
            # Respect Retry-After headers from server
            respect_retry_after_header=True,
            # Exponential backoff with jitter to prevent thundering herd
            raise_on_status=False,  # Let us handle status codes ourselves
        )

        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        return session

    def _setup_default_headers(self) -> None:
        """Set up default headers for all requests."""
        # Set default headers similar to the working client
        default_headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "AthenaOHDSIAPIClient/1.0",
        }

        # Update session headers
        self.session.headers.update(default_headers)

        logger.debug("Default headers set: %s", default_headers)

    def _throttle_request(self) -> None:
        """
        Implement request throttling to prevent overwhelming the server.

        This adds a small delay between requests to be respectful to the API.
        """
        if not self.enable_throttling:
            return

        # Add a small random delay between requests
        # This prevents overwhelming the server with rapid requests
        delay = random.uniform(  # nosec B311
            self.throttle_delay_range[0], self.throttle_delay_range[1]
        )
        time.sleep(delay)

        logger.debug(f"Request throttled for {delay:.3f} seconds")

    def _handle_rate_limit(self, response: requests.Response) -> None:
        """
        Handle rate limiting with intelligent backoff.

        Args:
            response: HTTP response that indicates rate limiting
        """
        # Get retry-after header if available
        retry_after = response.headers.get("Retry-After")

        if retry_after:
            try:
                wait_time = int(retry_after)
                logger.info(
                    f"Rate limited. Waiting {wait_time} seconds as requested by server."
                )
                time.sleep(wait_time)
            except ValueError:
                # If Retry-After is not a number, use exponential backoff
                wait_time = 60  # Default to 1 minute
                logger.info(f"Rate limited. Waiting {wait_time} seconds (default).")
                time.sleep(wait_time)
        else:
            # No Retry-After header, use exponential backoff
            wait_time = 60  # Default to 1 minute
            logger.info(
                f"Rate limited. Waiting {wait_time} seconds (exponential backoff)."
            )
            time.sleep(wait_time)

    def _build_url(self, path: str) -> str:
        """
        Build full URL by joining base URL and path.

        Args:
            path: API path

        Returns:
            Full URL
        """
        # Handle paths that start with / to ensure they're appended correctly
        if path.startswith("/"):
            # Remove the leading / and join with base_url
            path = path[1:]

        # Ensure base_url doesn't end with / and path doesn't start with /
        if self.base_url.endswith("/"):
            base = self.base_url[:-1]
        else:
            base = self.base_url

        if path.startswith("/"):
            path = path[1:]

        full_url = f"{base}/{path}"

        logger.debug(
            f"Building URL: base_url='{self.base_url}', path='{path}' "
            f"-> full_url='{full_url}'"
        )
        return full_url

    def _normalize_params(
        self, params: Optional[Dict[str, Any]]
    ) -> Optional[Dict[str, str]]:
        """
        Normalize parameters to ensure all values are strings.

        Args:
            params: Query parameters

        Returns:
            Normalized parameters with string values
        """
        if params is None:
            return None

        normalized = {}
        for key, value in params.items():
            if value is not None:
                normalized[key] = str(value)
        return normalized

    def _handle_response(self, response: requests.Response, url: str) -> Dict[str, Any]:
        """
        Handle API response and raise appropriate exceptions.

        Args:
            response: HTTP response from requests
            url: Full URL that was requested

        Returns:
            Parsed JSON response

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
            APIError: For API-specific error responses
        """
        # Log raw response for debugging
        raw_response_text = response.text
        logger.debug(f"Raw response text from {url}: {raw_response_text[:1000]}...")

        try:
            response.raise_for_status()

            # Attempt to parse JSON after logging raw text
            data = response.json()
            logger.debug("Successfully parsed JSON from %s", url)
            return data

        except requests.exceptions.HTTPError as e:
            status = e.response.status_code if e.response else "N/A"
            text = e.response.text if e.response else "No response content"

            # Try to parse the error response as JSON to extract API error details
            api_message = None

            try:
                if e.response and e.response.text:
                    error_data = e.response.json()
                    api_message = error_data.get("errorMessage")
            except (ValueError, AttributeError):
                pass

            # Create a more descriptive error message
            if api_message:
                msg = f"API Error {status}: {api_message}"
            else:
                msg = f"HTTP error {status} when accessing {url}"
                if text and text != "No response content":
                    msg += f": {text[:200]}"

            logger.error(msg)
            logger.exception(e)

            # Raise specific exception types based on status code
            if status == 401:
                raise AuthenticationError(
                    f"Authentication failed: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 403:
                raise ClientError(
                    f"Access forbidden: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 404:
                raise ClientError(
                    f"Resource not found: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif status == 429:
                raise RateLimitError(
                    f"Rate limit exceeded: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif 400 <= response.status_code < 500:
                raise ClientError(
                    f"Client error: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            elif response.status_code >= 500:
                raise ServerError(
                    f"Server error: {msg}",
                    status_code=response.status_code,
                    response=response.text,
                    url=url,
                ) from e
            else:
                raise

        except json.JSONDecodeError as e:
            msg = (
                f"Invalid JSON response from {url}: {e}. "
                f"Raw text was: {raw_response_text[:1000]}..."
            )
            logger.error(msg)
            logger.exception(e)
            raise ValidationError(
                f"Invalid JSON response: {e}", validation_details=str(e)
            ) from e

        except Exception as e:
            msg = f"An unexpected error occurred when accessing {url}: {e}"
            logger.error(msg)
            logger.exception(e)
            raise AthenaError(msg, error_code="UNEXPECTED_ERROR") from e

    def request(
        self,
        method: str,
        path: str,
        data: Any = None,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make an HTTP request to the Athena API with enhanced retry and throttling.

        Args:
            method: HTTP method (GET, POST, etc.)
            path: API endpoint path
            params: Query parameters
            data: Request body data
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object

        Raises:
            ClientError: For 4xx status codes
            ServerError: For 5xx status codes
            NetworkError: For connection errors
            RateLimitError: For rate limiting issues
        """
        url = self._build_url(path)
        body_bytes = b""

        # Convert data to JSON bytes if provided
        if data is not None:
            body_bytes = json.dumps(data).encode("utf-8")

        # Build authentication headers
        auth_headers = build_headers(method, url, body_bytes)

        # Merge with session headers
        headers = dict(self.session.headers)
        headers.update(auth_headers)

        # Normalize parameters to strings
        normalized_params = self._normalize_params(params)

        # Generate a correlation ID for logging
        correlation_id = f"req-{id(self)}-{id(path)}"
        logger.debug(
            f"[{correlation_id}] {method} {url} with params: {normalized_params}"
        )

        # Throttle request to be respectful to the server
        self._throttle_request()

        try:
            response = self.session.request(
                method=method,
                url=url,
                params=normalized_params,
                data=body_bytes if data is not None else None,
                headers=headers,
                timeout=self.timeout,
            )

            logger.debug(f"[{correlation_id}] {response.status_code} {response.reason}")

            # Handle rate limiting specifically
            if response.status_code == 429:
                logger.warning(
                    f"Rate limited by server. Status: {response.status_code}"
                )
                self._handle_rate_limit(response)
                # After waiting, we could retry the request, but for now we'll
                # raise the error
                # The retry mechanism in the client will handle this

            if raw_response:
                return response

            return self._handle_response(response, url)

        except requests.exceptions.Timeout as e:
            msg = (
                f"Timeout when accessing {url}. "
                f"Verify network connectivity and the API's responsiveness."
            )
            logger.error(msg)
            logger.exception(e)
            raise TimeoutError(msg, url=url, timeout=self.timeout) from e

        except requests.exceptions.ConnectionError as e:
            msg = (
                f"Connection error when accessing {url}. "
                f"Check your network connection and endpoint URL."
            )
            logger.error(msg)
            logger.exception(e)
            raise NetworkError(msg, url=url) from e

        except Exception as e:
            msg = f"An unexpected error occurred when accessing {url}: {e}"
            logger.error(msg)
            logger.exception(e)
            raise NetworkError(msg, url=url) from e

    def get(
        self,
        path: str,
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make a GET request to the Athena API.

        Args:
            path: API endpoint path
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return self.request("GET", path, params=params, raw_response=raw_response)

    def post(
        self,
        path: str,
        data: Dict[str, Any],
        params: Optional[Dict[str, Any]] = None,
        raw_response: bool = False,
    ) -> Union[Dict[str, Any], requests.Response]:
        """
        Make a POST request to the Athena API.

        Args:
            path: API endpoint path
            data: Request body data
            params: Query parameters
            raw_response: Whether to return the raw response object

        Returns:
            Parsed JSON response or raw Response object
        """
        return self.request(
            "POST", path, data=data, params=params, raw_response=raw_response
        )

    def close(self) -> None:
        """Closes the underlying HTTP session."""
        logger.info("Closing HTTP session.")
        self.session.close()

    def __enter__(self) -> "HttpClient":
        return self

    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
        self.close()

```

### File: `athena_client/build/lib/athena_client/query.py`
<a name="athena_client-build-lib-athena_client-querypy"></a>
```python
"""
Query DSL for building complex Athena queries.

This module provides a Query DSL that allows for building complex queries
using a fluent interface and operator overloading.
"""

from typing import Any, Dict, Optional


class Q:
    """
    Query DSL for building complex Athena queries.

    Usage:
        q = Q.term("diabetes")
        q = Q.phrase("heart attack")
        q = Q.exact('"Myocardial Infarction"')
        q = Q.wildcard("aspir*")

        # Combine with operators
        q = Q.term("diabetes") & Q.term("type 2")  # AND
        q = Q.term("heart") | Q.term("cardiac")    # OR
        q = -Q.term("chronic")                     # NOT

        # Apply modifiers
        q = Q.term("aspirin").fuzzy(0.8)

        # Get boosts for the API
        boosts = q.to_boosts()
    """

    def __init__(self, query_type: str, value: str, **kwargs: Any) -> None:
        """
        Initialize a query object.

        Args:
            query_type: Type of query (term, phrase, exact, wildcard)
            value: Query value
            **kwargs: Additional options
        """
        self.query_type = query_type
        self.value = value
        self.options = kwargs
        self.operator: Optional[str] = None
        self.left: Optional["Q"] = None
        self.right: Optional["Q"] = None

    @classmethod
    def term(cls, value: str) -> "Q":
        """
        Create a term query.

        Args:
            value: Term to search for

        Returns:
            Query object
        """
        return cls("term", value)

    @classmethod
    def phrase(cls, value: str) -> "Q":
        """
        Create a phrase query.

        Args:
            value: Phrase to search for

        Returns:
            Query object
        """
        return cls("phrase", value)

    @classmethod
    def exact(cls, value: str) -> "Q":
        """
        Create an exact match query.

        Args:
            value: Exact phrase to search for (should be in quotes)

        Returns:
            Query object
        """
        if not value.startswith('"') or not value.endswith('"'):
            value = f'"{value}"'
        return cls("exact", value)

    @classmethod
    def wildcard(cls, value: str) -> "Q":
        """
        Create a wildcard query.

        Args:
            value: Wildcard pattern (e.g., "aspir*")

        Returns:
            Query object
        """
        if not value.endswith("*"):
            value = f"{value}*"
        return cls("wildcard", value)

    def fuzzy(self, ratio: float = 0.7) -> "Q":
        """
        Apply fuzzy matching to the query.

        Args:
            ratio: Fuzzy match ratio (0.0 - 1.0)

        Returns:
            Query object with fuzzy matching
        """
        self.options["fuzzy"] = ratio
        return self

    def __and__(self, other: "Q") -> "Q":
        """
        Combine with AND operator.

        Args:
            other: Another Q object

        Returns:
            New Q object representing the AND condition
        """
        result = Q("compound", "")
        result.operator = "AND"
        result.left = self
        result.right = other
        return result

    def __or__(self, other: "Q") -> "Q":
        """
        Combine with OR operator.

        Args:
            other: Another Q object

        Returns:
            New Q object representing the OR condition
        """
        result = Q("compound", "")
        result.operator = "OR"
        result.left = self
        result.right = other
        return result

    def __neg__(self) -> "Q":
        """
        Apply NOT operator.

        Returns:
            New Q object representing the NOT condition
        """
        result = Q("compound", "")
        result.operator = "NOT"
        result.right = self
        return result

    def to_boosts(self) -> Dict[str, Any]:
        """
        Convert the query to a boosts dictionary for the Athena API.

        Returns:
            Dictionary with query boosts
        """
        if self.query_type == "compound":
            if self.operator == "AND":
                assert self.left is not None and self.right is not None
                boosts_left = self.left.to_boosts()
                boosts_right = self.right.to_boosts()
                # Merge the boosts with AND logic
                return {
                    "filter": {
                        "bool": {
                            "must": [
                                boosts_left.get("filter", {}),
                                boosts_right.get("filter", {}),
                            ]
                        }
                    }
                }
            elif self.operator == "OR":
                assert self.left is not None and self.right is not None
                boosts_left = self.left.to_boosts()
                boosts_right = self.right.to_boosts()
                # Merge the boosts with OR logic
                return {
                    "filter": {
                        "bool": {
                            "should": [
                                boosts_left.get("filter", {}),
                                boosts_right.get("filter", {}),
                            ]
                        }
                    }
                }
            elif self.operator == "NOT":
                assert self.right is not None
                boosts_right = self.right.to_boosts()
                # Apply NOT logic
                return {
                    "filter": {"bool": {"must_not": [boosts_right.get("filter", {})]}}
                }
            # Fallback for unrecognized operator
            return {"filter": {"query_string": {"query": self.value}}}

        # Handle basic query types
        query_dict: Dict[str, Any] = {}

        if self.query_type == "term":
            query_dict["query"] = self.value
            query_dict["fields"] = [
                "name^10",
                "synonyms^5",
                "definition^3",
                "concept_code",
            ]
        elif self.query_type == "phrase":
            query_dict["query"] = f'"{self.value}"'
            query_dict["fields"] = ["name^10", "synonyms^5", "definition^3"]
        elif self.query_type == "exact":
            query_dict["query"] = self.value
            query_dict["fields"] = ["concept_code^20", "name.exact^15"]
        elif self.query_type == "wildcard":
            query_dict["query"] = self.value
            query_dict["fields"] = ["name^10", "synonyms^5"]

        # Apply fuzzy if requested
        if "fuzzy" in self.options:
            query_dict["fuzziness"] = self.options["fuzzy"]

        if query_dict:
            return {"filter": {"query_string": query_dict}}
        # Final fallback for unhandled query types
        return {"filter": {"query_string": {"query": self.value}}}

    def __str__(self) -> str:
        """
        Convert the query to a string representation for API calls.

        Returns:
            String representation of the query
        """
        if self.query_type == "compound":
            if self.operator == "AND":
                assert self.left is not None and self.right is not None
                return f"({self.left}) AND ({self.right})"
            elif self.operator == "OR":
                assert self.left is not None and self.right is not None
                return f"({self.left}) OR ({self.right})"
            elif self.operator == "NOT":
                assert self.right is not None
                return f"NOT ({self.right})"
            # Gracefully handle unknown operators by returning the raw value
            return self.value
        else:
            # For basic query types, return the value
            return self.value

```

### File: `athena_client/build/lib/athena_client/search_result.py`
<a name="athena_client-build-lib-athena_client-search_resultpy"></a>
```python
"""
Search result wrapper for Athena API responses.

This module provides a wrapper around search results that provides
convenient access to the data in various formats.
"""

from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional

import pandas as pd

from .models import Concept, ConceptSearchResponse

if TYPE_CHECKING:
    pass


class SearchResult:
    """Wrapper for search results that provides convenient access methods."""

    def __init__(self, response: ConceptSearchResponse, client: Any) -> None:
        """Initialize the search result wrapper.

        Args:
            response: The search response from the API
            client: The client instance for making additional requests
        """
        self._response = response
        self._client = client

    def all(self) -> List[Concept]:
        """Get all concepts from the current page.

        Returns:
            List of Concept objects
        """
        return self._response.content

    def top(self, n: int) -> List[Concept]:
        """Get the top N concepts from the current page.

        Args:
            n: Number of concepts to return

        Returns:
            List of Concept objects
        """
        return self._response.content[:n]

    def to_list(self) -> List[Dict[str, Any]]:
        """Convert results to a list of dictionaries.

        Returns:
            List of dictionaries representing concepts
        """
        return [concept.model_dump() for concept in self._response.content]

    def to_json(self) -> str:
        """Convert results to JSON string.

        Returns:
            JSON string representation of the results
        """
        return self._response.model_dump_json()

    def to_df(self) -> pd.DataFrame:
        """Convert results to a pandas DataFrame.

        Returns:
            DataFrame containing the concept data
        """
        try:
            data = self.to_list()
            return pd.DataFrame(data)
        except ImportError:
            raise ImportError(
                "pandas is required for DataFrame output. "
                "Install with: pip install 'athena-client[pandas]'"
            ) from None

    def next_page(self) -> Optional["SearchResult"]:
        """Get the next page of results.

        Returns:
            SearchResult for the next page, or None if no more pages
        """
        if self._response.last:
            return None
        current_page = self._response.number
        size = self._response.size
        if current_page is None or size is None:
            return None
        return self._client.search(
            query="",  # This would need to be the original query
            page=current_page + 1,
            size=size,
        )

    def previous_page(self) -> Optional["SearchResult"]:
        """Get the previous page of results.

        Returns:
            SearchResult for the previous page, or None if no previous pages
        """
        if self._response.first:
            return None
        current_page = self._response.number
        size = self._response.size
        if current_page is None or size is None:
            return None
        return self._client.search(
            query="",  # This would need to be the original query
            page=current_page - 1,
            size=size,
        )

    @property
    def total_elements(self) -> int:
        """Get the total number of elements across all pages.

        Returns:
            Total number of elements
        """
        # Try to get from direct field first, then from pageable
        if self._response.totalElements is not None:
            return self._response.totalElements

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "totalElements" in pageable:
            return pageable["totalElements"]

        # Fallback to number of elements in current page
        return len(self._response.content)

    @property
    def total_pages(self) -> int:
        """Get the total number of pages.

        Returns:
            Total number of pages
        """
        # Try to get from direct field first, then calculate from pageable
        if self._response.totalPages is not None:
            return self._response.totalPages

        # Calculate from pageable if available
        pageable = self._response.pageable
        if pageable and "totalElements" in pageable and "pageSize" in pageable:
            total_elements = pageable["totalElements"]
            page_size = pageable["pageSize"]
            return (total_elements + page_size - 1) // page_size

        return 1

    @property
    def current_page(self) -> int:
        """Get the current page number.

        Returns:
            Current page number
        """
        # Try to get from direct field first, then from pageable
        if self._response.number is not None:
            return self._response.number

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "pageNumber" in pageable:
            return pageable["pageNumber"]

        return 0

    @property
    def page_size(self) -> int:
        """Get the page size.

        Returns:
            Page size
        """
        # Try to get from direct field first, then from pageable
        if self._response.size is not None:
            return self._response.size

        # Extract from pageable if available
        pageable = self._response.pageable
        if pageable and "pageSize" in pageable:
            return pageable["pageSize"]

        return len(self._response.content)

    @property
    def facets(self) -> Optional[Dict[str, Any]]:
        """Get search facets if available.

        Returns:
            Search facets dictionary or None
        """
        return self._response.facets

    def __len__(self) -> int:
        """Get the number of concepts in the current page.

        Returns:
            Number of concepts
        """
        return len(self._response.content)

    def __getitem__(self, index: int) -> Concept:
        """Get a concept by index.

        Args:
            index: Index of the concept

        Returns:
            Concept object
        """
        return self._response.content[index]

    def __iter__(self) -> Iterator["Concept"]:
        """Iterate over concepts in the current page.

        Returns:
            Iterator over Concept objects
        """
        return iter(self._response.content)

```

### File: `athena_client/build/lib/athena_client/settings.py`
<a name="athena_client-build-lib-athena_client-settingspy"></a>
```python
"""
Settings module for the Athena client.

This module provides configuration settings loaded from environment variables
or .env files using pydantic-settings.
"""

from functools import lru_cache
from typing import Optional

from pydantic_settings import BaseSettings, SettingsConfigDict


class _Settings(BaseSettings):
    """
    Configuration settings for the Athena client.

    Settings can be provided via environment variables, .env file, or defaults.
    """

    ATHENA_BASE_URL: str = "https://athena.ohdsi.org/api/v1"
    ATHENA_TOKEN: Optional[str] = None
    ATHENA_CLIENT_ID: Optional[str] = None
    ATHENA_PRIVATE_KEY: Optional[str] = None

    # Enhanced timeout configuration for different operations
    ATHENA_TIMEOUT_SECONDS: int = 30  # Increased default timeout
    ATHENA_SEARCH_TIMEOUT_SECONDS: int = 45  # Longer timeout for search operations
    ATHENA_GRAPH_TIMEOUT_SECONDS: int = 60  # Even longer for graph operations
    ATHENA_RELATIONSHIPS_TIMEOUT_SECONDS: int = 45  # For relationship queries

    # Retry configuration
    ATHENA_MAX_RETRIES: int = 3
    ATHENA_BACKOFF_FACTOR: float = 0.3

    # Pagination configuration
    ATHENA_DEFAULT_PAGE_SIZE: int = 20
    ATHENA_MAX_PAGE_SIZE: int = 1000
    ATHENA_LARGE_QUERY_THRESHOLD: int = 100  # Threshold for "large" queries

    # Progress and user experience
    ATHENA_SHOW_PROGRESS: bool = True
    ATHENA_PROGRESS_UPDATE_INTERVAL: float = 2.0  # Seconds between progress updates

    # Large query handling
    ATHENA_AUTO_CHUNK_LARGE_QUERIES: bool = True
    ATHENA_CHUNK_SIZE: int = 50  # Size for chunking large queries
    ATHENA_MAX_CONCURRENT_CHUNKS: int = 3  # Max concurrent chunk requests

    model_config = SettingsConfigDict(env_file=".env", env_prefix="")


@lru_cache
def get_settings() -> _Settings:
    """
    Get the settings singleton.

    Returns:
        Cached instance of _Settings.
    """
    return _Settings()  # cached singleton

```

## Folder: build/lib/athena_client/utils

### File: `athena_client/build/lib/athena_client/utils/__init__.py`
<a name="athena_client-build-lib-athena_client-utils-__init__py"></a>
```python
"""
Utility functions for the Athena client.

This module provides various utility functions for the Athena client,
including progress tracking, query size estimation, and timeout management.
"""

import logging
from typing import Optional

from .progress import (
    ProgressTracker,
    estimate_query_size,
    format_large_query_warning,
    get_operation_timeout,
    progress_context,
)

logger = logging.getLogger(__name__)


def configure_logging(level: Optional[int] = None) -> None:
    """
    Configure logging for the Athena client.

    Args:
        level: Logging level (e.g., logging.INFO, logging.DEBUG)
    """
    log_level = level or logging.INFO

    logger = logging.getLogger("athena_client")
    logger.setLevel(log_level)

    # Create console handler if no handlers exist
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setLevel(log_level)

        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        handler.setFormatter(formatter)

        logger.addHandler(handler)


__all__ = [
    "configure_logging",
    "ProgressTracker",
    "progress_context",
    "estimate_query_size",
    "get_operation_timeout",
    "format_large_query_warning",
]

```

### File: `athena_client/build/lib/athena_client/utils/progress.py`
<a name="athena_client-build-lib-athena_client-utils-progresspy"></a>
```python
"""
Progress tracking utilities for large queries.

This module provides progress indicators and user-friendly feedback
for long-running operations like large searches and graph queries.
"""

import threading
import time
from contextlib import contextmanager
from typing import Generator, Optional


class ProgressTracker:
    """Track progress of long-running operations with user-friendly feedback."""

    def __init__(
        self,
        total: int,
        description: str = "Processing",
        show_progress: bool = True,
        update_interval: float = 2.0,
    ) -> None:
        """
        Initialize the progress tracker.

        Args:
            total: Total number of items to process
            description: Description of the operation
            show_progress: Whether to show progress updates
            update_interval: Seconds between progress updates
        """
        self.total = total
        self.description = description
        self.show_progress = show_progress
        self.update_interval = update_interval
        self.current = 0
        self.start_time: Optional[float] = None
        self.last_update_time: float = 0.0
        self._lock = threading.Lock()

    def start(self) -> None:
        """Start tracking progress."""
        self.start_time = time.time()
        if self.show_progress:
            self._print_progress()

    def update(self, increment: int = 1) -> None:
        """
        Update progress by the given increment.

        Args:
            increment: Number of items completed
        """
        with self._lock:
            self.current += increment
            current_time = time.time()

            # Only update display if enough time has passed
            if (
                self.show_progress
                and current_time - self.last_update_time >= self.update_interval
            ):
                self._print_progress()
                self.last_update_time = current_time

    def complete(self) -> None:
        """Mark the operation as complete."""
        self.current = self.total
        if self.show_progress:
            self._print_progress()
            print(f"‚úÖ {self.description} completed!")

    def _print_progress(self) -> None:
        """Print the current progress."""
        if self.total == 0:
            return

        percentage = (self.current / self.total) * 100
        elapsed = time.time() - self.start_time if self.start_time else 0

        # Calculate ETA
        eta = None
        if self.current > 0 and elapsed > 0:
            rate = self.current / elapsed
            remaining = self.total - self.current
            eta = remaining / rate if rate > 0 else None

        # Create progress bar
        bar_length = 30
        filled_length = int(bar_length * self.current // self.total)
        bar = "‚ñà" * filled_length + "‚ñë" * (bar_length - filled_length)

        # Format time
        elapsed_str = self._format_time(elapsed)
        eta_str = f" (ETA: {self._format_time(eta)})" if eta else ""

        print(
            f"\r{self.description}: [{bar}] {percentage:.1f}% "
            f"({self.current}/{self.total}) {elapsed_str}{eta_str}",
            end="",
            flush=True,
        )

    def _format_time(self, seconds: Optional[float]) -> str:
        """Format time in a human-readable way."""
        if seconds is None:
            return "unknown"

        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}m"
        else:
            hours = seconds / 3600
            return f"{hours:.1f}h"


@contextmanager
def progress_context(
    total: int,
    description: str = "Processing",
    show_progress: bool = True,
    update_interval: float = 2.0,
) -> Generator[ProgressTracker, None, None]:
    """
    Context manager for progress tracking.

    Args:
        total: Total number of items to process
        description: Description of the operation
        show_progress: Whether to show progress updates
        update_interval: Seconds between progress updates

    Yields:
        ProgressTracker instance
    """
    tracker = ProgressTracker(total, description, show_progress, update_interval)
    try:
        tracker.start()
        yield tracker
    finally:
        tracker.complete()


def estimate_query_size(query: str) -> int:
    """
    Estimate the size of a query based on its characteristics.

    Args:
        query: The search query string

    Returns:
        Estimated number of results
    """
    # Simple heuristics for query size estimation
    query_lower = query.lower()

    # Very broad queries
    if len(query) <= 2:
        return 10000  # Very broad, likely many results

    # Common medical terms that are likely to have many results
    broad_terms = [
        "pain",
        "fever",
        "headache",
        "cough",
        "diabetes",
        "hypertension",
        "cancer",
        "heart",
        "lung",
        "liver",
        "kidney",
        "blood",
        "infection",
    ]

    if any(term in query_lower for term in broad_terms):
        return 5000

    # Specific terms with modifiers
    if any(word in query_lower for word in ["acute", "chronic", "severe", "mild"]):
        return 2000

    # Very specific terms (likely fewer results)
    if len(query) > 10 and any(char.isdigit() for char in query):
        return 500

    # Default estimate
    return 1000


def get_operation_timeout(operation_type: str, query_size: Optional[int] = None) -> int:
    """
    Get appropriate timeout for different operation types.

    Args:
        operation_type: Type of operation ('search', 'graph', 'relationships')
        query_size: Estimated size of the query

    Returns:
        Timeout in seconds
    """
    from athena_client.settings import get_settings

    settings = get_settings()

    # Base timeouts
    base_timeouts = {
        "search": settings.ATHENA_SEARCH_TIMEOUT_SECONDS,
        "graph": settings.ATHENA_GRAPH_TIMEOUT_SECONDS,
        "relationships": settings.ATHENA_RELATIONSHIPS_TIMEOUT_SECONDS,
        "details": settings.ATHENA_TIMEOUT_SECONDS,
    }

    base_timeout = base_timeouts.get(operation_type, settings.ATHENA_TIMEOUT_SECONDS)

    # Adjust based on query size
    if query_size:
        if query_size > 10000:
            return int(base_timeout * 2.5)  # Very large queries
        elif query_size > 5000:
            return int(base_timeout * 2.0)  # Large queries
        elif query_size > 1000:
            return int(base_timeout * 1.5)  # Medium queries

    return base_timeout


def format_large_query_warning(query: str, estimated_size: int) -> str:
    """
    Generate a user-friendly warning for large queries.

    Args:
        query: The search query
        estimated_size: Estimated number of results

    Returns:
        Warning message
    """
    if estimated_size < 1000:
        return ""

    warning = f"‚ö†Ô∏è  Large query detected: '{query}' "

    if estimated_size > 10000:
        warning += f"(estimated {estimated_size:,}+ results)\n"
        warning += "üí° Suggestions:\n"
        warning += "   ‚Ä¢ Add more specific terms to narrow results\n"
        warning += "   ‚Ä¢ Use domain or vocabulary filters\n"
        warning += "   ‚Ä¢ Consider using smaller page sizes\n"
        warning += "   ‚Ä¢ This query may take several minutes to complete"
    elif estimated_size > 5000:
        warning += f"(estimated {estimated_size:,}+ results)\n"
        warning += "üí° Consider adding filters to reduce results"
    else:
        warning += f"(estimated {estimated_size:,}+ results)"

    return warning

```

## Folder: build/lib/athena_client/models

### File: `athena_client/build/lib/athena_client/models/__init__.py`
<a name="athena_client-build-lib-athena_client-models-__init__py"></a>
```python
"""
Pydantic models for Athena API responses.

This module defines Pydantic models for the various responses from the Athena API.
"""

from enum import Enum
from typing import Any, ClassVar, Dict, List, Optional, Union, cast

import orjson
from pydantic import BaseModel as PydanticBaseModel
from pydantic import ConfigDict, Field, model_validator


def _json_dumps(value: Any, *, default: Any) -> str:
    """Serialize to JSON using orjson."""
    return orjson.dumps(value, default=default).decode()


class BaseModel(PydanticBaseModel):
    """Project-wide Pydantic base model using orjson."""

    model_config: ClassVar[ConfigDict] = cast(
        ConfigDict,
        {
            "populate_by_name": True,
            "extra": "ignore",
        },
    )

    def model_dump_json(self, **kwargs: Any) -> str:
        """Serialize model to JSON using orjson."""
        return orjson.dumps(self.model_dump(**kwargs)).decode()

    @classmethod
    def model_validate_json(
        cls: type["BaseModel"], json_data: Union[str, bytes], **kwargs: Any
    ) -> "BaseModel":
        """Deserialize model from JSON using orjson."""
        return cls.model_validate(orjson.loads(json_data), **kwargs)


class Domain(BaseModel):
    """Domain information for a concept."""

    id: int = Field(..., description="Domain ID")
    name: str = Field(..., description="Domain name")


class Vocabulary(BaseModel):
    """Vocabulary information for a concept."""

    id: str = Field(..., description="Vocabulary ID")
    name: str = Field(..., description="Vocabulary name")


class ConceptClass(BaseModel):
    """Concept class information."""

    id: str = Field(..., description="Concept class ID")
    name: str = Field(..., description="Concept class name")


class ConceptType(str, Enum):
    """Concept standard type."""

    STANDARD = "Standard"
    CLASSIFICATION = "Classification"
    NON_STANDARD = "Non-standard"


class Concept(BaseModel):
    """Basic concept information returned in search results."""

    id: int = Field(..., description="Concept ID")
    name: str = Field(..., description="Concept name")
    domain: str = Field(..., description="Domain name")
    vocabulary: str = Field(..., description="Vocabulary name")
    className: str = Field(..., description="Concept class name")
    standardConcept: Optional[ConceptType] = Field(
        None, description="Standard concept flag"
    )
    code: str = Field(..., description="Concept code")
    invalidReason: Optional[str] = Field(None, description="Invalid reason")
    score: Optional[float] = Field(None, description="Search score")


class ConceptSearchResponse(BaseModel):
    """Response from the /concepts search endpoint."""

    content: List[Concept] = Field(..., description="List of concept results")
    pageable: Dict[str, Any] = Field(..., description="Pagination information")
    totalElements: Optional[int] = Field(None, description="Total number of results")
    last: Optional[bool] = Field(None, description="Whether this is the last page")
    totalPages: Optional[int] = Field(None, description="Total number of pages")
    sort: Optional[Dict[str, Any]] = Field(None, description="Sort information")
    first: Optional[bool] = Field(None, description="Whether this is the first page")
    size: Optional[int] = Field(None, description="Page size")
    number: Optional[int] = Field(None, description="Page number")
    numberOfElements: Optional[int] = Field(
        None, description="Number of elements in this page"
    )
    empty: Optional[bool] = Field(None, description="Whether the result is empty")
    facets: Optional[Dict[str, Any]] = Field(None, description="Search facets")


class ConceptDetails(BaseModel):
    """Detailed concept information from the /concepts/{id} endpoint."""

    id: int = Field(..., description="Concept ID")
    name: str = Field(..., description="Concept name")
    domainId: str = Field(..., description="Domain ID")
    vocabularyId: str = Field(..., description="Vocabulary ID")
    conceptClassId: str = Field(..., description="Concept class ID")
    standardConcept: Optional[ConceptType] = Field(
        None, description="Standard concept flag"
    )
    conceptCode: str = Field(..., description="Concept code")
    invalidReason: Optional[str] = Field(None, description="Invalid reason")
    validStart: str = Field(..., description="Valid start date")
    validEnd: str = Field(..., description="Valid end date")
    synonyms: Optional[List[Union[str, Dict[str, Any]]]] = Field(
        None, description="Concept synonyms"
    )
    validTerm: Optional[Union[str, Dict[str, Any]]] = Field(
        None, description="Valid term"
    )
    vocabularyName: Optional[str] = Field(None, description="Vocabulary name")
    vocabularyVersion: Optional[str] = Field(None, description="Vocabulary version")
    vocabularyReference: Optional[str] = Field(None, description="Vocabulary reference")
    links: Optional[Dict[str, Any]] = Field(
        None, description="HATEOAS links", alias="_links"
    )

    @model_validator(mode="before")
    @classmethod
    def normalize_synonyms(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        synonyms = values.get("synonyms")
        if synonyms and isinstance(synonyms, list):
            normalized = []
            for item in synonyms:
                if isinstance(item, str):
                    normalized.append(item)
                elif isinstance(item, dict):
                    # Use 'synonymName' if present, else join all string values
                    if "synonymName" in item:
                        normalized.append(item["synonymName"])
                    else:
                        # Fallback: join all string values in the dict
                        str_values = [
                            str(v) for v in item.values() if isinstance(v, str)
                        ]
                        normalized.append(", ".join(str_values))
            values["synonyms"] = normalized
        return values

    @model_validator(mode="before")
    @classmethod
    def normalize_valid_term(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        valid_term = values.get("validTerm")
        if valid_term and isinstance(valid_term, dict):
            # Extract name from validTerm dict if it's a dictionary
            if "name" in valid_term:
                values["validTerm"] = valid_term["name"]
            else:
                # Fallback: convert to string representation
                values["validTerm"] = str(valid_term)
        return values


class RelationshipItem(BaseModel):
    """Information about a relationship between concepts."""

    targetConceptId: int = Field(..., description="Target concept ID")
    targetConceptName: str = Field(..., description="Target concept name")
    targetVocabularyId: str = Field(..., description="Target vocabulary ID")
    relationshipId: str = Field(..., description="Relationship ID")
    relationshipName: str = Field(..., description="Relationship name")


class RelationshipGroup(BaseModel):
    """Group of relationships with the same type."""

    relationshipName: str = Field(..., description="Relationship name")
    relationships: List[RelationshipItem] = Field(
        ..., description="List of relationships"
    )


class ConceptRelationship(BaseModel):
    """Response from the /concepts/{id}/relationships endpoint."""

    count: int = Field(..., description="Total count of relationships")
    items: List[RelationshipGroup] = Field(
        ..., description="List of relationship groups"
    )


class GraphTerm(BaseModel):
    """Term in the concept relationship graph."""

    id: int = Field(..., description="Term ID")
    name: str = Field(..., description="Term name")
    weight: int = Field(..., description="Term weight")
    depth: int = Field(..., description="Term depth")
    count: int = Field(..., description="Term count")
    isCurrent: bool = Field(..., description="Whether this is the current concept")


class GraphLink(BaseModel):
    """Link in the concept relationship graph."""

    source: int = Field(..., description="Source term ID")
    target: int = Field(..., description="Target term ID")
    relationshipId: Optional[str] = Field(None, description="Relationship ID")
    relationshipName: Optional[str] = Field(None, description="Relationship name")


class ConceptRelationsGraph(BaseModel):
    """Response from the /concepts/{id}/relations endpoint."""

    terms: List[GraphTerm] = Field(..., description="Graph terms")
    links: List[GraphLink] = Field(..., description="Graph links")
    connectionsCount: Optional[int] = Field(None, description="Total connections count")


# Re-export models
__all__ = [
    "Concept",
    "ConceptClass",
    "ConceptDetails",
    "ConceptRelationsGraph",
    "ConceptRelationship",
    "ConceptSearchResponse",
    "ConceptType",
    "Domain",
    "GraphLink",
    "GraphTerm",
    "RelationshipGroup",
    "RelationshipItem",
    "Vocabulary",
]

```

## Folder: build/lib/athena_client/db

### File: `athena_client/build/lib/athena_client/db/__init__.py`
<a name="athena_client-build-lib-athena_client-db-__init__py"></a>
```python

```

### File: `athena_client/build/lib/athena_client/db/base.py`
<a name="athena_client-build-lib-athena_client-db-basepy"></a>
```python
from typing import Dict, List, Protocol


class DatabaseConnector(Protocol):
    """Protocol for database connectors."""

    def validate_concepts(self, concept_ids: List[int]) -> List[int]:
        """Validate concept IDs against the local database."""
        ...

    def get_descendants(self, concept_ids: List[int]) -> List[int]:
        """Return descendant concept IDs for the given ancestors."""
        ...

    def get_standard_mapping(
        self, non_standard_concept_ids: List[int]
    ) -> Dict[int, int]:
        """Return mapping from non-standard to standard concept IDs."""
        ...

```

### File: `athena_client/build/lib/athena_client/db/sqlalchemy_connector.py`
<a name="athena_client-build-lib-athena_client-db-sqlalchemy_connectorpy"></a>
```python
from typing import Dict, List

from sqlalchemy import bindparam, create_engine, text
from sqlalchemy.engine import Engine


class SQLAlchemyConnector:
    """Database connector using SQLAlchemy Core."""

    def __init__(self, engine: Engine) -> None:
        self._engine = engine

    def validate_concepts(self, concept_ids: List[int]) -> List[int]:
        if not concept_ids:
            return []

        stmt = text(
            """
                SELECT concept_id
                FROM concept
                WHERE concept_id IN :ids AND standard_concept = 'S'
                """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(concept_ids)})
            validated_ids = [row[0] for row in result]

        return validated_ids

    def get_descendants(self, concept_ids: List[int]) -> List[int]:
        """Retrieve descendant concept IDs for the given ancestors."""
        if not concept_ids:
            return []

        stmt = text(
            """
                SELECT descendant_concept_id
                FROM concept_ancestor
                WHERE ancestor_concept_id IN :ids
                """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(concept_ids)})
            descendant_ids = [row[0] for row in result]

        return list(set(descendant_ids) - set(concept_ids))

    def get_standard_mapping(
        self, non_standard_concept_ids: List[int]
    ) -> Dict[int, int]:
        """Find standard mappings for the given non-standard concept IDs."""
        if not non_standard_concept_ids:
            return {}

        stmt = text(
            """
            SELECT cr.concept_id_1, cr.concept_id_2, c2.standard_concept
            FROM concept_relationship cr
            JOIN concept c2 ON cr.concept_id_2 = c2.concept_id
            WHERE cr.concept_id_1 IN :ids
              AND cr.relationship_id = 'Maps to'
              AND cr.invalid_reason IS NULL
            """
        ).bindparams(bindparam("ids", expanding=True))

        with self._engine.connect() as connection:
            result = connection.execute(stmt, {"ids": list(non_standard_concept_ids)})
            mapping: Dict[int, int] = {}
            for row in result:
                concept_id_1, concept_id_2, standard_flag = row
                if standard_flag == "S" and concept_id_1 not in mapping:
                    mapping[concept_id_1] = concept_id_2

        return mapping

    @staticmethod
    def from_connection_string(connection_string: str) -> "SQLAlchemyConnector":
        engine = create_engine(connection_string)
        return SQLAlchemyConnector(engine)

```

## Folder: build/bdist.macosx-15.5-arm64

## Folder: athena_client.egg-info

### File: `athena_client/athena_client.egg-info/SOURCES.txt`
<a name="athena_client-athena_clientegg-info-sourcestxt"></a>
```text
README.md
pyproject.toml
athena_client/__init__.py
athena_client/async_client.py
athena_client/auth.py
athena_client/cli.py
athena_client/client.py
athena_client/concept_explorer.py
athena_client/concept_set.py
athena_client/exceptions.py
athena_client/http.py
athena_client/query.py
athena_client/search_result.py
athena_client/settings.py
athena_client.egg-info/PKG-INFO
athena_client.egg-info/SOURCES.txt
athena_client.egg-info/dependency_links.txt
athena_client.egg-info/entry_points.txt
athena_client.egg-info/requires.txt
athena_client.egg-info/top_level.txt
athena_client/db/__init__.py
athena_client/db/base.py
athena_client/db/sqlalchemy_connector.py
athena_client/models/__init__.py
athena_client/utils/__init__.py
athena_client/utils/progress.py
tests/test_async_client.py
tests/test_auth.py
tests/test_cli.py
tests/test_client.py
tests/test_concept_explorer.py
tests/test_concept_set.py
tests/test_exceptions.py
tests/test_http.py
tests/test_models.py
tests/test_query.py
tests/test_search_result.py
tests/test_utils.py
```

### File: `athena_client/athena_client.egg-info/dependency_links.txt`
<a name="athena_client-athena_clientegg-info-dependency_linkstxt"></a>
```text


```

### File: `athena_client/athena_client.egg-info/entry_points.txt`
<a name="athena_client-athena_clientegg-info-entry_pointstxt"></a>
```text
[console_scripts]
athena = athena_client.cli:main
athena-client = athena_client.cli:main

```

### File: `athena_client/athena_client.egg-info/requires.txt`
<a name="athena_client-athena_clientegg-info-requirestxt"></a>
```text
orjson>=3.9.0
pydantic>=2.0.0
pydantic-settings
httpx>=0.18.0
backoff>=2.0.0
sqlalchemy<1.5.0,>=1.4.0
pandas>=1.3.0
click>=8.0.0
rich>=10.0.0
pyyaml>=6.0
cryptography>=36.0.0
psycopg2-binary>=2.9.0

[async]
httpx>=0.18.0
backoff>=2.0.0

[bigquery]
sqlalchemy<1.5.0,>=1.4.0
sqlalchemy-bigquery

[cli]
click>=8.0.0
rich>=10.0.0

[crypto]
cryptography>=36.0.0

[db]
athena-client[postgres]
athena-client[bigquery]

[dev]
ruff>=0.4.0
cyclonedx-bom>=3.15.0
mypy>=1.10
pip-audit>=2.6
pytest>=8.2
pytest-cov>=5.0
pytest-asyncio[mode-auto]>=0.23
hypothesis>=6.103
vcrpy>=6.0
rich>=13.7
build>=1.2
twine>=5.1
pytest-benchmark>=4.0
bandit>=1.7.5
cyclonedx-python-lib>=5.2.0
types-requests
types-PyYAML
pandas-stubs
sqlalchemy-stubs
hatch
hatchling

[pandas]
pandas>=1.3.0

[postgres]
sqlalchemy<1.5.0,>=1.4.0
psycopg2-binary>=2.9.0

[yaml]
pyyaml>=6.0

```

### File: `athena_client/athena_client.egg-info/top_level.txt`
<a name="athena_client-athena_clientegg-info-top_leveltxt"></a>
```text
athena_client

```
